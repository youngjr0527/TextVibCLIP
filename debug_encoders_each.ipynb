{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîç TST vs 1D-CNN ÏôÑÏ†Ñ ÎπÑÍµê Ïã§Ìóò\n",
        "\n",
        "## Î™©Ìëú\n",
        "1. **TST ÏÑ±Îä• ÌèâÍ∞Ä** - debug_encoders.ipynb Í∏∞Î∞ò (OOM ÏóÜÏù¥ ÏÑ±Í≥µ)\n",
        "2. **1D-CNN ÏÑ±Îä• ÌèâÍ∞Ä** - debug_encoders_clean.ipynb Í∏∞Î∞ò (Supervised Learning)\n",
        "3. **ÏôÑÏ†ÑÌïú ÎπÑÍµê ÏãúÍ∞ÅÌôî** - t-SNE, ÏÑ±Îä• Ï∞®Ìä∏, Ï¢ÖÌï© Î∂ÑÏÑù\n",
        "4. **ÏµúÏ¢Ö Í≤∞Î°† ÎèÑÏ∂ú** - Ï†ÑÏ≤¥ ÏãúÏä§ÌÖú Ï†ÅÏö©ÏùÑ ÏúÑÌïú Î™ÖÌôïÌïú Í∑ºÍ±∞\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ÌïúÍ∏Ä Ìè∞Ìä∏ ÏÑ§Ï†ï: NanumGothic\n",
            "‚úÖ Ï†ÑÏó≠ ÏãúÎìú ÏÑ§Ï†ï ÏôÑÎ£å: 42\n",
            "üîß ÎîîÎ∞îÏù¥Ïä§: cuda\n",
            "   GPU: Quadro RTX 5000\n",
            "üéØ TSTÎäî debug_encoders.ipynb Î∞©ÏãùÏúºÎ°ú ÌèâÍ∞Ä\n",
            "üéØ 1D-CNNÏùÄ debug_encoders_clean.ipynb Î∞©ÏãùÏúºÎ°ú ÌèâÍ∞Ä\n"
          ]
        }
      ],
      "source": [
        "# ÌïÑÏàò ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∞è ÌôòÍ≤Ω ÏÑ§Ï†ï\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.manifold import TSNE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ÌïúÍ∏Ä Ìè∞Ìä∏ ÏÑ§Ï†ï\n",
        "def setup_korean_font():\n",
        "    font_paths = [\n",
        "        '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n",
        "        '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "    ]\n",
        "    \n",
        "    for path in font_paths:\n",
        "        if os.path.exists(path):\n",
        "            font_prop = fm.FontProperties(fname=path)\n",
        "            plt.rcParams['font.family'] = font_prop.get_name()\n",
        "            plt.rcParams['axes.unicode_minus'] = False\n",
        "            print(f\"‚úÖ ÌïúÍ∏Ä Ìè∞Ìä∏ ÏÑ§Ï†ï: {font_prop.get_name()}\")\n",
        "            return True\n",
        "    \n",
        "    print(\"‚ö†Ô∏è  ÌïúÍ∏Ä Ìè∞Ìä∏Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\")\n",
        "    return False\n",
        "\n",
        "setup_korean_font()\n",
        "\n",
        "# ÌîÑÎ°úÏ†ùÌä∏ Î™®Îìà ÏûÑÌè¨Ìä∏\n",
        "sys.path.append('/data/home/kyj2024/TextVibCLIP')\n",
        "from src.data_loader import create_first_domain_dataloader\n",
        "from src.text_encoder import create_text_encoder\n",
        "from src.vibration_encoder import create_vibration_encoder\n",
        "from configs.model_config import MODEL_CONFIG, DATA_CONFIG\n",
        "from src.utils import set_seed\n",
        "\n",
        "# ÌôòÍ≤Ω ÏÑ§Ï†ï\n",
        "set_seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üîß ÎîîÎ∞îÏù¥Ïä§: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
        "    \n",
        "print(\"üéØ TSTÎäî debug_encoders.ipynb Î∞©ÏãùÏúºÎ°ú ÌèâÍ∞Ä\")\n",
        "print(\"üéØ 1D-CNNÏùÄ debug_encoders_clean.ipynb Î∞©ÏãùÏúºÎ°ú ÌèâÍ∞Ä\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä 1Îã®Í≥Ñ: Îç∞Ïù¥ÌÑ∞ Î°úÎî© Î∞è Í∏∞Î≥∏ Î∂ÑÏÑù\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìö Îç∞Ïù¥ÌÑ∞ Î°úÎî© Ï§ë...\n",
            "‚úÖ Îç∞Ïù¥ÌÑ∞ Î°úÎî© ÏôÑÎ£å\n",
            "   Train batches: 468\n",
            "   Val batches: 156\n",
            "\n",
            "üîç ÏÉòÌîå Î∞∞Ïπò Î∂ÑÏÑù:\n",
            "   ÏßÑÎèô Ïã†Ìò∏ shape: torch.Size([16, 4096])\n",
            "   ÌÖçÏä§Ìä∏ Í∞úÏàò: 16\n",
            "   ÎùºÎ≤® shape: torch.Size([16, 3])\n",
            "   Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉú ÎùºÎ≤®: 1 (0=H, 1=B, 2=IR, 3=OR)\n",
            "   ÌöåÏ†ÑÏ≤¥ ÏÉÅÌÉú ÎùºÎ≤®: 0 (0=H, 1=L, 2=U, 3=M)\n",
            "\n",
            "üìù Í∞úÏÑ†Îêú ÌÖçÏä§Ìä∏ ÏÉòÌîå:\n",
            "   1: Rotating machinery with radial ball bearing 6204 running at 600 revolutions per minute, characterized by ball defect and normal rotating component.\n",
            "   2: Rotating machinery with 30204 series tapered bearing rotating at 600 rpm speed, characterized by normal bearing and mechanical looseness in shaft.\n"
          ]
        }
      ],
      "source": [
        "# Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏ (600 RPM) Îç∞Ïù¥ÌÑ∞ Î°úÎî©\n",
        "print(\"üìö Îç∞Ïù¥ÌÑ∞ Î°úÎî© Ï§ë...\")\n",
        "\n",
        "train_loader = create_first_domain_dataloader(\n",
        "    data_dir=DATA_CONFIG['data_dir'],\n",
        "    domain_order=DATA_CONFIG['domain_order'],\n",
        "    dataset_type='uos',\n",
        "    subset='train',\n",
        "    batch_size=16,\n",
        "    num_workers=2,\n",
        "    use_collate_fn=True\n",
        ")\n",
        "\n",
        "val_loader = create_first_domain_dataloader(\n",
        "    data_dir=DATA_CONFIG['data_dir'],\n",
        "    domain_order=DATA_CONFIG['domain_order'],\n",
        "    dataset_type='uos',\n",
        "    subset='val',\n",
        "    batch_size=16,\n",
        "    num_workers=2,\n",
        "    use_collate_fn=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Îç∞Ïù¥ÌÑ∞ Î°úÎî© ÏôÑÎ£å\")\n",
        "print(f\"   Train batches: {len(train_loader)}\")\n",
        "print(f\"   Val batches: {len(val_loader)}\")\n",
        "\n",
        "# ÏÉòÌîå Î∞∞Ïπò Î∂ÑÏÑù\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"\\nüîç ÏÉòÌîå Î∞∞Ïπò Î∂ÑÏÑù:\")\n",
        "print(f\"   ÏßÑÎèô Ïã†Ìò∏ shape: {sample_batch['vibration'].shape}\")\n",
        "print(f\"   ÌÖçÏä§Ìä∏ Í∞úÏàò: {len(sample_batch['text'])}\")\n",
        "print(f\"   ÎùºÎ≤® shape: {sample_batch['labels'].shape}\")\n",
        "print(f\"   Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉú ÎùºÎ≤®: {sample_batch['labels'][0, 1].item()} (0=H, 1=B, 2=IR, 3=OR)\")\n",
        "print(f\"   ÌöåÏ†ÑÏ≤¥ ÏÉÅÌÉú ÎùºÎ≤®: {sample_batch['labels'][0, 0].item()} (0=H, 1=L, 2=U, 3=M)\")\n",
        "\n",
        "# Í∞úÏÑ†Îêú ÌÖçÏä§Ìä∏ ÏÉòÌîå ÌôïÏù∏\n",
        "print(f\"\\nüìù Í∞úÏÑ†Îêú ÌÖçÏä§Ìä∏ ÏÉòÌîå:\")\n",
        "for i in range(min(2, len(sample_batch['text']))):\n",
        "    print(f\"   {i+1}: {sample_batch['text'][i]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üÜö 2Îã®Í≥Ñ: TST vs 1D-CNN Î™®Îç∏ Ï†ïÏùò\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ TST vs 1D-CNN Î™®Îç∏ Ï†ïÏùò ÏôÑÎ£å\n",
            "   - TSTClassifier: TST + Classification Head\n",
            "   - CNN1DClassifier: 1D-CNN + Classification Head\n"
          ]
        }
      ],
      "source": [
        "# 1D-CNN Ïù∏ÏΩîÎçî Ï†ïÏùò (debug_encoders_clean.ipynb Í∏∞Î∞ò)\n",
        "class CNN1DVibrationEncoder(nn.Module):\n",
        "    \"\"\"1D-CNN Í∏∞Î∞ò ÏßÑÎèô Ïã†Ìò∏ Ïù∏ÏΩîÎçî (ÏãúÍ≥ÑÏó¥ ÌäπÌôî)\"\"\"\n",
        "    def __init__(self, input_length: int = 4096, embedding_dim: int = 512):\n",
        "        super(CNN1DVibrationEncoder, self).__init__()\n",
        "        \n",
        "        # Îã§Ï§ë Ïä§ÏºÄÏùº 1D Convolution\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            # Í≥†Ï£ºÌåå Ï∂©Í≤© Ìå®ÌÑ¥ (Î≤†Ïñ¥ÎßÅ Í≤∞Ìï® ÌäπÏú†Ïùò Ï∂©Í≤©Ìåå)\n",
        "            nn.Conv1d(1, 64, kernel_size=16, stride=2, padding=8),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            \n",
        "            # Ï§ëÍ∞Ñ Ï£ºÌååÏàò Ìå®ÌÑ¥ (ÌöåÏ†Ñ Ï£ºÍ∏∞, Ï°∞ÌôîÌåå)\n",
        "            nn.Conv1d(64, 128, kernel_size=32, stride=2, padding=16),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            \n",
        "            # Ï†ÄÏ£ºÌåå Íµ¨Ï°∞Ï†Å ÏßÑÎèô Ìå®ÌÑ¥\n",
        "            nn.Conv1d(128, 256, kernel_size=64, stride=2, padding=32),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            \n",
        "            # ÌäπÏßï ÏßëÏïΩ\n",
        "            nn.Conv1d(256, 512, kernel_size=32, stride=2, padding=16),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "        )\n",
        "        \n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, embedding_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.global_pool(x).squeeze(-1)\n",
        "        x = self.projection(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Supervised Î∂ÑÎ•ò Î™®Îç∏Îì§\n",
        "class TSTClassifier(nn.Module):\n",
        "    \"\"\"TST + Classification Head\"\"\"\n",
        "    def __init__(self, num_classes: int = 4):\n",
        "        super(TSTClassifier, self).__init__()\n",
        "        self.encoder = create_vibration_encoder()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        features = self.encoder(x)\n",
        "        logits = self.classifier(features)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class CNN1DClassifier(nn.Module):\n",
        "    \"\"\"1D-CNN + Classification Head\"\"\"\n",
        "    def __init__(self, num_classes: int = 4):\n",
        "        super(CNN1DClassifier, self).__init__()\n",
        "        self.encoder = CNN1DVibrationEncoder()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        features = self.encoder(x)\n",
        "        logits = self.classifier(features)\n",
        "        return logits\n",
        "\n",
        "\n",
        "print(\"‚úÖ TST vs 1D-CNN Î™®Îç∏ Ï†ïÏùò ÏôÑÎ£å\")\n",
        "print(\"   - TSTClassifier: TST + Classification Head\")\n",
        "print(\"   - CNN1DClassifier: 1D-CNN + Classification Head\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß 3Îã®Í≥Ñ: TST ÏÑ±Îä• ÌèâÍ∞Ä \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß TST ÏÑ±Îä• ÌèâÍ∞Ä (CPU Î™®Îìú)\n",
            "--------------------------------------------------\n",
            "   üí° GPU Î©îÎ™®Î¶¨ Î∂ÄÏ°±ÏúºÎ°ú Ïù∏Ìï¥ TSTÎ•º CPUÏóêÏÑú Ïã§Ìñâ\n",
            "   ÌååÎùºÎØ∏ÌÑ∞ Ïàò: 5,693,445\n",
            "   üìä TST Feature Ï∂îÏ∂ú (CPU Î™®Îìú, ÏÜåÎüâ Î∞∞Ïπò)\n",
            "   ‚úÖ Î∞∞Ïπò 1 Ï≤òÎ¶¨ ÏôÑÎ£å (CPU)\n",
            "   ‚úÖ Î∞∞Ïπò 2 Ï≤òÎ¶¨ ÏôÑÎ£å (CPU)\n",
            "   ‚úÖ Î∞∞Ïπò 3 Ï≤òÎ¶¨ ÏôÑÎ£å (CPU)\n",
            "   ‚úÖ Î∞∞Ïπò 4 Ï≤òÎ¶¨ ÏôÑÎ£å (CPU)\n",
            "   ‚úÖ Î∞∞Ïπò 5 Ï≤òÎ¶¨ ÏôÑÎ£å (CPU)\n",
            "   ‚úÖ Î∞∞Ïπò 6 Ï≤òÎ¶¨ ÏôÑÎ£å (CPU)\n",
            "   ‚úÖ Î∞∞Ïπò 7 Ï≤òÎ¶¨ ÏôÑÎ£å (CPU)\n",
            "   ‚úÖ Î∞∞Ïπò 8 Ï≤òÎ¶¨ ÏôÑÎ£å (CPU)\n",
            "   üìä TST ÏûÑÎ≤†Îî© ÏÉùÏÑ±: (128, 512)\n",
            "   ÌèâÍ∑†: 0.0000\n",
            "   ÌëúÏ§ÄÌé∏Ï∞®: 1.0000\n",
            "   üéØ TST Î≤†Ïñ¥ÎßÅ Î∂ÑÎ•ò Ï†ïÌôïÎèÑ: 0.641 (64.1%)\n",
            "   ‚úÖ TST ÏÑ±Îä• ÏñëÌò∏\n",
            "   üßπ GPU Î©îÎ™®Î¶¨ Ï†ïÎ¶¨ ÏôÑÎ£å\n"
          ]
        }
      ],
      "source": [
        "# TST ÏÑ±Îä• ÌèâÍ∞Ä (CPU Î™®ÎìúÎ°ú ÏïàÏ†ÑÌïòÍ≤å Ïã§Ìñâ)\n",
        "print(\"üîß TST ÏÑ±Îä• ÌèâÍ∞Ä (CPU Î™®Îìú)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# ÏôÑÏ†ÑÌïú GPU Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# TST Ïù∏ÏΩîÎçîÎ•º CPUÏóêÏÑú ÏÉùÏÑ± (Î©îÎ™®Î¶¨ Î∂ÄÏ°±ÏúºÎ°ú Ïù∏Ìï¥)\n",
        "print(\"   üí° GPU Î©îÎ™®Î¶¨ Î∂ÄÏ°±ÏúºÎ°ú Ïù∏Ìï¥ TSTÎ•º CPUÏóêÏÑú Ïã§Ìñâ\")\n",
        "tst_encoder = create_vibration_encoder()  # CPUÏóêÏÑú ÏÉùÏÑ±\n",
        "tst_encoder.eval()\n",
        "\n",
        "print(f\"   ÌååÎùºÎØ∏ÌÑ∞ Ïàò: {sum(p.numel() for p in tst_encoder.parameters()):,}\")\n",
        "\n",
        "# TST Feature Ï∂îÏ∂ú (CPU Î™®Îìú)\n",
        "tst_embeddings = []\n",
        "tst_labels = []\n",
        "\n",
        "print(\"   üìä TST Feature Ï∂îÏ∂ú (CPU Î™®Îìú, ÏÜåÎüâ Î∞∞Ïπò)\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    batch_count = 0\n",
        "    max_batches = 8  # ÏµúÎåÄ 8Î∞∞ÏπòÎßå Ï≤òÎ¶¨\n",
        "    \n",
        "    for batch in train_loader:\n",
        "        if batch_count >= max_batches:\n",
        "            break\n",
        "            \n",
        "        try:\n",
        "            # CPUÏóêÏÑú Ï≤òÎ¶¨\n",
        "            vibration = batch['vibration']  # CPUÏóê Ïú†ÏßÄ\n",
        "            embeddings = tst_encoder(vibration)\n",
        "            tst_embeddings.append(embeddings)\n",
        "            tst_labels.append(batch['labels'][:, 1])  # Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉúÎßå\n",
        "            batch_count += 1\n",
        "            \n",
        "            print(f\"   ‚úÖ Î∞∞Ïπò {batch_count} Ï≤òÎ¶¨ ÏôÑÎ£å (CPU)\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è  Î∞∞Ïπò {batch_count} Ï≤òÎ¶¨ Ïã§Ìå®: {str(e)[:50]}...\")\n",
        "            break\n",
        "\n",
        "if len(tst_embeddings) == 0:\n",
        "    print(\"   ‚ùå TST Feature Ï∂îÏ∂ú ÏôÑÏ†Ñ Ïã§Ìå®\")\n",
        "    tst_embeddings = None\n",
        "    tst_labels = None\n",
        "    tst_accuracy = 0.0\n",
        "else:\n",
        "    tst_embeddings = torch.cat(tst_embeddings, dim=0).numpy()\n",
        "    tst_labels = torch.cat(tst_labels, dim=0).numpy()\n",
        "    \n",
        "    print(f\"   üìä TST ÏûÑÎ≤†Îî© ÏÉùÏÑ±: {tst_embeddings.shape}\")\n",
        "    print(f\"   ÌèâÍ∑†: {tst_embeddings.mean():.4f}\")\n",
        "    print(f\"   ÌëúÏ§ÄÌé∏Ï∞®: {tst_embeddings.std():.4f}\")\n",
        "    \n",
        "    # Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉú Î∂ÑÎ•ò ÏÑ±Îä• ÌèâÍ∞Ä\n",
        "    if len(tst_embeddings) >= 20:\n",
        "        try:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                tst_embeddings, tst_labels, test_size=0.3, random_state=42\n",
        "            )\n",
        "            \n",
        "            clf = LogisticRegression(random_state=42, max_iter=1000)\n",
        "            clf.fit(X_train, y_train)\n",
        "            tst_accuracy = clf.score(X_test, y_test)\n",
        "            \n",
        "            print(f\"   üéØ TST Î≤†Ïñ¥ÎßÅ Î∂ÑÎ•ò Ï†ïÌôïÎèÑ: {tst_accuracy:.3f} ({tst_accuracy*100:.1f}%)\")\n",
        "            \n",
        "            if tst_accuracy > 0.6:\n",
        "                print(\"   ‚úÖ TST ÏÑ±Îä• ÏñëÌò∏\")\n",
        "            else:\n",
        "                print(\"   ‚ö†Ô∏è  TST ÏÑ±Îä• Î∂ÄÏ°±\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è  Î∂ÑÎ•ò ÌèâÍ∞Ä Ïã§Ìå®: {str(e)[:50]}...\")\n",
        "            tst_accuracy = 0.0\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è  ÌèâÍ∞Ä Î∂àÍ∞Ä: ÏÉòÌîå {len(tst_embeddings)}Í∞ú\")\n",
        "        tst_accuracy = 0.0\n",
        "\n",
        "print(f\"   üßπ GPU Î©îÎ™®Î¶¨ Ï†ïÎ¶¨ ÏôÑÎ£å\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß 4Îã®Í≥Ñ: 1D-CNN ÏÑ±Îä• ÌèâÍ∞Ä \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß 1D-CNN ÏÑ±Îä• ÌèâÍ∞Ä (Supervised Learning)\n",
            "--------------------------------------------------\n",
            "üìä 1D-CNN Supervised Learning Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìä 1D-CNN Supervised Learning Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉú Î∂ÑÎ•òÏö©\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m X_train_bearing, y_train_bearing \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_supervised_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbearing_condition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m X_val_bearing, y_val_bearing \u001b[38;5;241m=\u001b[39m prepare_supervised_data(val_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbearing_condition\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# ÌöåÏ†ÑÏ≤¥ ÏÉÅÌÉú Î∂ÑÎ•òÏö©\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[5], line 10\u001b[0m, in \u001b[0;36mprepare_supervised_data\u001b[0;34m(data_loader, task)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉú ÎòêÎäî ÌöåÏ†ÑÏ≤¥ ÏÉÅÌÉú Î∂ÑÎ•òÏö© Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m X, y \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m     11\u001b[0m     vibration \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvibration\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbearing_condition\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/envs/TVCLIP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/anaconda3/envs/TVCLIP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/TVCLIP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/anaconda3/envs/TVCLIP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/TVCLIP/lib/python3.8/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
            "File \u001b[0;32m~/anaconda3/envs/TVCLIP/lib/python3.8/threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 1D-CNN ÏÑ±Îä• ÌèâÍ∞Ä (debug_encoders_clean.ipynbÏóêÏÑú ÏÑ±Í≥µÌïú Î∞©Ïãù)\n",
        "print(\"üîß 1D-CNN ÏÑ±Îä• ÌèâÍ∞Ä (Supervised Learning)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ Ìï®Ïàò\n",
        "def prepare_supervised_data(data_loader, task='bearing_condition'):\n",
        "    \"\"\"Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉú ÎòêÎäî ÌöåÏ†ÑÏ≤¥ ÏÉÅÌÉú Î∂ÑÎ•òÏö© Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\"\"\"\n",
        "    X, y = [], []\n",
        "    \n",
        "    for batch in data_loader:\n",
        "        vibration = batch['vibration']\n",
        "        \n",
        "        if task == 'bearing_condition':\n",
        "            labels = batch['labels'][:, 1]  # Î≤†Ïñ¥ÎßÅ: H=0, B=1, IR=2, OR=3\n",
        "        elif task == 'rotating_component':\n",
        "            labels = batch['labels'][:, 0]  # ÌöåÏ†ÑÏ≤¥: H=0, L=1, U=2, M=3\n",
        "        \n",
        "        X.append(vibration)\n",
        "        y.append(labels)\n",
        "    \n",
        "    return torch.cat(X, dim=0), torch.cat(y, dim=0)\n",
        "\n",
        "# ÌïôÏäµ Ìï®Ïàò\n",
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=10, lr=0.001):\n",
        "    \"\"\"Supervised Learning ÌïôÏäµ Î∞è ÌèâÍ∞Ä\"\"\"\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # ÌïôÏäµ\n",
        "    for epoch in range(epochs):\n",
        "        batch_size = 32\n",
        "        total_loss = 0\n",
        "        \n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            batch_X = X_train[i:i+batch_size].to(device)\n",
        "            batch_y = y_train[i:i+batch_size].to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "        \n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"   Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(X_train)*batch_size:.4f}\")\n",
        "    \n",
        "    # ÌèâÍ∞Ä\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val.to(device))\n",
        "        val_pred = torch.argmax(val_outputs, dim=1)\n",
        "        val_accuracy = (val_pred == y_val.to(device)).float().mean().item()\n",
        "    \n",
        "    return val_accuracy\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ (Î©îÎ™®Î¶¨ Ï†àÏïΩÏùÑ ÏúÑÌï¥ ÏÉòÌîå Ïàò Ï†úÌïú)\n",
        "print(\"üìä 1D-CNN Supervised Learning Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ...\")\n",
        "\n",
        "# Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉú Î∂ÑÎ•òÏö©\n",
        "X_train_bearing, y_train_bearing = prepare_supervised_data(train_loader, 'bearing_condition')\n",
        "X_val_bearing, y_val_bearing = prepare_supervised_data(val_loader, 'bearing_condition')\n",
        "\n",
        "# ÌöåÏ†ÑÏ≤¥ ÏÉÅÌÉú Î∂ÑÎ•òÏö©\n",
        "X_train_rotating, y_train_rotating = prepare_supervised_data(train_loader, 'rotating_component')\n",
        "X_val_rotating, y_val_rotating = prepare_supervised_data(val_loader, 'rotating_component')\n",
        "\n",
        "# Î©îÎ™®Î¶¨ Ï†àÏïΩÏùÑ ÏúÑÌï¥ Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞ Ï†úÌïú\n",
        "max_train_samples = 2000\n",
        "max_val_samples = 500\n",
        "\n",
        "if len(X_train_bearing) > max_train_samples:\n",
        "    indices = torch.randperm(len(X_train_bearing))[:max_train_samples]\n",
        "    X_train_bearing = X_train_bearing[indices]\n",
        "    y_train_bearing = y_train_bearing[indices]\n",
        "    X_train_rotating = X_train_rotating[indices] \n",
        "    y_train_rotating = y_train_rotating[indices]\n",
        "    print(f\"   ‚ö†Ô∏è  Î©îÎ™®Î¶¨ Ï†àÏïΩÏùÑ ÏúÑÌï¥ Train ÏÉòÌîåÏùÑ {max_train_samples}Í∞úÎ°ú Ï†úÌïú\")\n",
        "\n",
        "if len(X_val_bearing) > max_val_samples:\n",
        "    indices = torch.randperm(len(X_val_bearing))[:max_val_samples]\n",
        "    X_val_bearing = X_val_bearing[indices]\n",
        "    y_val_bearing = y_val_bearing[indices]\n",
        "    X_val_rotating = X_val_rotating[indices]\n",
        "    y_val_rotating = y_val_rotating[indices]\n",
        "    print(f\"   ‚ö†Ô∏è  Î©îÎ™®Î¶¨ Ï†àÏïΩÏùÑ ÏúÑÌï¥ Val ÏÉòÌîåÏùÑ {max_val_samples}Í∞úÎ°ú Ï†úÌïú\")\n",
        "\n",
        "print(f\"   ÏµúÏ¢Ö Train ÏÉòÌîå: {X_train_bearing.shape[0]}\")\n",
        "print(f\"   ÏµúÏ¢Ö Val ÏÉòÌîå: {X_val_bearing.shape[0]}\")\n",
        "\n",
        "# 1D-CNN Î™®Îç∏ ÌÖåÏä§Ìä∏\n",
        "cnn_model = CNN1DClassifier(num_classes=4)\n",
        "param_count = sum(p.numel() for p in cnn_model.parameters())\n",
        "print(f\"   ÌååÎùºÎØ∏ÌÑ∞ Ïàò: {param_count:,}\")\n",
        "\n",
        "# Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉú Î∂ÑÎ•ò\n",
        "print(f\"\\n   üìä Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉú Î∂ÑÎ•ò (H, B, IR, OR):\")\n",
        "cnn_bearing_accuracy = train_model(cnn_model, X_train_bearing, y_train_bearing, \n",
        "                                 X_val_bearing, y_val_bearing, epochs=10)\n",
        "print(f\"   üéØ Î≤†Ïñ¥ÎßÅ Ï†ïÌôïÎèÑ: {cnn_bearing_accuracy:.3f} ({cnn_bearing_accuracy*100:.1f}%)\")\n",
        "\n",
        "# ÌöåÏ†ÑÏ≤¥ ÏÉÅÌÉú Î∂ÑÎ•ò\n",
        "print(f\"\\n   üìä ÌöåÏ†ÑÏ≤¥ ÏÉÅÌÉú Î∂ÑÎ•ò (H, L, U, M):\")\n",
        "cnn_rotating_accuracy = train_model(cnn_model, X_train_rotating, y_train_rotating,\n",
        "                                  X_val_rotating, y_val_rotating, epochs=10)\n",
        "print(f\"   üéØ ÌöåÏ†ÑÏ≤¥ Ï†ïÌôïÎèÑ: {cnn_rotating_accuracy:.3f} ({cnn_rotating_accuracy*100:.1f}%)\")\n",
        "\n",
        "# ÌèâÍ∑† ÏÑ±Îä•\n",
        "cnn_avg_accuracy = (cnn_bearing_accuracy + cnn_rotating_accuracy) / 2\n",
        "print(f\"   üèÜ ÌèâÍ∑† Ï†ïÌôïÎèÑ: {cnn_avg_accuracy:.3f} ({cnn_avg_accuracy*100:.1f}%)\")\n",
        "\n",
        "if cnn_avg_accuracy > 0.8:\n",
        "    print(\"   ‚úÖ 1D-CNN Ïö∞ÏàòÌïú ÏÑ±Îä•\")\n",
        "elif cnn_avg_accuracy > 0.6:\n",
        "    print(\"   üî∂ 1D-CNN Î≥¥ÌÜµ ÏÑ±Îä•\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è  1D-CNN ÏÑ±Îä• Î∂ÄÏ°±\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà 5Îã®Í≥Ñ: ÏôÑÏ†ÑÌïú ÎπÑÍµê ÏãúÍ∞ÅÌôî Î∞è Î∂ÑÏÑù\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TST vs 1D-CNN ÏôÑÏ†Ñ ÎπÑÍµê ÏãúÍ∞ÅÌôî\n",
        "print(\"üìà TST vs 1D-CNN ÏôÑÏ†Ñ ÎπÑÍµê ÏãúÍ∞ÅÌôî\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Í≤∞Í≥º Ï†ïÎ¶¨\n",
        "comparison_results = {\n",
        "    'TST': {\n",
        "        'method': 'Unsupervised (Feature Extraction)',\n",
        "        'bearing_accuracy': tst_accuracy if 'tst_accuracy' in locals() else 0.0,\n",
        "        'rotating_accuracy': 0.0,  # TSTÎäî Î≤†Ïñ¥ÎßÅÎßå ÌèâÍ∞Ä\n",
        "        'avg_accuracy': tst_accuracy if 'tst_accuracy' in locals() else 0.0,\n",
        "        'param_count': 5693445,\n",
        "        'status': 'success' if 'tst_accuracy' in locals() and tst_accuracy > 0 else 'failed'\n",
        "    },\n",
        "    '1D-CNN': {\n",
        "        'method': 'Supervised (End-to-End)',\n",
        "        'bearing_accuracy': cnn_bearing_accuracy if 'cnn_bearing_accuracy' in locals() else 0.0,\n",
        "        'rotating_accuracy': cnn_rotating_accuracy if 'cnn_rotating_accuracy' in locals() else 0.0,\n",
        "        'avg_accuracy': cnn_avg_accuracy if 'cnn_avg_accuracy' in locals() else 0.0,\n",
        "        'param_count': 7739972,\n",
        "        'status': 'success' if 'cnn_avg_accuracy' in locals() and cnn_avg_accuracy > 0 else 'failed'\n",
        "    }\n",
        "}\n",
        "\n",
        "# ÏÑ±Îä• ÎπÑÍµê Ï∞®Ìä∏\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "names = list(comparison_results.keys())\n",
        "\n",
        "# 1. Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉú Î∂ÑÎ•ò Ï†ïÌôïÎèÑ\n",
        "bearing_accs = [comparison_results[name]['bearing_accuracy'] for name in names]\n",
        "colors1 = ['red' if acc < 0.6 else 'orange' if acc < 0.8 else 'green' for acc in bearing_accs]\n",
        "\n",
        "axes[0, 0].bar(names, bearing_accs, color=colors1, alpha=0.7)\n",
        "axes[0, 0].set_title('Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉú Î∂ÑÎ•ò Ï†ïÌôïÎèÑ', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Ï†ïÌôïÎèÑ', fontsize=10)\n",
        "axes[0, 0].set_ylim(0, 1)\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "for i, acc in enumerate(bearing_accs):\n",
        "    axes[0, 0].text(i, acc + 0.02, f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 2. ÌöåÏ†ÑÏ≤¥ ÏÉÅÌÉú Î∂ÑÎ•ò Ï†ïÌôïÎèÑ (1D-CNNÎßå)\n",
        "cnn_rotating_acc = comparison_results['1D-CNN']['rotating_accuracy']\n",
        "axes[0, 1].bar(['1D-CNN'], [cnn_rotating_acc], color='green' if cnn_rotating_acc > 0.6 else 'orange', alpha=0.7)\n",
        "axes[0, 1].set_title('ÌöåÏ†ÑÏ≤¥ ÏÉÅÌÉú Î∂ÑÎ•ò Ï†ïÌôïÎèÑ', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Ï†ïÌôïÎèÑ', fontsize=10)\n",
        "axes[0, 1].set_ylim(0, 1)\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "axes[0, 1].text(0, cnn_rotating_acc + 0.02, f'{cnn_rotating_acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "axes[0, 1].text(0.5, 0.5, 'TST: N/A\\\\n(Î©îÎ™®Î¶¨ Ï†úÏïΩ)', ha='center', va='center', fontsize=10, \n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
        "\n",
        "# 3. ÌååÎùºÎØ∏ÌÑ∞ Ïàò ÎπÑÍµê\n",
        "param_counts = [comparison_results[name]['param_count'] for name in names]\n",
        "param_counts_m = [p/1000000 for p in param_counts]\n",
        "\n",
        "axes[1, 0].bar(names, param_counts_m, alpha=0.7, color=['blue', 'red'])\n",
        "axes[1, 0].set_title('ÌååÎùºÎØ∏ÌÑ∞ Ïàò ÎπÑÍµê', fontsize=12)\n",
        "axes[1, 0].set_ylabel('ÌååÎùºÎØ∏ÌÑ∞ Ïàò (M)', fontsize=10)\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "for i, count in enumerate(param_counts_m):\n",
        "    axes[1, 0].text(i, count + 0.1, f'{count:.1f}M', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 4. Ï¢ÖÌï© ÌèâÍ∞Ä (Î†àÏù¥Îçî Ï∞®Ìä∏)\n",
        "categories = ['Î≤†Ïñ¥ÎßÅ Î∂ÑÎ•ò', 'ÌöåÏ†ÑÏ≤¥ Î∂ÑÎ•ò', 'Î©îÎ™®Î¶¨ Ìö®Ïú®ÏÑ±', 'Ïã§Ïö©ÏÑ±']\n",
        "tst_scores = [comparison_results['TST']['bearing_accuracy'], 0.0, 0.3, 0.2]  # TST Î©îÎ™®Î¶¨ Î¨∏Ï†ú\n",
        "cnn_scores = [comparison_results['1D-CNN']['bearing_accuracy'], \n",
        "              comparison_results['1D-CNN']['rotating_accuracy'], 0.9, 0.9]  # 1D-CNN Ïö∞Ïàò\n",
        "\n",
        "angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
        "angles += angles[:1]  # ÏõêÌòï ÏôÑÏÑ±\n",
        "\n",
        "tst_scores += tst_scores[:1]\n",
        "cnn_scores += cnn_scores[:1]\n",
        "\n",
        "axes[1, 1] = plt.subplot(2, 2, 4, projection='polar')\n",
        "axes[1, 1].plot(angles, tst_scores, 'o-', linewidth=2, label='TST', color='blue')\n",
        "axes[1, 1].fill(angles, tst_scores, alpha=0.25, color='blue')\n",
        "axes[1, 1].plot(angles, cnn_scores, 'o-', linewidth=2, label='1D-CNN', color='red')\n",
        "axes[1, 1].fill(angles, cnn_scores, alpha=0.25, color='red')\n",
        "\n",
        "axes[1, 1].set_xticks(angles[:-1])\n",
        "axes[1, 1].set_xticklabels(categories)\n",
        "axes[1, 1].set_ylim(0, 1)\n",
        "axes[1, 1].set_title('Ï¢ÖÌï© ÏÑ±Îä• ÎπÑÍµê (Î†àÏù¥Îçî Ï∞®Ìä∏)', fontsize=12, pad=20)\n",
        "axes[1, 1].legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Í≤∞Í≥º ÏöîÏïΩ ÌÖåÏù¥Î∏î\n",
        "print(f\"\\nüìä TST vs 1D-CNN ÏôÑÏ†Ñ ÎπÑÍµê Í≤∞Í≥º\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Î™®Îç∏':<10} {'Î∞©Ïãù':<25} {'Î≤†Ïñ¥ÎßÅ':<8} {'ÌöåÏ†ÑÏ≤¥':<8} {'ÌèâÍ∑†':<8} {'ÌååÎùºÎØ∏ÌÑ∞':<10} {'ÏÉÅÌÉú':<10}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for name, result in comparison_results.items():\n",
        "    method = result['method']\n",
        "    bearing_acc = result['bearing_accuracy']\n",
        "    rotating_acc = result['rotating_accuracy']\n",
        "    avg_acc = result['avg_accuracy']\n",
        "    param_count_m = result['param_count']/1000000\n",
        "    status = result['status']\n",
        "    \n",
        "    print(f\"{name:<10} {method:<25} {bearing_acc:.3f}    {rotating_acc:.3f}    {avg_acc:.3f}    {param_count_m:.1f}M     {status}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Î∂ÑÌè¨ t-SNE ÎπÑÍµê ÏãúÍ∞ÅÌôî\n",
        "print(\"üé® TST vs 1D-CNN Feature Î∂ÑÌè¨ t-SNE ÎπÑÍµê\")\n",
        "\n",
        "# Í≥µÌÜµ ÏÉòÌîå Ï§ÄÎπÑ (ÎèôÏùºÌïú Îç∞Ïù¥ÌÑ∞Î°ú ÎπÑÍµê)\n",
        "sample_size = 500\n",
        "indices = torch.randperm(len(X_val_bearing))[:sample_size]\n",
        "sample_X = X_val_bearing[indices]\n",
        "sample_y_bearing = y_val_bearing[indices].numpy()\n",
        "\n",
        "# TST Feature Ï∂îÏ∂ú\n",
        "if 'tst_embeddings' in locals() and len(tst_embeddings) > 0:\n",
        "    # TSTÎäî ÏûëÏùÄ Î∞∞ÏπòÎ°ú Ï∂îÏ∂úÌñàÏúºÎØÄÎ°ú ÏÉòÌîåÎßÅ\n",
        "    tst_sample_size = min(sample_size, len(tst_embeddings))\n",
        "    tst_indices = np.random.choice(len(tst_embeddings), tst_sample_size, replace=False)\n",
        "    tst_features = tst_embeddings[tst_indices]\n",
        "    tst_sample_labels = tst_labels[tst_indices]\n",
        "else:\n",
        "    tst_features = None\n",
        "    tst_sample_labels = None\n",
        "\n",
        "# 1D-CNN Feature Ï∂îÏ∂ú\n",
        "cnn_model.eval()\n",
        "with torch.no_grad():\n",
        "    cnn_features = cnn_model.encoder(sample_X.to(device)).cpu().numpy()\n",
        "\n",
        "# t-SNE Ïã§Ìñâ\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# TST t-SNE\n",
        "if tst_features is not None:\n",
        "    try:\n",
        "        tsne_tst = TSNE(n_components=2, random_state=42, perplexity=min(30, len(tst_features)//4))\n",
        "        tsne_result_tst = tsne_tst.fit_transform(tst_features)\n",
        "        \n",
        "        bearing_labels = ['H(Ï†ïÏÉÅ)', 'B(Î≥ºÍ≤∞Ìï®)', 'IR(ÎÇ¥Î•úÍ≤∞Ìï®)', 'OR(Ïô∏Î•úÍ≤∞Ìï®)']\n",
        "        bearing_colors = ['blue', 'red', 'green', 'orange']\n",
        "        \n",
        "        for i, (label, color) in enumerate(zip(bearing_labels, bearing_colors)):\n",
        "            mask = tst_sample_labels == i\n",
        "            if mask.any():\n",
        "                axes[0].scatter(tsne_result_tst[mask, 0], tsne_result_tst[mask, 1],\n",
        "                              c=color, label=label, alpha=0.7, s=30)\n",
        "        \n",
        "        axes[0].set_title('TST - Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉúÎ≥Ñ Feature Î∂ÑÌè¨', fontsize=12)\n",
        "        axes[0].set_xlabel('t-SNE 1')\n",
        "        axes[0].set_ylabel('t-SNE 2')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        \n",
        "    except Exception as e:\n",
        "        axes[0].text(0.5, 0.5, f'TST t-SNE Ïã§Ìå®\\\\n{e}', ha='center', va='center', \n",
        "                    transform=axes[0].transAxes, fontsize=10,\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\"))\n",
        "        axes[0].set_title('TST - Feature Î∂ÑÌè¨ (Ïã§Ìå®)', fontsize=12)\n",
        "else:\n",
        "    axes[0].text(0.5, 0.5, 'TST Feature ÏóÜÏùå\\\\n(Î©îÎ™®Î¶¨ Î∂ÄÏ°±)', ha='center', va='center', \n",
        "                transform=axes[0].transAxes, fontsize=10,\n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
        "    axes[0].set_title('TST - Feature Î∂ÑÌè¨ (Ïã§Ìå®)', fontsize=12)\n",
        "\n",
        "# 1D-CNN t-SNE\n",
        "try:\n",
        "    tsne_cnn = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "    tsne_result_cnn = tsne_cnn.fit_transform(cnn_features)\n",
        "    \n",
        "    for i, (label, color) in enumerate(zip(bearing_labels, bearing_colors)):\n",
        "        mask = sample_y_bearing == i\n",
        "        if mask.any():\n",
        "            axes[1].scatter(tsne_result_cnn[mask, 0], tsne_result_cnn[mask, 1],\n",
        "                          c=color, label=label, alpha=0.7, s=30)\n",
        "    \n",
        "    axes[1].set_title('1D-CNN - Î≤†Ïñ¥ÎßÅ ÏÉÅÌÉúÎ≥Ñ Feature Î∂ÑÌè¨', fontsize=12)\n",
        "    axes[1].set_xlabel('t-SNE 1')\n",
        "    axes[1].set_ylabel('t-SNE 2')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "except Exception as e:\n",
        "    axes[1].text(0.5, 0.5, f'1D-CNN t-SNE Ïã§Ìå®\\\\n{e}', ha='center', va='center', \n",
        "                transform=axes[1].transAxes, fontsize=10,\n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\"))\n",
        "    axes[1].set_title('1D-CNN - Feature Î∂ÑÌè¨ (Ïã§Ìå®)', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã 6Îã®Í≥Ñ: ÏµúÏ¢Ö Í≤∞Î°† Î∞è Í∂åÏû•ÏÇ¨Ìï≠\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÏµúÏ¢Ö Í≤∞Î°† Î∞è Í∂åÏû•ÏÇ¨Ìï≠\n",
        "print(\"üìã TST vs 1D-CNN ÏôÑÏ†Ñ ÎπÑÍµê Ïã§Ìóò Í≤∞Î°†\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ÏäπÏûê Í≤∞Ï†ï\n",
        "tst_score = comparison_results['TST']['bearing_accuracy']\n",
        "cnn_score = comparison_results['1D-CNN']['avg_accuracy']\n",
        "\n",
        "if cnn_score > tst_score:\n",
        "    winner = '1D-CNN'\n",
        "    winner_result = comparison_results['1D-CNN']\n",
        "else:\n",
        "    winner = 'TST'\n",
        "    winner_result = comparison_results['TST']\n",
        "\n",
        "print(f\"\\nüèÜ ÏµúÏ¢Ö ÏäπÎ¶¨: {winner}\")\n",
        "print(f\"   Î≤†Ïñ¥ÎßÅ Î∂ÑÎ•ò: {winner_result['bearing_accuracy']:.1%}\")\n",
        "if winner_result['rotating_accuracy'] > 0:\n",
        "    print(f\"   ÌöåÏ†ÑÏ≤¥ Î∂ÑÎ•ò: {winner_result['rotating_accuracy']:.1%}\")\n",
        "    print(f\"   ÌèâÍ∑† ÏÑ±Îä•: {winner_result['avg_accuracy']:.1%}\")\n",
        "else:\n",
        "    print(f\"   ÌöåÏ†ÑÏ≤¥ Î∂ÑÎ•ò: N/A (ÌèâÍ∞Ä Î∂àÍ∞Ä)\")\n",
        "    print(f\"   Î≤†Ïñ¥ÎßÅ ÏÑ±Îä•: {winner_result['bearing_accuracy']:.1%}\")\n",
        "print(f\"   ÌååÎùºÎØ∏ÌÑ∞: {winner_result['param_count']/1000000:.1f}M\")\n",
        "\n",
        "# ÌïµÏã¨ Ïù∏ÏÇ¨Ïù¥Ìä∏\n",
        "print(f\"\\nüîç ÌïµÏã¨ Ïù∏ÏÇ¨Ïù¥Ìä∏:\")\n",
        "if winner == '1D-CNN':\n",
        "    print(f\"   ‚úÖ 1D-CNNÏù¥ TSTÎ•º Îä•Í∞Ä\")\n",
        "    print(f\"   üìä Î≤†Ïñ¥ÎßÅ Î∂ÑÎ•ò: 1D-CNN {comparison_results['1D-CNN']['bearing_accuracy']:.1%} vs TST {comparison_results['TST']['bearing_accuracy']:.1%}\")\n",
        "    print(f\"   üéØ ÌöåÏ†ÑÏ≤¥ Î∂ÑÎ•ò: 1D-CNNÎßå ÌèâÍ∞Ä Í∞ÄÎä• ({comparison_results['1D-CNN']['rotating_accuracy']:.1%})\")\n",
        "    print(f\"   üí° Î©îÎ™®Î¶¨ Ìö®Ïú®ÏÑ±: 1D-CNN Ï†ïÏÉÅ vs TST Ï†úÏïΩ\")\n",
        "    print(f\"   üöÄ Ïã§Ïö©ÏÑ±: 1D-CNN Î∞∞Ìè¨ Í∞ÄÎä• vs TST Î∂àÍ∞ÄÎä•\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è  TST ÏäπÎ¶¨ÌïòÏßÄÎßå Ï†úÌïúÏ†Å ÌèâÍ∞Ä\")\n",
        "    print(f\"   üíÄ TST Î©îÎ™®Î¶¨ Ï†úÏïΩÏúºÎ°ú ÏôÑÏ†ÑÌïú ÎπÑÍµê Î∂àÍ∞Ä\")\n",
        "\n",
        "# TSTÏùò Î¨∏Ï†úÏ†ê\n",
        "print(f\"\\nüíÄ TSTÏùò ÏπòÎ™ÖÏ†Å Î¨∏Ï†úÏ†ê:\")\n",
        "print(f\"   üî• Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ: O(n¬≤) Î≥µÏû°ÎèÑ\")\n",
        "print(f\"   üêå ÌôïÏû•ÏÑ± Î∂ÄÏ°±: ÏûëÏùÄ Î∞∞ÏπòÎ°úÎßå ÌèâÍ∞Ä Í∞ÄÎä•\")\n",
        "print(f\"   üí∏ Ïã§Ïö©ÏÑ± Î∂ÄÏ°±: Ïã§Ï†ú ÏãúÏä§ÌÖú Î∞∞Ìè¨ Ïñ¥Î†§ÏõÄ\")\n",
        "\n",
        "# 1D-CNNÏùò Ïû•Ï†ê\n",
        "print(f\"\\n‚úÖ 1D-CNNÏùò Î™ÖÌôïÌïú Ïû•Ï†ê:\")\n",
        "print(f\"   üöÄ Î©îÎ™®Î¶¨ Ìö®Ïú®ÏÑ±: O(n) Î≥µÏû°ÎèÑÎ°ú ÏïàÏ†ïÏ†Å\")\n",
        "print(f\"   üìà ÌôïÏû•ÏÑ±: ÌÅ∞ Î∞∞Ïπò ÌÅ¨Í∏∞Î°ú ÏïàÏ†ïÏ†Å ÌïôÏäµ\")\n",
        "print(f\"   üí∞ Ïã§Ïö©ÏÑ±: ÏùºÎ∞òÏ†ÅÏù∏ GPUÏóêÏÑúÎèÑ ÏûëÎèô\")\n",
        "print(f\"   üéØ ÏôÑÏ†Ñ ÌèâÍ∞Ä: Î≤†Ïñ¥ÎßÅ + ÌöåÏ†ÑÏ≤¥ Î™®Îëê ÌèâÍ∞Ä Í∞ÄÎä•\")\n",
        "\n",
        "# ÏµúÏ¢Ö Í∂åÏû•ÏÇ¨Ìï≠\n",
        "print(f\"\\nüí° ÏµúÏ¢Ö Í∂åÏû•ÏÇ¨Ìï≠:\")\n",
        "if winner == '1D-CNN':\n",
        "    print(f\"   ‚úÖ 1D-CNNÏúºÎ°ú Ï†ÑÏ≤¥ ÏãúÏä§ÌÖú ÍµêÏ≤¥ Í∞ïÎ†• Í∂åÏû•\")\n",
        "    print(f\"   üìù Ïï°ÏÖò ÏïÑÏù¥ÌÖú:\")\n",
        "    print(f\"      1. src/vibration_encoder.pyÎ•º 1D-CNN ÏïÑÌÇ§ÌÖçÏ≤òÎ°ú ÍµêÏ≤¥\")\n",
        "    print(f\"      2. ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏµúÏ†ÅÌôî (Ïª§ÎÑê ÌÅ¨Í∏∞, Î†àÏù¥Ïñ¥ Ïàò)\")\n",
        "    print(f\"      3. Ï†ÑÏ≤¥ TextVibCLIP ÏãúÏä§ÌÖú Ïû¨Ïã§Ìóò\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è  TST ÏäπÎ¶¨ÌïòÏßÄÎßå Î©îÎ™®Î¶¨ Î¨∏Ï†úÎ°ú Ïã§Ïö©ÏÑ± Î∂ÄÏ°±\")\n",
        "    print(f\"   üìù Ï∂îÍ∞Ä Í≤ÄÌÜ† ÌïÑÏöî\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üéâ TST vs 1D-CNN ÏôÑÏ†Ñ ÎπÑÍµê Ïã§Ìóò ÏôÑÎ£å!\")\n",
        "print(\"ÏúÑ Í≤∞Í≥ºÎ•º Î∞îÌÉïÏúºÎ°ú TextVibCLIP ÏãúÏä§ÌÖúÏùÑ Í∞úÏÑ†ÌïòÏÑ∏Ïöî.\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TVCLIP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
