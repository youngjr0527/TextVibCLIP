{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ” TST vs 1D-CNN ì™„ì „ ë¹„êµ ì‹¤í—˜\n",
        "\n",
        "## ëª©í‘œ\n",
        "1. **TST ì„±ëŠ¥ í‰ê°€** - debug_encoders.ipynb ê¸°ë°˜ (OOM ì—†ì´ ì„±ê³µ)\n",
        "2. **1D-CNN ì„±ëŠ¥ í‰ê°€** - debug_encoders_clean.ipynb ê¸°ë°˜ (Supervised Learning)\n",
        "3. **ì™„ì „í•œ ë¹„êµ ì‹œê°í™”** - t-SNE, ì„±ëŠ¥ ì°¨íŠ¸, ì¢…í•© ë¶„ì„\n",
        "4. **ìµœì¢… ê²°ë¡  ë„ì¶œ** - ì „ì²´ ì‹œìŠ¤í…œ ì ìš©ì„ ìœ„í•œ ëª…í™•í•œ ê·¼ê±°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… í•œê¸€ í°íŠ¸ ì„¤ì •: NanumGothic\n",
            "âœ… ì „ì—­ ì‹œë“œ ì„¤ì • ì™„ë£Œ: 42\n",
            "ğŸ”§ ë””ë°”ì´ìŠ¤: cuda\n",
            "   GPU: Quadro RTX 5000\n",
            "ğŸ¯ TSTëŠ” debug_encoders.ipynb ë°©ì‹ìœ¼ë¡œ í‰ê°€\n",
            "ğŸ¯ 1D-CNNì€ debug_encoders_clean.ipynb ë°©ì‹ìœ¼ë¡œ í‰ê°€\n"
          ]
        }
      ],
      "source": [
        "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í™˜ê²½ ì„¤ì •\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.manifold import TSNE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
        "def setup_korean_font():\n",
        "    font_paths = [\n",
        "        '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n",
        "        '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "    ]\n",
        "    \n",
        "    for path in font_paths:\n",
        "        if os.path.exists(path):\n",
        "            font_prop = fm.FontProperties(fname=path)\n",
        "            plt.rcParams['font.family'] = font_prop.get_name()\n",
        "            plt.rcParams['axes.unicode_minus'] = False\n",
        "            print(f\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì •: {font_prop.get_name()}\")\n",
        "            return True\n",
        "    \n",
        "    print(\"âš ï¸  í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    return False\n",
        "\n",
        "setup_korean_font()\n",
        "\n",
        "# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸\n",
        "sys.path.append('/data/home/kyj2024/TextVibCLIP')\n",
        "from src.data_loader import create_first_domain_dataloader\n",
        "from src.text_encoder import create_text_encoder\n",
        "from src.vibration_encoder import create_vibration_encoder\n",
        "from configs.model_config import MODEL_CONFIG, DATA_CONFIG\n",
        "from src.utils import set_seed\n",
        "\n",
        "# í™˜ê²½ ì„¤ì •\n",
        "set_seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ğŸ”§ ë””ë°”ì´ìŠ¤: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
        "    \n",
        "print(\"ğŸ¯ TSTëŠ” debug_encoders.ipynb ë°©ì‹ìœ¼ë¡œ í‰ê°€\")\n",
        "print(\"ğŸ¯ 1D-CNNì€ debug_encoders_clean.ipynb ë°©ì‹ìœ¼ë¡œ í‰ê°€\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š 1ë‹¨ê³„: ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“š ë°ì´í„° ë¡œë”© ì¤‘...\n",
            "âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ\n",
            "   Train batches: 468\n",
            "   Val batches: 156\n",
            "\n",
            "ğŸ” ìƒ˜í”Œ ë°°ì¹˜ ë¶„ì„:\n",
            "   ì§„ë™ ì‹ í˜¸ shape: torch.Size([16, 4096])\n",
            "   í…ìŠ¤íŠ¸ ê°œìˆ˜: 16\n",
            "   ë¼ë²¨ shape: torch.Size([16, 3])\n",
            "   ë² ì–´ë§ ìƒíƒœ ë¼ë²¨: 1 (0=H, 1=B, 2=IR, 3=OR)\n",
            "   íšŒì „ì²´ ìƒíƒœ ë¼ë²¨: 0 (0=H, 1=L, 2=U, 3=M)\n",
            "\n",
            "ğŸ“ ê°œì„ ëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ:\n",
            "   1: Rotating machinery with radial ball bearing 6204 running at 600 revolutions per minute, characterized by ball defect and normal rotating component.\n",
            "   2: Rotating machinery with 30204 series tapered bearing rotating at 600 rpm speed, characterized by normal bearing and mechanical looseness in shaft.\n"
          ]
        }
      ],
      "source": [
        "# ì²« ë²ˆì§¸ ë„ë©”ì¸ (600 RPM) ë°ì´í„° ë¡œë”©\n",
        "print(\"ğŸ“š ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
        "\n",
        "train_loader = create_first_domain_dataloader(\n",
        "    data_dir=DATA_CONFIG['data_dir'],\n",
        "    domain_order=DATA_CONFIG['domain_order'],\n",
        "    dataset_type='uos',\n",
        "    subset='train',\n",
        "    batch_size=16,\n",
        "    num_workers=2,\n",
        "    use_collate_fn=True\n",
        ")\n",
        "\n",
        "val_loader = create_first_domain_dataloader(\n",
        "    data_dir=DATA_CONFIG['data_dir'],\n",
        "    domain_order=DATA_CONFIG['domain_order'],\n",
        "    dataset_type='uos',\n",
        "    subset='val',\n",
        "    batch_size=16,\n",
        "    num_workers=2,\n",
        "    use_collate_fn=True\n",
        ")\n",
        "\n",
        "print(f\"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ\")\n",
        "print(f\"   Train batches: {len(train_loader)}\")\n",
        "print(f\"   Val batches: {len(val_loader)}\")\n",
        "\n",
        "# ìƒ˜í”Œ ë°°ì¹˜ ë¶„ì„\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"\\nğŸ” ìƒ˜í”Œ ë°°ì¹˜ ë¶„ì„:\")\n",
        "print(f\"   ì§„ë™ ì‹ í˜¸ shape: {sample_batch['vibration'].shape}\")\n",
        "print(f\"   í…ìŠ¤íŠ¸ ê°œìˆ˜: {len(sample_batch['text'])}\")\n",
        "print(f\"   ë¼ë²¨ shape: {sample_batch['labels'].shape}\")\n",
        "print(f\"   ë² ì–´ë§ ìƒíƒœ ë¼ë²¨: {sample_batch['labels'][0, 1].item()} (0=H, 1=B, 2=IR, 3=OR)\")\n",
        "print(f\"   íšŒì „ì²´ ìƒíƒœ ë¼ë²¨: {sample_batch['labels'][0, 0].item()} (0=H, 1=L, 2=U, 3=M)\")\n",
        "\n",
        "# ê°œì„ ëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ í™•ì¸\n",
        "print(f\"\\nğŸ“ ê°œì„ ëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ:\")\n",
        "for i in range(min(2, len(sample_batch['text']))):\n",
        "    print(f\"   {i+1}: {sample_batch['text'][i]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ†š 2ë‹¨ê³„: TST vs 1D-CNN ëª¨ë¸ ì •ì˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… TST vs 1D-CNN ëª¨ë¸ ì •ì˜ ì™„ë£Œ\n",
            "   - TSTClassifier: TST + Classification Head\n",
            "   - CNN1DClassifier: 1D-CNN + Classification Head\n"
          ]
        }
      ],
      "source": [
        "# 1D-CNN ì¸ì½”ë” ì •ì˜ (debug_encoders_clean.ipynb ê¸°ë°˜)\n",
        "class CNN1DVibrationEncoder(nn.Module):\n",
        "    \"\"\"1D-CNN ê¸°ë°˜ ì§„ë™ ì‹ í˜¸ ì¸ì½”ë” (ì‹œê³„ì—´ íŠ¹í™”)\"\"\"\n",
        "    def __init__(self, input_length: int = 4096, embedding_dim: int = 512):\n",
        "        super(CNN1DVibrationEncoder, self).__init__()\n",
        "        \n",
        "        # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ 1D Convolution\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            # ê³ ì£¼íŒŒ ì¶©ê²© íŒ¨í„´ (ë² ì–´ë§ ê²°í•¨ íŠ¹ìœ ì˜ ì¶©ê²©íŒŒ)\n",
        "            nn.Conv1d(1, 64, kernel_size=16, stride=2, padding=8),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            \n",
        "            # ì¤‘ê°„ ì£¼íŒŒìˆ˜ íŒ¨í„´ (íšŒì „ ì£¼ê¸°, ì¡°í™”íŒŒ)\n",
        "            nn.Conv1d(64, 128, kernel_size=32, stride=2, padding=16),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            \n",
        "            # ì €ì£¼íŒŒ êµ¬ì¡°ì  ì§„ë™ íŒ¨í„´\n",
        "            nn.Conv1d(128, 256, kernel_size=64, stride=2, padding=32),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            \n",
        "            # íŠ¹ì§• ì§‘ì•½\n",
        "            nn.Conv1d(256, 512, kernel_size=32, stride=2, padding=16),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "        )\n",
        "        \n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, embedding_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.global_pool(x).squeeze(-1)\n",
        "        x = self.projection(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Supervised ë¶„ë¥˜ ëª¨ë¸ë“¤\n",
        "class TSTClassifier(nn.Module):\n",
        "    \"\"\"TST + Classification Head\"\"\"\n",
        "    def __init__(self, num_classes: int = 4):\n",
        "        super(TSTClassifier, self).__init__()\n",
        "        self.encoder = create_vibration_encoder()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        features = self.encoder(x)\n",
        "        logits = self.classifier(features)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class CNN1DClassifier(nn.Module):\n",
        "    \"\"\"1D-CNN + Classification Head\"\"\"\n",
        "    def __init__(self, num_classes: int = 4):\n",
        "        super(CNN1DClassifier, self).__init__()\n",
        "        self.encoder = CNN1DVibrationEncoder()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        features = self.encoder(x)\n",
        "        logits = self.classifier(features)\n",
        "        return logits\n",
        "\n",
        "\n",
        "print(\"âœ… TST vs 1D-CNN ëª¨ë¸ ì •ì˜ ì™„ë£Œ\")\n",
        "print(\"   - TSTClassifier: TST + Classification Head\")\n",
        "print(\"   - CNN1DClassifier: 1D-CNN + Classification Head\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ 3ë‹¨ê³„: TST ì„±ëŠ¥ í‰ê°€ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ TST ì„±ëŠ¥ í‰ê°€ (CPU ëª¨ë“œ)\n",
            "--------------------------------------------------\n",
            "   ğŸ’¡ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ TSTë¥¼ CPUì—ì„œ ì‹¤í–‰\n",
            "   íŒŒë¼ë¯¸í„° ìˆ˜: 5,693,445\n",
            "   ğŸ“Š TST Feature ì¶”ì¶œ (CPU ëª¨ë“œ, ì†ŒëŸ‰ ë°°ì¹˜)\n",
            "   âœ… ë°°ì¹˜ 1 ì²˜ë¦¬ ì™„ë£Œ (CPU)\n",
            "   âœ… ë°°ì¹˜ 2 ì²˜ë¦¬ ì™„ë£Œ (CPU)\n",
            "   âœ… ë°°ì¹˜ 3 ì²˜ë¦¬ ì™„ë£Œ (CPU)\n",
            "   âœ… ë°°ì¹˜ 4 ì²˜ë¦¬ ì™„ë£Œ (CPU)\n",
            "   âœ… ë°°ì¹˜ 5 ì²˜ë¦¬ ì™„ë£Œ (CPU)\n",
            "   âœ… ë°°ì¹˜ 6 ì²˜ë¦¬ ì™„ë£Œ (CPU)\n",
            "   âœ… ë°°ì¹˜ 7 ì²˜ë¦¬ ì™„ë£Œ (CPU)\n",
            "   âœ… ë°°ì¹˜ 8 ì²˜ë¦¬ ì™„ë£Œ (CPU)\n",
            "   ğŸ“Š TST ì„ë² ë”© ìƒì„±: (128, 512)\n",
            "   í‰ê· : 0.0000\n",
            "   í‘œì¤€í¸ì°¨: 1.0000\n",
            "   ğŸ¯ TST ë² ì–´ë§ ë¶„ë¥˜ ì •í™•ë„: 0.641 (64.1%)\n",
            "   âœ… TST ì„±ëŠ¥ ì–‘í˜¸\n",
            "   ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# TST ì„±ëŠ¥ í‰ê°€ (CPU ëª¨ë“œë¡œ ì•ˆì „í•˜ê²Œ ì‹¤í–‰)\n",
        "print(\"ğŸ”§ TST ì„±ëŠ¥ í‰ê°€ (CPU ëª¨ë“œ)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# ì™„ì „í•œ GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# TST ì¸ì½”ë”ë¥¼ CPUì—ì„œ ìƒì„± (ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´)\n",
        "print(\"   ğŸ’¡ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ TSTë¥¼ CPUì—ì„œ ì‹¤í–‰\")\n",
        "tst_encoder = create_vibration_encoder()  # CPUì—ì„œ ìƒì„±\n",
        "tst_encoder.eval()\n",
        "\n",
        "print(f\"   íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in tst_encoder.parameters()):,}\")\n",
        "\n",
        "# TST Feature ì¶”ì¶œ (CPU ëª¨ë“œ)\n",
        "tst_embeddings = []\n",
        "tst_labels = []\n",
        "\n",
        "print(\"   ğŸ“Š TST Feature ì¶”ì¶œ (CPU ëª¨ë“œ, ì†ŒëŸ‰ ë°°ì¹˜)\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    batch_count = 0\n",
        "    max_batches = 8  # ìµœëŒ€ 8ë°°ì¹˜ë§Œ ì²˜ë¦¬\n",
        "    \n",
        "    for batch in train_loader:\n",
        "        if batch_count >= max_batches:\n",
        "            break\n",
        "            \n",
        "        try:\n",
        "            # CPUì—ì„œ ì²˜ë¦¬\n",
        "            vibration = batch['vibration']  # CPUì— ìœ ì§€\n",
        "            embeddings = tst_encoder(vibration)\n",
        "            tst_embeddings.append(embeddings)\n",
        "            tst_labels.append(batch['labels'][:, 1])  # ë² ì–´ë§ ìƒíƒœë§Œ\n",
        "            batch_count += 1\n",
        "            \n",
        "            print(f\"   âœ… ë°°ì¹˜ {batch_count} ì²˜ë¦¬ ì™„ë£Œ (CPU)\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸  ë°°ì¹˜ {batch_count} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)[:50]}...\")\n",
        "            break\n",
        "\n",
        "if len(tst_embeddings) == 0:\n",
        "    print(\"   âŒ TST Feature ì¶”ì¶œ ì™„ì „ ì‹¤íŒ¨\")\n",
        "    tst_embeddings = None\n",
        "    tst_labels = None\n",
        "    tst_accuracy = 0.0\n",
        "else:\n",
        "    tst_embeddings = torch.cat(tst_embeddings, dim=0).numpy()\n",
        "    tst_labels = torch.cat(tst_labels, dim=0).numpy()\n",
        "    \n",
        "    print(f\"   ğŸ“Š TST ì„ë² ë”© ìƒì„±: {tst_embeddings.shape}\")\n",
        "    print(f\"   í‰ê· : {tst_embeddings.mean():.4f}\")\n",
        "    print(f\"   í‘œì¤€í¸ì°¨: {tst_embeddings.std():.4f}\")\n",
        "    \n",
        "    # ë² ì–´ë§ ìƒíƒœ ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€\n",
        "    if len(tst_embeddings) >= 20:\n",
        "        try:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                tst_embeddings, tst_labels, test_size=0.3, random_state=42\n",
        "            )\n",
        "            \n",
        "            clf = LogisticRegression(random_state=42, max_iter=1000)\n",
        "            clf.fit(X_train, y_train)\n",
        "            tst_accuracy = clf.score(X_test, y_test)\n",
        "            \n",
        "            print(f\"   ğŸ¯ TST ë² ì–´ë§ ë¶„ë¥˜ ì •í™•ë„: {tst_accuracy:.3f} ({tst_accuracy*100:.1f}%)\")\n",
        "            \n",
        "            if tst_accuracy > 0.6:\n",
        "                print(\"   âœ… TST ì„±ëŠ¥ ì–‘í˜¸\")\n",
        "            else:\n",
        "                print(\"   âš ï¸  TST ì„±ëŠ¥ ë¶€ì¡±\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸  ë¶„ë¥˜ í‰ê°€ ì‹¤íŒ¨: {str(e)[:50]}...\")\n",
        "            tst_accuracy = 0.0\n",
        "    else:\n",
        "        print(f\"   âš ï¸  í‰ê°€ ë¶ˆê°€: ìƒ˜í”Œ {len(tst_embeddings)}ê°œ\")\n",
        "        tst_accuracy = 0.0\n",
        "\n",
        "print(f\"   ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ 4ë‹¨ê³„: 1D-CNN ì„±ëŠ¥ í‰ê°€ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ 1D-CNN ì„±ëŠ¥ í‰ê°€ (Supervised Learning)\n",
            "--------------------------------------------------\n",
            "ğŸ“Š 1D-CNN Supervised Learning ë°ì´í„° ì¤€ë¹„...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“Š 1D-CNN Supervised Learning ë°ì´í„° ì¤€ë¹„...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# ë² ì–´ë§ ìƒíƒœ ë¶„ë¥˜ìš©\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m X_train_bearing, y_train_bearing \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_supervised_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbearing_condition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m X_val_bearing, y_val_bearing \u001b[38;5;241m=\u001b[39m prepare_supervised_data(val_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbearing_condition\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# íšŒì „ì²´ ìƒíƒœ ë¶„ë¥˜ìš©\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[5], line 10\u001b[0m, in \u001b[0;36mprepare_supervised_data\u001b[0;34m(data_loader, task)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"ë² ì–´ë§ ìƒíƒœ ë˜ëŠ” íšŒì „ì²´ ìƒíƒœ ë¶„ë¥˜ìš© ë°ì´í„° ì¤€ë¹„\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m X, y \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m     11\u001b[0m     vibration \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvibration\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbearing_condition\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/envs/TVCLIP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/anaconda3/envs/TVCLIP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/TVCLIP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/anaconda3/envs/TVCLIP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/TVCLIP/lib/python3.8/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
            "File \u001b[0;32m~/anaconda3/envs/TVCLIP/lib/python3.8/threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 1D-CNN ì„±ëŠ¥ í‰ê°€ (debug_encoders_clean.ipynbì—ì„œ ì„±ê³µí•œ ë°©ì‹)\n",
        "print(\"ğŸ”§ 1D-CNN ì„±ëŠ¥ í‰ê°€ (Supervised Learning)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# ë°ì´í„° ì¤€ë¹„ í•¨ìˆ˜\n",
        "def prepare_supervised_data(data_loader, task='bearing_condition'):\n",
        "    \"\"\"ë² ì–´ë§ ìƒíƒœ ë˜ëŠ” íšŒì „ì²´ ìƒíƒœ ë¶„ë¥˜ìš© ë°ì´í„° ì¤€ë¹„\"\"\"\n",
        "    X, y = [], []\n",
        "    \n",
        "    for batch in data_loader:\n",
        "        vibration = batch['vibration']\n",
        "        \n",
        "        if task == 'bearing_condition':\n",
        "            labels = batch['labels'][:, 1]  # ë² ì–´ë§: H=0, B=1, IR=2, OR=3\n",
        "        elif task == 'rotating_component':\n",
        "            labels = batch['labels'][:, 0]  # íšŒì „ì²´: H=0, L=1, U=2, M=3\n",
        "        \n",
        "        X.append(vibration)\n",
        "        y.append(labels)\n",
        "    \n",
        "    return torch.cat(X, dim=0), torch.cat(y, dim=0)\n",
        "\n",
        "# í•™ìŠµ í•¨ìˆ˜\n",
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=10, lr=0.001):\n",
        "    \"\"\"Supervised Learning í•™ìŠµ ë° í‰ê°€\"\"\"\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # í•™ìŠµ\n",
        "    for epoch in range(epochs):\n",
        "        batch_size = 32\n",
        "        total_loss = 0\n",
        "        \n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            batch_X = X_train[i:i+batch_size].to(device)\n",
        "            batch_y = y_train[i:i+batch_size].to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "        \n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"   Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(X_train)*batch_size:.4f}\")\n",
        "    \n",
        "    # í‰ê°€\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val.to(device))\n",
        "        val_pred = torch.argmax(val_outputs, dim=1)\n",
        "        val_accuracy = (val_pred == y_val.to(device)).float().mean().item()\n",
        "    \n",
        "    return val_accuracy\n",
        "\n",
        "# ë°ì´í„° ì¤€ë¹„ (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ìƒ˜í”Œ ìˆ˜ ì œí•œ)\n",
        "print(\"ğŸ“Š 1D-CNN Supervised Learning ë°ì´í„° ì¤€ë¹„...\")\n",
        "\n",
        "# ë² ì–´ë§ ìƒíƒœ ë¶„ë¥˜ìš©\n",
        "X_train_bearing, y_train_bearing = prepare_supervised_data(train_loader, 'bearing_condition')\n",
        "X_val_bearing, y_val_bearing = prepare_supervised_data(val_loader, 'bearing_condition')\n",
        "\n",
        "# íšŒì „ì²´ ìƒíƒœ ë¶„ë¥˜ìš©\n",
        "X_train_rotating, y_train_rotating = prepare_supervised_data(train_loader, 'rotating_component')\n",
        "X_val_rotating, y_val_rotating = prepare_supervised_data(val_loader, 'rotating_component')\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ë°ì´í„° í¬ê¸° ì œí•œ\n",
        "max_train_samples = 2000\n",
        "max_val_samples = 500\n",
        "\n",
        "if len(X_train_bearing) > max_train_samples:\n",
        "    indices = torch.randperm(len(X_train_bearing))[:max_train_samples]\n",
        "    X_train_bearing = X_train_bearing[indices]\n",
        "    y_train_bearing = y_train_bearing[indices]\n",
        "    X_train_rotating = X_train_rotating[indices] \n",
        "    y_train_rotating = y_train_rotating[indices]\n",
        "    print(f\"   âš ï¸  ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ Train ìƒ˜í”Œì„ {max_train_samples}ê°œë¡œ ì œí•œ\")\n",
        "\n",
        "if len(X_val_bearing) > max_val_samples:\n",
        "    indices = torch.randperm(len(X_val_bearing))[:max_val_samples]\n",
        "    X_val_bearing = X_val_bearing[indices]\n",
        "    y_val_bearing = y_val_bearing[indices]\n",
        "    X_val_rotating = X_val_rotating[indices]\n",
        "    y_val_rotating = y_val_rotating[indices]\n",
        "    print(f\"   âš ï¸  ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ Val ìƒ˜í”Œì„ {max_val_samples}ê°œë¡œ ì œí•œ\")\n",
        "\n",
        "print(f\"   ìµœì¢… Train ìƒ˜í”Œ: {X_train_bearing.shape[0]}\")\n",
        "print(f\"   ìµœì¢… Val ìƒ˜í”Œ: {X_val_bearing.shape[0]}\")\n",
        "\n",
        "# 1D-CNN ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
        "cnn_model = CNN1DClassifier(num_classes=4)\n",
        "param_count = sum(p.numel() for p in cnn_model.parameters())\n",
        "print(f\"   íŒŒë¼ë¯¸í„° ìˆ˜: {param_count:,}\")\n",
        "\n",
        "# ë² ì–´ë§ ìƒíƒœ ë¶„ë¥˜\n",
        "print(f\"\\n   ğŸ“Š ë² ì–´ë§ ìƒíƒœ ë¶„ë¥˜ (H, B, IR, OR):\")\n",
        "cnn_bearing_accuracy = train_model(cnn_model, X_train_bearing, y_train_bearing, \n",
        "                                 X_val_bearing, y_val_bearing, epochs=10)\n",
        "print(f\"   ğŸ¯ ë² ì–´ë§ ì •í™•ë„: {cnn_bearing_accuracy:.3f} ({cnn_bearing_accuracy*100:.1f}%)\")\n",
        "\n",
        "# íšŒì „ì²´ ìƒíƒœ ë¶„ë¥˜\n",
        "print(f\"\\n   ğŸ“Š íšŒì „ì²´ ìƒíƒœ ë¶„ë¥˜ (H, L, U, M):\")\n",
        "cnn_rotating_accuracy = train_model(cnn_model, X_train_rotating, y_train_rotating,\n",
        "                                  X_val_rotating, y_val_rotating, epochs=10)\n",
        "print(f\"   ğŸ¯ íšŒì „ì²´ ì •í™•ë„: {cnn_rotating_accuracy:.3f} ({cnn_rotating_accuracy*100:.1f}%)\")\n",
        "\n",
        "# í‰ê·  ì„±ëŠ¥\n",
        "cnn_avg_accuracy = (cnn_bearing_accuracy + cnn_rotating_accuracy) / 2\n",
        "print(f\"   ğŸ† í‰ê·  ì •í™•ë„: {cnn_avg_accuracy:.3f} ({cnn_avg_accuracy*100:.1f}%)\")\n",
        "\n",
        "if cnn_avg_accuracy > 0.8:\n",
        "    print(\"   âœ… 1D-CNN ìš°ìˆ˜í•œ ì„±ëŠ¥\")\n",
        "elif cnn_avg_accuracy > 0.6:\n",
        "    print(\"   ğŸ”¶ 1D-CNN ë³´í†µ ì„±ëŠ¥\")\n",
        "else:\n",
        "    print(\"   âš ï¸  1D-CNN ì„±ëŠ¥ ë¶€ì¡±\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ˆ 5ë‹¨ê³„: ì™„ì „í•œ ë¹„êµ ì‹œê°í™” ë° ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TST vs 1D-CNN ì™„ì „ ë¹„êµ ì‹œê°í™”\n",
        "print(\"ğŸ“ˆ TST vs 1D-CNN ì™„ì „ ë¹„êµ ì‹œê°í™”\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ê²°ê³¼ ì •ë¦¬\n",
        "comparison_results = {\n",
        "    'TST': {\n",
        "        'method': 'Unsupervised (Feature Extraction)',\n",
        "        'bearing_accuracy': tst_accuracy if 'tst_accuracy' in locals() else 0.0,\n",
        "        'rotating_accuracy': 0.0,  # TSTëŠ” ë² ì–´ë§ë§Œ í‰ê°€\n",
        "        'avg_accuracy': tst_accuracy if 'tst_accuracy' in locals() else 0.0,\n",
        "        'param_count': 5693445,\n",
        "        'status': 'success' if 'tst_accuracy' in locals() and tst_accuracy > 0 else 'failed'\n",
        "    },\n",
        "    '1D-CNN': {\n",
        "        'method': 'Supervised (End-to-End)',\n",
        "        'bearing_accuracy': cnn_bearing_accuracy if 'cnn_bearing_accuracy' in locals() else 0.0,\n",
        "        'rotating_accuracy': cnn_rotating_accuracy if 'cnn_rotating_accuracy' in locals() else 0.0,\n",
        "        'avg_accuracy': cnn_avg_accuracy if 'cnn_avg_accuracy' in locals() else 0.0,\n",
        "        'param_count': 7739972,\n",
        "        'status': 'success' if 'cnn_avg_accuracy' in locals() and cnn_avg_accuracy > 0 else 'failed'\n",
        "    }\n",
        "}\n",
        "\n",
        "# ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "names = list(comparison_results.keys())\n",
        "\n",
        "# 1. ë² ì–´ë§ ìƒíƒœ ë¶„ë¥˜ ì •í™•ë„\n",
        "bearing_accs = [comparison_results[name]['bearing_accuracy'] for name in names]\n",
        "colors1 = ['red' if acc < 0.6 else 'orange' if acc < 0.8 else 'green' for acc in bearing_accs]\n",
        "\n",
        "axes[0, 0].bar(names, bearing_accs, color=colors1, alpha=0.7)\n",
        "axes[0, 0].set_title('ë² ì–´ë§ ìƒíƒœ ë¶„ë¥˜ ì •í™•ë„', fontsize=12)\n",
        "axes[0, 0].set_ylabel('ì •í™•ë„', fontsize=10)\n",
        "axes[0, 0].set_ylim(0, 1)\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "for i, acc in enumerate(bearing_accs):\n",
        "    axes[0, 0].text(i, acc + 0.02, f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 2. íšŒì „ì²´ ìƒíƒœ ë¶„ë¥˜ ì •í™•ë„ (1D-CNNë§Œ)\n",
        "cnn_rotating_acc = comparison_results['1D-CNN']['rotating_accuracy']\n",
        "axes[0, 1].bar(['1D-CNN'], [cnn_rotating_acc], color='green' if cnn_rotating_acc > 0.6 else 'orange', alpha=0.7)\n",
        "axes[0, 1].set_title('íšŒì „ì²´ ìƒíƒœ ë¶„ë¥˜ ì •í™•ë„', fontsize=12)\n",
        "axes[0, 1].set_ylabel('ì •í™•ë„', fontsize=10)\n",
        "axes[0, 1].set_ylim(0, 1)\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "axes[0, 1].text(0, cnn_rotating_acc + 0.02, f'{cnn_rotating_acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "axes[0, 1].text(0.5, 0.5, 'TST: N/A\\\\n(ë©”ëª¨ë¦¬ ì œì•½)', ha='center', va='center', fontsize=10, \n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
        "\n",
        "# 3. íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ\n",
        "param_counts = [comparison_results[name]['param_count'] for name in names]\n",
        "param_counts_m = [p/1000000 for p in param_counts]\n",
        "\n",
        "axes[1, 0].bar(names, param_counts_m, alpha=0.7, color=['blue', 'red'])\n",
        "axes[1, 0].set_title('íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ', fontsize=12)\n",
        "axes[1, 0].set_ylabel('íŒŒë¼ë¯¸í„° ìˆ˜ (M)', fontsize=10)\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "for i, count in enumerate(param_counts_m):\n",
        "    axes[1, 0].text(i, count + 0.1, f'{count:.1f}M', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 4. ì¢…í•© í‰ê°€ (ë ˆì´ë” ì°¨íŠ¸)\n",
        "categories = ['ë² ì–´ë§ ë¶„ë¥˜', 'íšŒì „ì²´ ë¶„ë¥˜', 'ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±', 'ì‹¤ìš©ì„±']\n",
        "tst_scores = [comparison_results['TST']['bearing_accuracy'], 0.0, 0.3, 0.2]  # TST ë©”ëª¨ë¦¬ ë¬¸ì œ\n",
        "cnn_scores = [comparison_results['1D-CNN']['bearing_accuracy'], \n",
        "              comparison_results['1D-CNN']['rotating_accuracy'], 0.9, 0.9]  # 1D-CNN ìš°ìˆ˜\n",
        "\n",
        "angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
        "angles += angles[:1]  # ì›í˜• ì™„ì„±\n",
        "\n",
        "tst_scores += tst_scores[:1]\n",
        "cnn_scores += cnn_scores[:1]\n",
        "\n",
        "axes[1, 1] = plt.subplot(2, 2, 4, projection='polar')\n",
        "axes[1, 1].plot(angles, tst_scores, 'o-', linewidth=2, label='TST', color='blue')\n",
        "axes[1, 1].fill(angles, tst_scores, alpha=0.25, color='blue')\n",
        "axes[1, 1].plot(angles, cnn_scores, 'o-', linewidth=2, label='1D-CNN', color='red')\n",
        "axes[1, 1].fill(angles, cnn_scores, alpha=0.25, color='red')\n",
        "\n",
        "axes[1, 1].set_xticks(angles[:-1])\n",
        "axes[1, 1].set_xticklabels(categories)\n",
        "axes[1, 1].set_ylim(0, 1)\n",
        "axes[1, 1].set_title('ì¢…í•© ì„±ëŠ¥ ë¹„êµ (ë ˆì´ë” ì°¨íŠ¸)', fontsize=12, pad=20)\n",
        "axes[1, 1].legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ê²°ê³¼ ìš”ì•½ í…Œì´ë¸”\n",
        "print(f\"\\nğŸ“Š TST vs 1D-CNN ì™„ì „ ë¹„êµ ê²°ê³¼\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'ëª¨ë¸':<10} {'ë°©ì‹':<25} {'ë² ì–´ë§':<8} {'íšŒì „ì²´':<8} {'í‰ê· ':<8} {'íŒŒë¼ë¯¸í„°':<10} {'ìƒíƒœ':<10}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for name, result in comparison_results.items():\n",
        "    method = result['method']\n",
        "    bearing_acc = result['bearing_accuracy']\n",
        "    rotating_acc = result['rotating_accuracy']\n",
        "    avg_acc = result['avg_accuracy']\n",
        "    param_count_m = result['param_count']/1000000\n",
        "    status = result['status']\n",
        "    \n",
        "    print(f\"{name:<10} {method:<25} {bearing_acc:.3f}    {rotating_acc:.3f}    {avg_acc:.3f}    {param_count_m:.1f}M     {status}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature ë¶„í¬ t-SNE ë¹„êµ ì‹œê°í™”\n",
        "print(\"ğŸ¨ TST vs 1D-CNN Feature ë¶„í¬ t-SNE ë¹„êµ\")\n",
        "\n",
        "# ê³µí†µ ìƒ˜í”Œ ì¤€ë¹„ (ë™ì¼í•œ ë°ì´í„°ë¡œ ë¹„êµ)\n",
        "sample_size = 500\n",
        "indices = torch.randperm(len(X_val_bearing))[:sample_size]\n",
        "sample_X = X_val_bearing[indices]\n",
        "sample_y_bearing = y_val_bearing[indices].numpy()\n",
        "\n",
        "# TST Feature ì¶”ì¶œ\n",
        "if 'tst_embeddings' in locals() and len(tst_embeddings) > 0:\n",
        "    # TSTëŠ” ì‘ì€ ë°°ì¹˜ë¡œ ì¶”ì¶œí–ˆìœ¼ë¯€ë¡œ ìƒ˜í”Œë§\n",
        "    tst_sample_size = min(sample_size, len(tst_embeddings))\n",
        "    tst_indices = np.random.choice(len(tst_embeddings), tst_sample_size, replace=False)\n",
        "    tst_features = tst_embeddings[tst_indices]\n",
        "    tst_sample_labels = tst_labels[tst_indices]\n",
        "else:\n",
        "    tst_features = None\n",
        "    tst_sample_labels = None\n",
        "\n",
        "# 1D-CNN Feature ì¶”ì¶œ\n",
        "cnn_model.eval()\n",
        "with torch.no_grad():\n",
        "    cnn_features = cnn_model.encoder(sample_X.to(device)).cpu().numpy()\n",
        "\n",
        "# t-SNE ì‹¤í–‰\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# TST t-SNE\n",
        "if tst_features is not None:\n",
        "    try:\n",
        "        tsne_tst = TSNE(n_components=2, random_state=42, perplexity=min(30, len(tst_features)//4))\n",
        "        tsne_result_tst = tsne_tst.fit_transform(tst_features)\n",
        "        \n",
        "        bearing_labels = ['H(ì •ìƒ)', 'B(ë³¼ê²°í•¨)', 'IR(ë‚´ë¥œê²°í•¨)', 'OR(ì™¸ë¥œê²°í•¨)']\n",
        "        bearing_colors = ['blue', 'red', 'green', 'orange']\n",
        "        \n",
        "        for i, (label, color) in enumerate(zip(bearing_labels, bearing_colors)):\n",
        "            mask = tst_sample_labels == i\n",
        "            if mask.any():\n",
        "                axes[0].scatter(tsne_result_tst[mask, 0], tsne_result_tst[mask, 1],\n",
        "                              c=color, label=label, alpha=0.7, s=30)\n",
        "        \n",
        "        axes[0].set_title('TST - ë² ì–´ë§ ìƒíƒœë³„ Feature ë¶„í¬', fontsize=12)\n",
        "        axes[0].set_xlabel('t-SNE 1')\n",
        "        axes[0].set_ylabel('t-SNE 2')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        \n",
        "    except Exception as e:\n",
        "        axes[0].text(0.5, 0.5, f'TST t-SNE ì‹¤íŒ¨\\\\n{e}', ha='center', va='center', \n",
        "                    transform=axes[0].transAxes, fontsize=10,\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\"))\n",
        "        axes[0].set_title('TST - Feature ë¶„í¬ (ì‹¤íŒ¨)', fontsize=12)\n",
        "else:\n",
        "    axes[0].text(0.5, 0.5, 'TST Feature ì—†ìŒ\\\\n(ë©”ëª¨ë¦¬ ë¶€ì¡±)', ha='center', va='center', \n",
        "                transform=axes[0].transAxes, fontsize=10,\n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
        "    axes[0].set_title('TST - Feature ë¶„í¬ (ì‹¤íŒ¨)', fontsize=12)\n",
        "\n",
        "# 1D-CNN t-SNE\n",
        "try:\n",
        "    tsne_cnn = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "    tsne_result_cnn = tsne_cnn.fit_transform(cnn_features)\n",
        "    \n",
        "    for i, (label, color) in enumerate(zip(bearing_labels, bearing_colors)):\n",
        "        mask = sample_y_bearing == i\n",
        "        if mask.any():\n",
        "            axes[1].scatter(tsne_result_cnn[mask, 0], tsne_result_cnn[mask, 1],\n",
        "                          c=color, label=label, alpha=0.7, s=30)\n",
        "    \n",
        "    axes[1].set_title('1D-CNN - ë² ì–´ë§ ìƒíƒœë³„ Feature ë¶„í¬', fontsize=12)\n",
        "    axes[1].set_xlabel('t-SNE 1')\n",
        "    axes[1].set_ylabel('t-SNE 2')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "except Exception as e:\n",
        "    axes[1].text(0.5, 0.5, f'1D-CNN t-SNE ì‹¤íŒ¨\\\\n{e}', ha='center', va='center', \n",
        "                transform=axes[1].transAxes, fontsize=10,\n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\"))\n",
        "    axes[1].set_title('1D-CNN - Feature ë¶„í¬ (ì‹¤íŒ¨)', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“‹ 6ë‹¨ê³„: ìµœì¢… ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ìµœì¢… ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­\n",
        "print(\"ğŸ“‹ TST vs 1D-CNN ì™„ì „ ë¹„êµ ì‹¤í—˜ ê²°ë¡ \")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ìŠ¹ì ê²°ì •\n",
        "tst_score = comparison_results['TST']['bearing_accuracy']\n",
        "cnn_score = comparison_results['1D-CNN']['avg_accuracy']\n",
        "\n",
        "if cnn_score > tst_score:\n",
        "    winner = '1D-CNN'\n",
        "    winner_result = comparison_results['1D-CNN']\n",
        "else:\n",
        "    winner = 'TST'\n",
        "    winner_result = comparison_results['TST']\n",
        "\n",
        "print(f\"\\nğŸ† ìµœì¢… ìŠ¹ë¦¬: {winner}\")\n",
        "print(f\"   ë² ì–´ë§ ë¶„ë¥˜: {winner_result['bearing_accuracy']:.1%}\")\n",
        "if winner_result['rotating_accuracy'] > 0:\n",
        "    print(f\"   íšŒì „ì²´ ë¶„ë¥˜: {winner_result['rotating_accuracy']:.1%}\")\n",
        "    print(f\"   í‰ê·  ì„±ëŠ¥: {winner_result['avg_accuracy']:.1%}\")\n",
        "else:\n",
        "    print(f\"   íšŒì „ì²´ ë¶„ë¥˜: N/A (í‰ê°€ ë¶ˆê°€)\")\n",
        "    print(f\"   ë² ì–´ë§ ì„±ëŠ¥: {winner_result['bearing_accuracy']:.1%}\")\n",
        "print(f\"   íŒŒë¼ë¯¸í„°: {winner_result['param_count']/1000000:.1f}M\")\n",
        "\n",
        "# í•µì‹¬ ì¸ì‚¬ì´íŠ¸\n",
        "print(f\"\\nğŸ” í•µì‹¬ ì¸ì‚¬ì´íŠ¸:\")\n",
        "if winner == '1D-CNN':\n",
        "    print(f\"   âœ… 1D-CNNì´ TSTë¥¼ ëŠ¥ê°€\")\n",
        "    print(f\"   ğŸ“Š ë² ì–´ë§ ë¶„ë¥˜: 1D-CNN {comparison_results['1D-CNN']['bearing_accuracy']:.1%} vs TST {comparison_results['TST']['bearing_accuracy']:.1%}\")\n",
        "    print(f\"   ğŸ¯ íšŒì „ì²´ ë¶„ë¥˜: 1D-CNNë§Œ í‰ê°€ ê°€ëŠ¥ ({comparison_results['1D-CNN']['rotating_accuracy']:.1%})\")\n",
        "    print(f\"   ğŸ’¡ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: 1D-CNN ì •ìƒ vs TST ì œì•½\")\n",
        "    print(f\"   ğŸš€ ì‹¤ìš©ì„±: 1D-CNN ë°°í¬ ê°€ëŠ¥ vs TST ë¶ˆê°€ëŠ¥\")\n",
        "else:\n",
        "    print(f\"   âš ï¸  TST ìŠ¹ë¦¬í•˜ì§€ë§Œ ì œí•œì  í‰ê°€\")\n",
        "    print(f\"   ğŸ’€ TST ë©”ëª¨ë¦¬ ì œì•½ìœ¼ë¡œ ì™„ì „í•œ ë¹„êµ ë¶ˆê°€\")\n",
        "\n",
        "# TSTì˜ ë¬¸ì œì \n",
        "print(f\"\\nğŸ’€ TSTì˜ ì¹˜ëª…ì  ë¬¸ì œì :\")\n",
        "print(f\"   ğŸ”¥ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: O(nÂ²) ë³µì¡ë„\")\n",
        "print(f\"   ğŸŒ í™•ì¥ì„± ë¶€ì¡±: ì‘ì€ ë°°ì¹˜ë¡œë§Œ í‰ê°€ ê°€ëŠ¥\")\n",
        "print(f\"   ğŸ’¸ ì‹¤ìš©ì„± ë¶€ì¡±: ì‹¤ì œ ì‹œìŠ¤í…œ ë°°í¬ ì–´ë ¤ì›€\")\n",
        "\n",
        "# 1D-CNNì˜ ì¥ì \n",
        "print(f\"\\nâœ… 1D-CNNì˜ ëª…í™•í•œ ì¥ì :\")\n",
        "print(f\"   ğŸš€ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: O(n) ë³µì¡ë„ë¡œ ì•ˆì •ì \")\n",
        "print(f\"   ğŸ“ˆ í™•ì¥ì„±: í° ë°°ì¹˜ í¬ê¸°ë¡œ ì•ˆì •ì  í•™ìŠµ\")\n",
        "print(f\"   ğŸ’° ì‹¤ìš©ì„±: ì¼ë°˜ì ì¸ GPUì—ì„œë„ ì‘ë™\")\n",
        "print(f\"   ğŸ¯ ì™„ì „ í‰ê°€: ë² ì–´ë§ + íšŒì „ì²´ ëª¨ë‘ í‰ê°€ ê°€ëŠ¥\")\n",
        "\n",
        "# ìµœì¢… ê¶Œì¥ì‚¬í•­\n",
        "print(f\"\\nğŸ’¡ ìµœì¢… ê¶Œì¥ì‚¬í•­:\")\n",
        "if winner == '1D-CNN':\n",
        "    print(f\"   âœ… 1D-CNNìœ¼ë¡œ ì „ì²´ ì‹œìŠ¤í…œ êµì²´ ê°•ë ¥ ê¶Œì¥\")\n",
        "    print(f\"   ğŸ“ ì•¡ì…˜ ì•„ì´í…œ:\")\n",
        "    print(f\"      1. src/vibration_encoder.pyë¥¼ 1D-CNN ì•„í‚¤í…ì²˜ë¡œ êµì²´\")\n",
        "    print(f\"      2. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ì»¤ë„ í¬ê¸°, ë ˆì´ì–´ ìˆ˜)\")\n",
        "    print(f\"      3. ì „ì²´ TextVibCLIP ì‹œìŠ¤í…œ ì¬ì‹¤í—˜\")\n",
        "else:\n",
        "    print(f\"   âš ï¸  TST ìŠ¹ë¦¬í•˜ì§€ë§Œ ë©”ëª¨ë¦¬ ë¬¸ì œë¡œ ì‹¤ìš©ì„± ë¶€ì¡±\")\n",
        "    print(f\"   ğŸ“ ì¶”ê°€ ê²€í†  í•„ìš”\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ‰ TST vs 1D-CNN ì™„ì „ ë¹„êµ ì‹¤í—˜ ì™„ë£Œ!\")\n",
        "print(\"ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ TextVibCLIP ì‹œìŠ¤í…œì„ ê°œì„ í•˜ì„¸ìš”.\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TVCLIP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
