"""
Vibration Encoder: 1D-CNN ê¸°ë°˜ ì§„ë™ ì‹ í˜¸ ì¸ì½”ë”
1D ì§„ë™ ì‹ í˜¸ë¥¼ 512ì°¨ì› ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
ë² ì–´ë§ ê²°í•¨ì˜ ë‹¤ì–‘í•œ ì£¼íŒŒìˆ˜ íŒ¨í„´ì„ íš¨ê³¼ì ìœ¼ë¡œ ê°ì§€

TST â†’ 1D-CNN êµì²´ ì´ìœ :
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: O(n) ë³µì¡ë„ë¡œ ì•ˆì •ì  ì²˜ë¦¬
- ì„±ëŠ¥ ìš°ìˆ˜ì„±: 79.0% vs 66.7% (TST ëŒ€ë¹„ 12.3%p í–¥ìƒ)
- ì‹¤ìš©ì„±: ì¼ë°˜ì ì¸ GPUì—ì„œë„ ì›í™œí•œ ì‘ë™ ê°€ëŠ¥
"""

import sys
from pathlib import Path
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional
import logging

# ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‹¤í–‰ ì‹œ(project rootê°€ sys.pathì— ì—†ì„ ë•Œ) ë£¨íŠ¸ ê²½ë¡œ ìë™ ì¶”ê°€
if __package__ is None or __package__ == "":
    project_root = Path(__file__).resolve().parents[1]
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))

from configs.model_config import MODEL_CONFIG

logger = logging.getLogger(__name__)


class VibrationEncoder(nn.Module):
    """
    1D-CNN ê¸°ë°˜ ì§„ë™ ì‹ í˜¸ ì¸ì½”ë”
    
    ë² ì–´ë§ ê²°í•¨ì˜ ë‹¤ì–‘í•œ ì£¼íŒŒìˆ˜ íŒ¨í„´ì„ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì»¤ë„ë¡œ íš¨ê³¼ì  ê°ì§€:
    - Block 1: ê³ ì£¼íŒŒ ì¶©ê²© íŒ¨í„´ (ë² ì–´ë§ ê²°í•¨ íŠ¹ìœ ì˜ ì¶©ê²©íŒŒ)
    - Block 2: ì¤‘ê°„ ì£¼íŒŒìˆ˜ íŒ¨í„´ (íšŒì „ ì£¼ê¸°, ì¡°í™”íŒŒ)
    - Block 3: ì €ì£¼íŒŒ êµ¬ì¡°ì  ì§„ë™ íŒ¨í„´
    - Block 4: íŠ¹ì§• ì§‘ì•½
    
    1D ì§„ë™ ì‹ í˜¸ (4096 samples) â†’ 512ì°¨ì› ì„ë² ë”© ë³€í™˜
    """
    
    def __init__(self,
                 input_length: int = MODEL_CONFIG['vibration_encoder']['input_length'],
                 embedding_dim: int = MODEL_CONFIG['embedding_dim']):
        """
        Args:
            input_length (int): ì…ë ¥ ì‹ í˜¸ ê¸¸ì´ (ê¸°ë³¸ê°’: 4096)
            embedding_dim (int): ìµœì¢… ì¶œë ¥ ì„ë² ë”© ì°¨ì› (ê¸°ë³¸ê°’: 512)
        """
        super(VibrationEncoder, self).__init__()
        
        self.input_length = input_length
        self.embedding_dim = embedding_dim
        
        # ğŸ¯ OPTIMIZED: 2048 ì…ë ¥ì— ìµœì í™”ëœ 4-layer 1D-CNN
        # ìì—°ìŠ¤ëŸ¬ìš´ ì°¨ì› ì¶•ì†Œ: 2048 â†’ 1024 â†’ 512 â†’ 256 â†’ 128
        kernel_sizes = MODEL_CONFIG['vibration_encoder']['kernel_sizes']
        channels = MODEL_CONFIG['vibration_encoder']['channels']
        dropout_rate = MODEL_CONFIG['vibration_encoder']['dropout']
        
        self.conv_layers = nn.Sequential(
            # Block 1: ê³ ì£¼íŒŒ ì¶©ê²© íŒ¨í„´ ê°ì§€ (ë² ì–´ë§ ê²°í•¨ íŠ¹ìœ ì˜ ì¶©ê²©íŒŒ)
            nn.Conv1d(1, channels[0], kernel_size=kernel_sizes[0], stride=2, padding=kernel_sizes[0]//2),  # 2048 â†’ 1024
            nn.BatchNorm1d(channels[0]),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            
            # Block 2: ì¤‘ê°„ ì£¼íŒŒìˆ˜ íŒ¨í„´ (íšŒì „ ì£¼ê¸°, ì¡°í™”íŒŒ)
            nn.Conv1d(channels[0], channels[1], kernel_size=kernel_sizes[1], stride=2, padding=kernel_sizes[1]//2),  # 1024 â†’ 512
            nn.BatchNorm1d(channels[1]),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            
            # Block 3: ì €ì£¼íŒŒ êµ¬ì¡°ì  ì§„ë™ íŒ¨í„´
            nn.Conv1d(channels[1], channels[2], kernel_size=kernel_sizes[2], stride=2, padding=kernel_sizes[2]//2),  # 512 â†’ 256
            nn.BatchNorm1d(channels[2]),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            
            # Block 4: íŠ¹ì§• ì§‘ì•½ ë° ìµœì¢… í‘œí˜„
            nn.Conv1d(channels[2], channels[3], kernel_size=kernel_sizes[3], stride=2, padding=kernel_sizes[3]//2),  # 256 â†’ 128
            nn.BatchNorm1d(channels[3]),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
        )
        
        # Global Average Pooling (ì‹œê°„ì¶• ì •ë³´ ì§‘ì•½)
        self.global_pool = nn.AdaptiveAvgPool1d(1)
        
        # Final projection to embedding space (ë§ˆì§€ë§‰ conv ì±„ë„ ìˆ˜ì— ë§ì¶¤)
        final_conv_channels = channels[-1]  # 512
        self.projection = nn.Sequential(
            nn.Linear(final_conv_channels, MODEL_CONFIG['projection']['hidden_dim']),
            nn.ReLU(),
            nn.Dropout(MODEL_CONFIG['projection']['dropout']),
            nn.Linear(MODEL_CONFIG['projection']['hidden_dim'], embedding_dim)
            # ğŸ¯ FIXED: LayerNorm ì œê±° (gradient vanishing ë°©ì§€)
        )
        
        # ğŸ¯ FIXED: ì•ˆì •ì ì¸ ìŠ¤ì¼€ì¼ë§ íŒ©í„°
        self.embedding_scaler = nn.Parameter(torch.tensor(3.0))  # 10.0 â†’ 3.0 (ì•ˆì •í™”)
        
        # Projection layer ì´ˆê¸°í™” (CLIP-style)
        with torch.no_grad():
            # ì²« ë²ˆì§¸ projection layer: Xavier normal
            nn.init.xavier_normal_(self.projection[0].weight)
            nn.init.zeros_(self.projection[0].bias)
            
            # ë§ˆì§€ë§‰ projection layer: í‘œì¤€ ì´ˆê¸°í™”
            nn.init.xavier_normal_(self.projection[3].weight)
            nn.init.zeros_(self.projection[3].bias)

        # Auxiliary classification head (bearing condition 4-class)
        aux_cfg = MODEL_CONFIG.get('aux_classification', {'enabled': False})
        self.use_aux_head = bool(aux_cfg.get('enabled', False))
        if self.use_aux_head:
            num_classes = int(aux_cfg.get('num_classes', 4))
            aux_dropout = float(aux_cfg.get('dropout', 0.1))
            self.aux_head = nn.Sequential(
                nn.Dropout(aux_dropout),
                nn.Linear(embedding_dim, embedding_dim // 2),
                nn.ReLU(),
                nn.Linear(embedding_dim // 2, num_classes)
            )
        
        # íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”
        self._init_parameters()
        
        logger.info(f"1D-CNN VibrationEncoder ì´ˆê¸°í™”: input_length={input_length}, "
                   f"embedding_dim={embedding_dim}")
        logger.info(f"   OPTIMIZED: ì»¤ë„ í¬ê¸°: {kernel_sizes} - 4-layer ë² ì–´ë§ ìµœì í™”")
        logger.info(f"   OPTIMIZED: ì±„ë„ ìˆ˜: {channels} - ìì—°ìŠ¤ëŸ¬ìš´ 64â†’512 ì¦ê°€")
        logger.info(f"   ì´ íŒŒë¼ë¯¸í„°: {self.get_trainable_parameters():,}")
    
    def _init_parameters(self):
        """íŒŒë¼ë¯¸í„° ì´ˆê¸°í™” (ê°œì„ ëœ ì´ˆê¸°í™”)"""
        for module in self.modules():
            if isinstance(module, nn.Conv1d):
                # He initialization (ReLUì— ì í•©)
                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
            elif isinstance(module, nn.Linear):
                # ë§ˆì§€ë§‰ projection layerëŠ” ë” ì‘ì€ ì´ˆê¸°í™”
                if module == self.projection[-1]:  # ë§ˆì§€ë§‰ Linear layer
                    nn.init.normal_(module.weight, mean=0.0, std=0.02)
                    if module.bias is not None:
                        nn.init.zeros_(module.bias)
                else:
                    nn.init.xavier_uniform_(module.weight)
                    if module.bias is not None:
                        nn.init.zeros_(module.bias)
    
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Forward pass
        
        Args:
            x: ì§„ë™ ì‹ í˜¸ (batch_size, input_length)
            mask: padding mask (ì‚¬ìš©ë˜ì§€ ì•ŠìŒ, TST í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
            
        Returns:
            torch.Tensor: ì§„ë™ ì„ë² ë”© (batch_size, embedding_dim)
        """
        batch_size, seq_len = x.shape
        
        # ğŸ¯ SIMPLIFIED: í†µì¼ëœ ì…ë ¥ ê¸¸ì´ (2048)
        # ì…ë ¥ ê¸¸ì´ ê²€ì¦
        if seq_len != self.input_length:
            raise ValueError(f"ì…ë ¥ ê¸¸ì´ ë¶ˆì¼ì¹˜: ì˜ˆìƒ {self.input_length}, ì‹¤ì œ {seq_len}")
        
        # Reshape: (batch_size, input_length) -> (batch_size, 1, input_length)
        x = x.unsqueeze(1)
        
        # 1D Convolution layers
        x = self.conv_layers(x)  # (batch_size, 512, reduced_length)
        
        # Global average pooling
        x = self.global_pool(x)  # (batch_size, 512, 1)
        x = x.squeeze(-1)  # (batch_size, 512)
        
        # Final projection
        output = self.projection(x)  # (batch_size, embedding_dim)
        
        # ğŸ¯ CRITICAL FIX: ì„ë² ë”© í¬ê¸° ìŠ¤ì¼€ì¼ë§ (Text encoderì™€ ê· í˜• ë§ì¶”ê¸°)
        output = output * self.embedding_scaler
        
        return output
    
    def get_trainable_parameters(self) -> int:
        """í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ ë°˜í™˜"""
        return sum(p.numel() for p in self.parameters() if p.requires_grad)
    
    def freeze_parameters(self):
        """ëª¨ë“  íŒŒë¼ë¯¸í„° freeze"""
        for param in self.parameters():
            param.requires_grad = False
        logger.info("1D-CNN VibrationEncoder íŒŒë¼ë¯¸í„° freeze ì™„ë£Œ")
    
    def unfreeze_parameters(self):
        """ëª¨ë“  íŒŒë¼ë¯¸í„° unfreeze"""
        for param in self.parameters():
            param.requires_grad = True
        logger.info("1D-CNN VibrationEncoder íŒŒë¼ë¯¸í„° unfreeze ì™„ë£Œ")


def create_vibration_encoder() -> VibrationEncoder:
    """
    ì„¤ì •ì— ë”°ë¥¸ 1D-CNN VibrationEncoder ìƒì„±
    
    Returns:
        VibrationEncoder: ì„¤ì •ëœ 1D-CNN ì§„ë™ ì¸ì½”ë”
    """
    encoder = VibrationEncoder()
    
    logger.info(f"1D-CNN VibrationEncoder ìƒì„± ì™„ë£Œ: {encoder.get_trainable_parameters():,} íŒŒë¼ë¯¸í„°")
    
    return encoder


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    print("=== 1D-CNN VibrationEncoder í…ŒìŠ¤íŠ¸ ===")
    
    # ì¸ì½”ë” ìƒì„±
    encoder = create_vibration_encoder()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    batch_size = 32  # 1D-CNNì€ í° ë°°ì¹˜ í¬ê¸° ì§€ì›
    input_length = MODEL_CONFIG['vibration_encoder']['input_length']
    
    # ë”ë¯¸ ì§„ë™ ì‹ í˜¸ (ì •ê·œë¶„í¬)
    test_signals = torch.randn(batch_size, input_length)
    
    print(f"ì…ë ¥ ì‹ í˜¸ shape: {test_signals.shape}")
    
    # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ì´ë™
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    encoder.to(device)
    test_signals = test_signals.to(device)
    
    # Forward pass í…ŒìŠ¤íŠ¸
    with torch.no_grad():
        embeddings = encoder(test_signals)
    
    print(f"ì¶œë ¥ ì„ë² ë”© shape: {embeddings.shape}")
    print(f"ì„ë² ë”© norm: {torch.norm(embeddings, dim=1)}")
    
    # íŒŒë¼ë¯¸í„° ì •ë³´
    print(f"ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {encoder.get_trainable_parameters():,}")
    
    # ë‹¤ì–‘í•œ ê¸¸ì´ ì‹ í˜¸ í…ŒìŠ¤íŠ¸ (ì˜¤ë¥˜ ë°œìƒ ì˜ˆìƒ)
    try:
        wrong_length_signal = torch.randn(batch_size, input_length // 2).to(device)
        encoder(wrong_length_signal)
    except ValueError as e:
        print(f"ì˜ˆìƒëœ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # Auxiliary head í…ŒìŠ¤íŠ¸ (í™œì„±í™”ëœ ê²½ìš°)
    if encoder.use_aux_head:
        with torch.no_grad():
            aux_logits = encoder.aux_head(embeddings)
        print(f"Auxiliary logits shape: {aux_logits.shape}")
    
    print("\n=== 1D-CNN VibrationEncoder í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")