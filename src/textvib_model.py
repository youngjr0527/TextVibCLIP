"""
TextVibCLIP: ì§„ë™ ì‹ í˜¸ì™€ í…ìŠ¤íŠ¸ì˜ ë©€í‹°ëª¨ë‹¬ ëŒ€ì¡° í•™ìŠµ ëª¨ë¸
CLIP-inspired architecture with asymmetric continual learning
"""

import sys
from pathlib import Path
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Tuple, Optional, Union
import logging

# ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‹¤í–‰ ì‹œ(project rootê°€ sys.pathì— ì—†ì„ ë•Œ) ë£¨íŠ¸ ê²½ë¡œ ìë™ ì¶”ê°€
if __package__ is None or __package__ == "":
    project_root = Path(__file__).resolve().parents[1]
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))

from .text_encoder import TextEncoder, create_text_encoder
from .vibration_encoder import VibrationEncoder, create_vibration_encoder
from configs.model_config import MODEL_CONFIG

logger = logging.getLogger(__name__)


class InfoNCELoss(nn.Module):
    """
    Bidirectional InfoNCE Loss with asymmetric temperature
    
    - First domain training: Ï„_text = Ï„_vib (ê· ë“± í•™ìŠµ)
    - Continual learning: Ï„_text > Ï„_vib (í…ìŠ¤íŠ¸ ì•ˆì •í™”, ì§„ë™ ì ì‘ ê°•í™”)
    """
    
    def __init__(self, 
                 temperature_text: float = 0.07,
                 temperature_vib: float = 0.07,
                 reduction: str = 'mean'):
        """
        Args:
            temperature_text (float): Text-to-vibration direction temperature
            temperature_vib (float): Vibration-to-text direction temperature  
            reduction (str): Loss reduction method
        """
        super(InfoNCELoss, self).__init__()
        
        # ğŸ¯ CRITICAL FIX: í•™ìŠµ ê°€ëŠ¥í•œ ì˜¨ë„ íŒŒë¼ë¯¸í„° (CLIP-style)
        # ì´ˆê¸°ê°’ì„ log spaceì—ì„œ ì„¤ì •í•˜ì—¬ ì•ˆì •ì ì¸ í•™ìŠµ
        self.log_temperature_text = nn.Parameter(torch.log(torch.tensor(temperature_text)))
        self.log_temperature_vib = nn.Parameter(torch.log(torch.tensor(temperature_vib)))
        
        self.reduction = reduction
        
        logger.info(f"InfoNCE Loss ì´ˆê¸°í™”: Ï„_text={temperature_text:.3f}, Ï„_vib={temperature_vib:.3f} (í•™ìŠµ ê°€ëŠ¥)")
    
    def _class_based_infonce_loss(self, logits: torch.Tensor, positive_mask: torch.Tensor, temperature: float) -> torch.Tensor:
        """
        í´ë˜ìŠ¤ ê¸°ë°˜ InfoNCE loss
        
        Args:
            logits: ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ (N, M)
            positive_mask: ê°™ì€ í´ë˜ìŠ¤ëŠ” True, ë‹¤ë¥¸ í´ë˜ìŠ¤ëŠ” False (N, M)
            temperature: ì˜¨ë„ íŒŒë¼ë¯¸í„°
            
        Returns:
            torch.Tensor: InfoNCE loss
        """
        # Temperature scaling
        logits_scaled = logits / temperature
        
        # ğŸ¯ AMP ì•ˆì „ì„±: Half precision ë²”ìœ„ ë‚´ì—ì„œ ì—°ì‚°
        logits_f32 = logits_scaled.float()
        N = logits_f32.size(0)
        M = logits_f32.size(1)
        device = logits_f32.device
        
        # ë¶„ëª¨: log-sum-exp(all)
        log_denominator = torch.logsumexp(logits_f32, dim=1)  # (N,)
        
        # ìê¸°ìì‹  ì œì™¸ ë§ˆìŠ¤í¬(ì§ì‚¬ê°í˜• ëŒ€ì‘)
        eye_mask = torch.zeros((N, M), dtype=torch.bool, device=device)
        diag_len = min(N, M)
        if diag_len > 0:
            idx = torch.arange(diag_len, device=device)
            eye_mask[idx, idx] = True
        pos_mask_no_self = positive_mask & (~eye_mask)
        
        # ê¸°ë³¸: positive ìœ„ì¹˜ë§Œ ë‚¨ê¹€
        masked_logits = logits_f32.masked_fill(~pos_mask_no_self, -1e4)
        log_numerator = torch.logsumexp(masked_logits, dim=1)  # (N,)
        
        # ğŸ¯ FIXED: í–‰ë³„ë¡œ positiveê°€ ì „í˜€ ì—†ëŠ” ê²½ìš° ì•ˆì „í•œ fallback
        has_positive = pos_mask_no_self.any(dim=1)  # (N,)
        if not torch.all(has_positive):
            # positiveê°€ ì—†ëŠ” í–‰ë“¤ì— ëŒ€í•´ì„œë§Œ ëŒ€ê° ì›ì†Œ ì‚¬ìš©
            no_positive_mask = ~has_positive  # (N,)
            
            if diag_len > 0:
                # ëŒ€ê°ì„  ì›ì†Œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í–‰ë“¤ (row index < diag_len)
                row_idx = torch.arange(N, device=device)
                can_use_diag = (row_idx < diag_len) & no_positive_mask  # (N,)
                
                if can_use_diag.any():
                    # í•´ë‹¹ í–‰ë“¤ì˜ ëŒ€ê°ì„  ì›ì†Œ ê°’
                    diag_values = torch.zeros(N, device=device)  # (N,) í¬ê¸°ë¡œ ì´ˆê¸°í™”
                    diag_indices = row_idx[can_use_diag]
                    diag_values[can_use_diag] = logits_f32[diag_indices, diag_indices]
                    
                    # positiveê°€ ì—†ëŠ” í–‰ë“¤ì— ëŒ€í•´ì„œë§Œ ëŒ€ê°ì„  ê°’ìœ¼ë¡œ ëŒ€ì²´
                    log_numerator = torch.where(can_use_diag, diag_values, log_numerator)
        
        # InfoNCE: -log(exp(pos_sum) / exp(all_sum))
        loss_per_sample = -(log_numerator - log_denominator)

        # ğŸ¯ If some rows have at least one positive (excluding self), average only over them.
        #    If none have positives, fall back to averaging all (diagonal already injected above).
        if has_positive.any():
            return loss_per_sample[has_positive].mean()
        else:
            return loss_per_sample.mean()
    
    def forward(self, 
                text_embeddings: torch.Tensor, 
                vib_embeddings: torch.Tensor,
                batch_labels: torch.Tensor = None) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        Bidirectional InfoNCE loss ê³„ì‚°
        
        Args:
            text_embeddings: (batch_size, embedding_dim)
            vib_embeddings: (batch_size, embedding_dim)
            
        Returns:
            Tuple[torch.Tensor, Dict]: (total_loss, loss_components)
        """
        batch_size = text_embeddings.size(0)
        
        # ğŸ¯ CRITICAL FIX: ê°•ì œ ì„ë² ë”© ì •ë ¬ (CLIP-inspired)
        # L2 ì •ê·œí™”
        text_embeddings = F.normalize(text_embeddings, p=2, dim=1)
        vib_embeddings = F.normalize(vib_embeddings, p=2, dim=1)
        
        # í•™ìŠµ ê°€ëŠ¥í•œ ì˜¨ë„ íŒŒë¼ë¯¸í„° ì‚¬ìš©
        temp_text = torch.exp(self.log_temperature_text)
        temp_vib = torch.exp(self.log_temperature_vib)
        
        # ğŸ¯ FIXED: ì ì ˆí•œ ìŠ¤ì¼€ì¼ë§ (ë°œì‚° ë°©ì§€)
        # ì˜¨ë„ê°€ ë‚®ì„ ë•Œ ì ë‹¹í•œ ìŠ¤ì¼€ì¼ë§ë§Œ ì ìš©
        alignment_scale = torch.clamp(1.0 / temp_text, min=1.0, max=10.0)  # 100 â†’ 10 (10ë°° ê°ì†Œ)
        text_embeddings = text_embeddings * alignment_scale
        vib_embeddings = vib_embeddings * alignment_scale
        
        # ğŸ¯ FIXED: í´ë˜ìŠ¤ ê¸°ë°˜ Contrastive Learning
        # ê°™ì€ ê³ ì¥ ìœ í˜•ë¼ë¦¬ positive pairs, ë‹¤ë¥¸ ê³ ì¥ ìœ í˜•ì€ negative pairs
        
        # ë°°ì¹˜ì—ì„œ ë¼ë²¨ ì •ë³´ ì¶”ì¶œ (ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬ë°›ìŒ)
        # batch_labels = batch.get('labels', None)  # ì´ì œ ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ìŒ
        if batch_labels is not None:
            if batch_labels.dim() == 2:
                if batch_labels.size(1) == 2:
                    # UOS: ì²« ë²ˆì§¸ ì°¨ì›ì´ ì£¼ ë¶„ë¥˜ (7-í´ë˜ìŠ¤)
                    class_labels = batch_labels[:, 0]  # [0,1,2,3,4,5,6] for H/B/IR/OR/L/U/M
                elif batch_labels.size(1) == 1:
                    # CWRU: (batch_size, 1) í˜•íƒœì˜ ë¼ë²¨
                    class_labels = batch_labels[:, 0]  # [0,1,2,3] for Normal/B/IR/OR
                else:
                    # ì˜ˆìƒì¹˜ ëª»í•œ í˜•íƒœ
                    class_labels = batch_labels[:, 0]
            elif batch_labels.dim() == 1:
                # 1ì°¨ì› ë¼ë²¨ (ì§ì ‘ ì‚¬ìš©)
                class_labels = batch_labels
            else:
                # Fallback: diagonal matching
                class_labels = torch.arange(batch_size).to(text_embeddings.device)
        else:
            # Fallback: diagonal matching (ê¸°ì¡´ ë°©ì‹)
            class_labels = torch.arange(batch_size).to(text_embeddings.device)
        
        # Cosine similarity matrix
        similarity_matrix = torch.matmul(text_embeddings, vib_embeddings.t())  # (N, N)
        
        # í´ë˜ìŠ¤ ê¸°ë°˜ positive/negative mask ìƒì„±
        class_labels = class_labels.to(text_embeddings.device)
        positive_mask = (class_labels.unsqueeze(1) == class_labels.unsqueeze(0))  # (N, N)
        
        # í´ë˜ìŠ¤ ê¸°ë°˜ InfoNCE loss ê³„ì‚° (í•™ìŠµ ê°€ëŠ¥í•œ ì˜¨ë„ ì‚¬ìš©)
        temp_text = torch.exp(self.log_temperature_text)
        temp_vib = torch.exp(self.log_temperature_vib)
        
        loss_text_to_vib = self._class_based_infonce_loss(
            similarity_matrix, positive_mask, temp_text
        )
        loss_vib_to_text = self._class_based_infonce_loss(
            similarity_matrix.t(), positive_mask.t(), temp_vib
        )
        
        # Total bidirectional loss
        total_loss = (loss_text_to_vib + loss_vib_to_text) / 2.0
        
        # Loss components for monitoring
        loss_components = {
            'text_to_vib': loss_text_to_vib,
            'vib_to_text': loss_vib_to_text,
            'total': total_loss
        }
        
        return total_loss, loss_components
    
    def update_temperatures(self, temperature_text: float, temperature_vib: float):
        """ì˜¨ë„ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ (Continual learningì—ì„œ ì‚¬ìš©)"""
        with torch.no_grad():
            self.log_temperature_text.copy_(torch.log(torch.tensor(temperature_text)))
            self.log_temperature_vib.copy_(torch.log(torch.tensor(temperature_vib)))
        logger.info(f"Temperature ì—…ë°ì´íŠ¸: Ï„_text={temperature_text:.3f}, Ï„_vib={temperature_vib:.3f}")
    
    @property
    def temperature_text(self):
        """í˜„ì¬ text temperature ê°’ ë°˜í™˜"""
        return torch.exp(self.log_temperature_text).item()
    
    @property  
    def temperature_vib(self):
        """í˜„ì¬ vibration temperature ê°’ ë°˜í™˜"""
        return torch.exp(self.log_temperature_vib).item()


class TextVibCLIP(nn.Module):
    """
    TextVibCLIP ë©”ì¸ ëª¨ë¸
    
    Text Encoder + Vibration Encoder + InfoNCE Loss
    First domain training ë° Continual learning ì§€ì›
    """
    
    def __init__(self,
                 domain_stage: str = 'first_domain',
                 embedding_dim: int = MODEL_CONFIG['embedding_dim']):
        """
        Args:
            domain_stage (str): 'first_domain' (Domain 1) ë˜ëŠ” 'continual' (Domain 2+)
            embedding_dim (int): ì„ë² ë”© ì°¨ì›
        """
        super(TextVibCLIP, self).__init__()
        
        self.domain_stage = domain_stage
        self.embedding_dim = embedding_dim
        
        # Text Encoder ìƒì„±
        self.text_encoder = create_text_encoder(domain_stage)
        
        # Vibration Encoder ìƒì„±
        self.vibration_encoder = create_vibration_encoder()

        # ğŸ¯ Cross-Modal Projection Layer (Residual stack ì˜µì…˜)
        self.text_projection = self._build_projection(embedding_dim)
        self.vibration_projection = self._build_projection(embedding_dim)

        # Prototypes (class anchors) for shared semantic space
        proto_cfg = MODEL_CONFIG.get('prototypes', {})
        self.use_prototypes = bool(proto_cfg.get('enabled', False))
        self.prototype_tau = float(proto_cfg.get('tau', 0.1))
        self.prototype_lambda = float(proto_cfg.get('lambda_proto', 0.5))
        self.prototype_ema_m = float(proto_cfg.get('ema_momentum', 0.99))
        self.prototype_init_from_text = bool(proto_cfg.get('init_from_text', True))

        # í´ë˜ìŠ¤ ìˆ˜ëŠ” UOSì˜ 7ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš© (CWRU 4ëŠ” í•˜ìœ„ ë¶€ë¶„ì§‘í•©ìœ¼ë¡œ ì²˜ë¦¬)
        aux_cfg = MODEL_CONFIG.get('aux_classification', {})
        self.num_classes = int(aux_cfg.get('num_classes', 7))

        if self.use_prototypes:
            # í•™ìŠµ ê°€ëŠ¥í•œ í”„ë¡œí† íƒ€ì… í…Œì´ë¸” (K, D)
            proto = torch.randn(self.num_classes, embedding_dim) * (1.0 / (embedding_dim ** 0.5))
            self.prototypes = nn.Parameter(proto)
            # ì§€ì—° ì´ˆê¸°í™”/EMA í”Œë˜ê·¸ ë° ë²„í¼
            self.register_buffer('prototypes_initialized', torch.tensor(0, dtype=torch.uint8))
            self.register_buffer('prototype_counts', torch.zeros(self.num_classes, dtype=torch.long))

        # Bilinear similarity head (optional)
        sim_cfg = MODEL_CONFIG.get('similarity', {})
        self.use_bilinear = bool(sim_cfg.get('bilinear_enabled', False))
        self.lambda_bilinear = float(sim_cfg.get('lambda_bilinear', 0.0))
        if self.use_bilinear:
            self.bilinear_W = nn.Parameter(torch.eye(embedding_dim))
        
        # InfoNCE Loss ì„¤ì •
        if domain_stage == 'first_domain':
            temp_text = MODEL_CONFIG['infonce']['first_domain_temperature_text']
            temp_vib = MODEL_CONFIG['infonce']['first_domain_temperature_vib']
        else:  # continual
            temp_text = MODEL_CONFIG['infonce']['continual_temperature_text']
            temp_vib = MODEL_CONFIG['infonce']['continual_temperature_vib']
        
        self.infonce_loss = InfoNCELoss(temp_text, temp_vib)
        
        # Continual learning ìƒíƒœ ê´€ë¦¬
        self.is_continual_mode = (domain_stage == 'continual')
        
        logger.info(f"TextVibCLIP ì´ˆê¸°í™” ì™„ë£Œ: {domain_stage} stage")

    def _build_projection(self, embedding_dim: int) -> nn.Module:
        rp_cfg = MODEL_CONFIG.get('residual_projection', {'enabled': False})
        if not bool(rp_cfg.get('enabled', False)):
            return nn.Sequential(
                nn.Linear(embedding_dim, embedding_dim * 2),
                nn.ReLU(),
                nn.Dropout(MODEL_CONFIG['projection']['dropout']),
                nn.Linear(embedding_dim * 2, embedding_dim),
                nn.LayerNorm(embedding_dim)
            )
        # Residual MLP Block (Pre-LN)
        class ResidualMLP(nn.Module):
            def __init__(self, dim: int, ffn_mult: int = 4, dropout: float = 0.1):
                super().__init__()
                hidden = dim * ffn_mult
                self.norm = nn.LayerNorm(dim)
                self.fc1 = nn.Linear(dim, hidden)
                self.act = nn.GELU()
                self.dropout = nn.Dropout(dropout)
                self.fc2 = nn.Linear(hidden, dim)

            def forward(self, x: torch.Tensor) -> torch.Tensor:
                h = self.norm(x)
                h = self.fc1(h)
                h = self.act(h)
                h = self.dropout(h)
                h = self.fc2(h)
                return x + h

        layers = []
        num_layers = int(rp_cfg.get('num_layers', 3))
        ffn_mult = int(rp_cfg.get('ffn_mult', 4))
        dropout = float(rp_cfg.get('dropout', 0.1))
        # ì…ë ¥ ì •ê·œí™” + ì„ í˜• ë§¤í•‘ìœ¼ë¡œ ì§„ì…
        layers.append(nn.LayerNorm(embedding_dim))
        layers.append(nn.Identity())  # ìë¦¬í‘œì‹œì(í˜•íƒœ ìœ ì§€)
        # Residual blocks
        for _ in range(num_layers):
            layers.append(ResidualMLP(embedding_dim, ffn_mult=ffn_mult, dropout=dropout))
        # ìµœì¢… ì •ê·œí™”
        layers.append(nn.LayerNorm(embedding_dim))
        return nn.Sequential(*layers)
    
    def forward(self, 
                batch: Dict[str, Union[torch.Tensor, List[str]]],
                return_embeddings: bool = False) -> Dict[str, torch.Tensor]:
        """
        Forward pass
        
        Args:
            batch: ë°°ì¹˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
                - 'vibration': ì§„ë™ ì‹ í˜¸ (batch_size, input_length)
                - 'text': í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (batch_size,)
            return_embeddings: ì„ë² ë”©ë„ ë°˜í™˜í• ì§€ ì—¬ë¶€
            
        Returns:
            Dict with loss and optionally embeddings
        """
        vibration_signals = batch['vibration']
        texts = batch['text']
        
        device = vibration_signals.device
        
        # Vibration encoding
        vib_embeddings = self.vibration_encoder(vibration_signals)
        
        # Text encoding
        if 'input_ids' in batch and 'attention_mask' in batch:
            # ì´ë¯¸ í† í¬ë‚˜ì´ì§•ëœ ë°ì´í„° ì‚¬ìš© (ë°°ì¹˜ íš¨ìœ¨ì„±)
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            text_embeddings = self.text_encoder.encode_tokenized(input_ids, attention_mask)
        else:
            # í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ì§ì ‘ í† í¬ë‚˜ì´ì§• (í•˜ìœ„ í˜¸í™˜ì„±)
            text_embeddings = self.text_encoder.encode_texts(texts, device, max_length=128)
        
        # ğŸ¯ CRITICAL FIX: Cross-Modal Projection ì ìš©
        text_embeddings = F.normalize(self.text_projection(text_embeddings), p=2, dim=1)
        vib_embeddings = F.normalize(self.vibration_projection(vib_embeddings), p=2, dim=1)
        
        # ğŸ¯ FIXED: í‘œì¤€ contrastive learning (diagonal pairs only)
        # ê° text-vibration ìŒì€ ë°°ì¹˜ ë‚´ì—ì„œ ëŒ€ê°ì„  ìœ„ì¹˜ì—ì„œë§Œ ë§¤ì¹­
        # ë©€í‹°-í¬ì§€í‹°ë¸Œ ë¡œì§ ì œê±° (ì—°êµ¬ ì˜ë„ì— ë§ì§€ ì•ŠìŒ)
        multi_positive = None  # í•­ìƒ Noneìœ¼ë¡œ ì„¤ì •

        # Replay ì„ë² ë”©ì´ ì œê³µë˜ë©´ ë¶„ëª¨(negative pool)ë¥¼ í™•ì¥í•˜ì—¬ InfoNCE ê³„ì‚°
        replay_text = batch.get('replay_text_embeddings', None)
        replay_vib = batch.get('replay_vib_embeddings', None)
        
        if replay_text is not None and replay_vib is not None and replay_text.numel() > 0 and replay_vib.numel() > 0:
            # ğŸ¯ FIXED: í´ë˜ìŠ¤ ê¸°ë°˜ Replay InfoNCE
            text_norm = F.normalize(text_embeddings, p=2, dim=1)
            vib_norm = F.normalize(vib_embeddings, p=2, dim=1)
            replay_text_norm = F.normalize(replay_text.detach(), p=2, dim=1)
            replay_vib_norm = F.normalize(replay_vib.detach(), p=2, dim=1)
            
            # í˜„ì¬ ë°°ì¹˜ + Replay ë°°ì¹˜ ê²°í•©
            all_text = torch.cat([text_norm, replay_text_norm], dim=0)  # (N+R, d)
            all_vib = torch.cat([vib_norm, replay_vib_norm], dim=0)  # (N+R, d)
            
            # í´ë˜ìŠ¤ ë¼ë²¨ ê²°í•© (í˜„ì¬ + replay)
            batch_labels = batch.get('labels', None)
            replay_labels = batch.get('replay_labels', None)
            
            if batch_labels is not None and replay_labels is not None:
                # í˜„ì¬ ë°°ì¹˜ ë¼ë²¨ ì²˜ë¦¬
                if batch_labels.dim() == 2:
                    if batch_labels.size(1) == 2:
                        current_classes = batch_labels[:, 0]  # UOS ì£¼ ë¶„ë¥˜
                    else:
                        current_classes = batch_labels[:, 0]  # CWRU (batch_size, 1)
                else:
                    current_classes = batch_labels  # 1ì°¨ì› ë¼ë²¨
                
                # Replay ë¼ë²¨ ì²˜ë¦¬
                if replay_labels.dim() == 2:
                    if replay_labels.size(1) == 2:
                        replay_classes = replay_labels[:, 0]  # UOS
                    else:
                        replay_classes = replay_labels[:, 0]  # CWRU (batch_size, 1)
                else:
                    replay_classes = replay_labels  # 1ì°¨ì› ë¼ë²¨
                
                all_classes = torch.cat([current_classes, replay_classes], dim=0)
                
                # í´ë˜ìŠ¤ ê¸°ë°˜ positive mask
                positive_mask = (all_classes.unsqueeze(1) == all_classes.unsqueeze(0))
                
                # Text->Vib with replay
                sim_t2v = torch.matmul(text_norm, all_vib.t())
                loss_t2v = self.infonce_loss._class_based_infonce_loss(
                    sim_t2v, positive_mask[:text_norm.size(0)], self.infonce_loss.temperature_text
                )
                
                # Vib->Text with replay  
                sim_v2t = torch.matmul(vib_norm, all_text.t())
                loss_v2t = self.infonce_loss._class_based_infonce_loss(
                    sim_v2t, positive_mask[:vib_norm.size(0)], self.infonce_loss.temperature_vib
                )
                
                loss = (loss_t2v + loss_v2t) / 2.0
                loss_components = {
                    'text_to_vib': loss_t2v,
                    'vib_to_text': loss_v2t,
                    'total': loss
                }
            else:
                # ë¼ë²¨ ì •ë³´ ì—†ìœ¼ë©´ ê¸°ì¡´ diagonal ë°©ì‹
                batch_size = text_norm.size(0)
                labels = torch.arange(batch_size, device=device)
                all_vib = torch.cat([vib_norm, replay_vib_norm], dim=0)
                all_text = torch.cat([text_norm, replay_text_norm], dim=0)
                
                logits_t2v = torch.matmul(text_norm, all_vib.t()) / self.infonce_loss.temperature_text
                logits_v2t = torch.matmul(vib_norm, all_text.t()) / self.infonce_loss.temperature_vib
                
                loss_t2v = F.cross_entropy(logits_t2v, labels, reduction=self.infonce_loss.reduction)
                loss_v2t = F.cross_entropy(logits_v2t, labels, reduction=self.infonce_loss.reduction)
                
                loss = (loss_t2v + loss_v2t) / 2.0
                loss_components = {
                    'text_to_vib': loss_t2v,
                    'vib_to_text': loss_v2t,
                    'total': loss
                }
        else:
            # í‘œì¤€ ë˜ëŠ” ë©€í‹°-í¬ì§€í‹°ë¸Œ InfoNCE
            if multi_positive is None:
                # ğŸ¯ ë¼ë²¨ ì •ë³´ë¥¼ InfoNCEì— ì „ë‹¬
                batch_labels = batch.get('labels', None)
                loss, loss_components = self.infonce_loss(text_embeddings, vib_embeddings, batch_labels)
            else:
                # ğŸ¯ FIXED: í‘œì¤€ L2 ì •ê·œí™” (gradient ë³´ì¡´)
                text_norm = F.normalize(text_embeddings, p=2, dim=1)
                vib_norm = F.normalize(vib_embeddings, p=2, dim=1)
                logits_t2v = torch.matmul(text_norm, vib_norm.t()) / self.infonce_loss.temperature_text
                logits_v2t = torch.matmul(vib_norm, text_norm.t()) / self.infonce_loss.temperature_vib
                pos_t2v = multi_positive
                pos_v2t = multi_positive
                loss_t2v = self._multi_positive_infonce_loss(logits_t2v, pos_t2v)
                loss_v2t = self._multi_positive_infonce_loss(logits_v2t, pos_v2t)
                loss = (loss_t2v + loss_v2t) / 2.0
                loss_components = {
                    'text_to_vib': loss_t2v,
                    'vib_to_text': loss_v2t,
                    'total': loss
                }

        # Bilinear similarity auxiliary loss (optional)
        if self.use_bilinear and self.lambda_bilinear > 0.0:
            # s_ij = t_i^T W v_j, ë©€í‹°-í¬ì§€í‹°ë¸Œ ë§ˆìŠ¤í¬ ê¸°ë°˜ InfoNCEì™€ ë™ì¼í•œ í˜•íƒœë¡œ ì‚¬ìš©
            batch_labels = batch.get('labels', None)
            t = F.normalize(text_embeddings, p=2, dim=1)
            v = F.normalize(vib_embeddings, p=2, dim=1)
            logits_bi = torch.matmul(torch.matmul(t, self.bilinear_W), v.t())
            if batch_labels is not None:
                if batch_labels.dim() == 2:
                    cls = batch_labels[:, 0]
                elif batch_labels.dim() == 1:
                    cls = batch_labels
                else:
                    cls = torch.arange(t.size(0), device=t.device)
                pos_mask = (cls.unsqueeze(1) == cls.unsqueeze(0))
            else:
                # ëŒ€ê°ì„ ë§Œ í¬ì§€í‹°ë¸Œ
                pos_mask = torch.eye(t.size(0), dtype=torch.bool, device=t.device)
            # ì˜¨ë„ëŠ” text ë°©í–¥ ê²ƒì„ ì‚¬ìš©
            bi_loss = self.infonce_loss._class_based_infonce_loss(logits_bi, pos_mask, self.infonce_loss.temperature_text)
            loss = loss + self.lambda_bilinear * bi_loss
            loss_components['bilinear'] = bi_loss

        # Prototype alignment loss (optional)
        if self.use_prototypes:
            proto_loss = None
            labels_for_proto = batch.get('labels', None)
            if labels_for_proto is not None:
                # ë¼ë²¨ ì •ê·œí™”: UOS (B,2) => ì²«ë²ˆì§¸ ì—´, CWRU (B,1) => ì—´ 0, 1D => ê·¸ëŒ€ë¡œ
                if labels_for_proto.dim() == 2:
                    class_labels = labels_for_proto[:, 0]
                elif labels_for_proto.dim() == 1:
                    class_labels = labels_for_proto
                else:
                    class_labels = None

                if class_labels is not None:
                    class_labels = class_labels.clamp(min=0, max=self.num_classes - 1)
                    # í”„ë¡œí† íƒ€ì… ì •ê·œí™” í›„ ë¡œì§“ ê³„ì‚°
                    proto_norm = F.normalize(self.prototypes, p=2, dim=1)
                    logits_text_proto = torch.matmul(text_embeddings, proto_norm.t()) / self.prototype_tau
                    logits_vib_proto = torch.matmul(vib_embeddings, proto_norm.t()) / self.prototype_tau
                    ce_text = F.cross_entropy(logits_text_proto, class_labels)
                    ce_vib = F.cross_entropy(logits_vib_proto, class_labels)
                    proto_loss = (ce_text + ce_vib) * 0.5
                    loss = loss + self.prototype_lambda * proto_loss
                    loss_components['proto_ce'] = proto_loss

                    # ì´ˆê¸°í™”(í…ìŠ¤íŠ¸ ê¸°ë°˜ í‰ê· ) ë° EMA ì—…ë°ì´íŠ¸
                    with torch.no_grad():
                        # ë°°ì¹˜ í´ë˜ìŠ¤ë³„ í‰ê·  (í…ìŠ¤íŠ¸/ì§„ë™ í‰ê· ì„ í•¨ê»˜ ì‚¬ìš©)
                        unique_classes = class_labels.unique()
                        for cls in unique_classes.tolist():
                            mask = (class_labels == cls)
                            if mask.any():
                                mean_t = text_embeddings[mask].mean(dim=0)
                                mean_v = vib_embeddings[mask].mean(dim=0)
                                mean_tv = F.normalize(0.5 * (mean_t + mean_v), p=2, dim=0)

                                if (self.prototypes_initialized.item() == 0) and self.prototype_init_from_text:
                                    # ìµœì´ˆ í•œ ë²ˆ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ë” ê°•í•˜ê²Œ ì´ˆê¸°í™”
                                    self.prototypes.data[cls] = mean_tv
                                else:
                                    # EMA ì—…ë°ì´íŠ¸
                                    current = F.normalize(self.prototypes.data[cls], p=2, dim=0)
                                    updated = self.prototype_ema_m * current + (1.0 - self.prototype_ema_m) * mean_tv
                                    self.prototypes.data[cls] = F.normalize(updated, p=2, dim=0)

                        if self.prototypes_initialized.item() == 0:
                            self.prototypes_initialized.fill_(1)

        # ğŸ¯ CRITICAL FIX: CWRU ì „ìš© ê°•í™”ëœ Auxiliary Classification
        aux_cfg = MODEL_CONFIG.get('aux_classification', {'enabled': False})
        if aux_cfg.get('enabled', False):
            aux_labels = batch.get('labels', None)
            if aux_labels is not None:
                if aux_labels.dim() == 2 and aux_labels.size(1) >= 1:
                    # UOS: ì²« ë²ˆì§¸ê°€ ì£¼ ë¶„ë¥˜ (7-í´ë˜ìŠ¤)
                    main_class = aux_labels[:, 0]
                    if hasattr(self.vibration_encoder, 'use_aux_head') and self.vibration_encoder.use_aux_head:
                        logits_cls = self.vibration_encoder.aux_head(vib_embeddings)
                        ce_loss = F.cross_entropy(logits_cls, main_class)
                        loss = loss + float(aux_cfg.get('loss_weight', 1.0)) * ce_loss
                        loss_components['aux_ce'] = ce_loss
                elif aux_labels.dim() == 1:
                    # ğŸ¯ CWRU: ê°•í™”ëœ ì§ì ‘ ë¶„ë¥˜ (contrastive learning ë³´ì™„)
                    if hasattr(self.vibration_encoder, 'use_aux_head') and self.vibration_encoder.use_aux_head:
                        logits_cls = self.vibration_encoder.aux_head(vib_embeddings)
                        ce_loss = F.cross_entropy(logits_cls, aux_labels)
                        
                        # CWRUì—ì„œëŠ” auxiliary lossë¥¼ ì£¼ìš” lossë¡œ ê°•í™”
                        aux_weight = float(aux_cfg.get('loss_weight', 3.0))
                        if hasattr(batch, 'get') and 'metadata' in batch:
                            # CWRU ë°ì´í„°ì¸ì§€ í™•ì¸
                            metadata_sample = batch['metadata'][0] if batch['metadata'] else {}
                            if metadata_sample.get('dataset_type') == 'cwru':
                                aux_weight = 10.0  # CWRUì—ì„œëŠ” 10ë°° ê°•í™”
                        
                        loss = loss + aux_weight * ce_loss
                        loss_components['aux_ce'] = ce_loss
                        loss_components['aux_weight'] = aux_weight
        
        # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
        results = {
            'loss': loss,
            'loss_components': loss_components
        }
        
        if return_embeddings:
            results.update({
                'text_embeddings': text_embeddings,
                'vib_embeddings': vib_embeddings
            })
        
        return results

    def _multi_positive_infonce_loss(self, logits: torch.Tensor, positive_mask: torch.Tensor) -> torch.Tensor:
        """ë©€í‹°-í¬ì§€í‹°ë¸Œ InfoNCE ì†ì‹¤
        Args:
            logits: (N, M) ìœ ì‚¬ë„ ë¡œì§“
            positive_mask: (N, M) bool í…ì„œ, ì–‘ì„± ìœ„ì¹˜ True
        Returns:
            ìŠ¤ì¹¼ë¼ ì†ì‹¤ (mean)
        """
        # AMP(half)ì—ì„œì˜ overflow íšŒí”¼: ì—°ì‚°ì„ float32ë¡œ ìˆ˜í–‰
        logits_f32 = logits.float()
        # ì •ê·œí™”ë¥¼ ìœ„í•œ log-sum-exp (ë¶„ëª¨)
        log_denom = torch.logsumexp(logits_f32, dim=1)  # (N,)
        # ì–‘ì„± ë¡œì§“ë§Œ ë‚¨ê¸°ê³  log-sum-exp (ë¶„ì)
        # ëª¨ë“  í–‰ì— ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ì–‘ì„±ì´ ì¡´ì¬í•œë‹¤ê³  ê°€ì • (ìê¸° ìì‹  í¬í•¨)
        masked_logits = logits_f32.masked_fill(~positive_mask, -1e4)
        log_num = torch.logsumexp(masked_logits, dim=1)  # (N,)
        loss_vec = -(log_num - log_denom)
        return loss_vec.mean()
    
    def encode_text(self, texts: List[str], device: torch.device) -> torch.Tensor:
        """í…ìŠ¤íŠ¸ë§Œ ì¸ì½”ë”© (ì¶”ë¡ ìš©)"""
        return self.text_encoder.encode_texts(texts, device)
    
    def encode_vibration(self, vibration_signals: torch.Tensor) -> torch.Tensor:
        """ì§„ë™ ì‹ í˜¸ë§Œ ì¸ì½”ë”© (ì¶”ë¡ ìš©)"""
        return self.vibration_encoder(vibration_signals)
    
    def switch_to_continual_mode(self):
        """Continual learning ëª¨ë“œë¡œ ì „í™˜"""
        self.is_continual_mode = True
        
        # ğŸ¯ CRITICAL FIX: Text encoder ë¶€ë¶„ freeze (ì™„ì „ freeze ë¬¸ì œ í•´ê²°)
        # LoRAëŠ” freezeí•˜ë˜, projection layerëŠ” í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ ìœ ì§€
        self.text_encoder.disable_lora_training()
        
        # Projection layerëŠ” í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ ìœ ì§€ (ìµœì†Œí•œì˜ adaptation)
        if hasattr(self.text_encoder, 'projection'):
            for param in self.text_encoder.projection.parameters():
                param.requires_grad = True  # False â†’ True (í•™ìŠµ ê°€ëŠ¥)
        
        # InfoNCE temperature ì—…ë°ì´íŠ¸
        temp_text = MODEL_CONFIG['infonce']['continual_temperature_text']
        temp_vib = MODEL_CONFIG['infonce']['continual_temperature_vib']
        self.infonce_loss.update_temperatures(temp_text, temp_vib)
        
        logger.info("Continual learning ëª¨ë“œë¡œ ì „í™˜ ì™„ë£Œ (LoRA freeze, Projection í•™ìŠµ ê°€ëŠ¥)")
    
    def switch_to_first_domain_mode(self):
        """First domain training ëª¨ë“œë¡œ ì „í™˜"""
        self.is_continual_mode = False
        
        # Text encoder LoRA í•™ìŠµ í™œì„±í™”
        self.text_encoder.enable_lora_training()
        # LoRA íŒŒë¼ë¯¸í„° ê°œìˆ˜/í•™ìŠµ ê°€ëŠ¥ ìƒíƒœ ë¡œê¹…
        try:
            lora_params_total = 0
            lora_params_trainable = 0
            for name, p in self.text_encoder.distilbert.named_parameters():
                if 'lora_' in name:
                    lora_params_total += p.numel()
                    if p.requires_grad:
                        lora_params_trainable += p.numel()
            logger.info(
                f"LoRA íŒŒë¼ë¯¸í„° ìƒíƒœ: total={lora_params_total:,}, trainable={lora_params_trainable:,}"
            )
        except Exception as e:
            logger.info(f"LoRA íŒŒë¼ë¯¸í„° ìƒíƒœ í™•ì¸ ìŠ¤í‚µ: {e}")
        
        # Projection layer ì¬í™œì„±í™”
        if hasattr(self.text_encoder, 'projection'):
            for param in self.text_encoder.projection.parameters():
                param.requires_grad = True
        
        # InfoNCE temperature ì—…ë°ì´íŠ¸
        temp_text = MODEL_CONFIG['infonce']['first_domain_temperature_text']
        temp_vib = MODEL_CONFIG['infonce']['first_domain_temperature_vib']
        self.infonce_loss.update_temperatures(temp_text, temp_vib)
        
        logger.info("First domain training ëª¨ë“œë¡œ ì „í™˜ ì™„ë£Œ (TextEncoder í™œì„±í™”)")
    
    # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
    def switch_to_joint_mode(self):
        """í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­"""
        return self.switch_to_first_domain_mode()
    
    def get_trainable_parameters(self) -> Dict[str, int]:
        """ê° ì»´í¬ë„ŒíŠ¸ë³„ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ ë°˜í™˜"""
        text_params = self.text_encoder.get_trainable_parameters()
        text_lora_params = self.text_encoder.get_lora_parameters()
        vib_params = self.vibration_encoder.get_trainable_parameters()
        
        return {
            'text_total': text_params,
            'text_lora': text_lora_params,
            'vibration': vib_params,
            'total': text_params + vib_params
        }
    
    def save_checkpoint(self, path: str, epoch: int, optimizer_state: Optional[Dict] = None):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.state_dict(),
            'domain_stage': self.domain_stage,
            'embedding_dim': self.embedding_dim,
            'is_continual_mode': self.is_continual_mode
        }
        
        if optimizer_state is not None:
            checkpoint['optimizer_state_dict'] = optimizer_state
        
        torch.save(checkpoint, path)
        logger.info(f"ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: {path}")
    
    def load_checkpoint(self, path: str, device: torch.device) -> Dict:
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë”©"""
        checkpoint = torch.load(path, map_location=device)
        
        self.load_state_dict(checkpoint['model_state_dict'])
        
        # ëª¨ë“œ ë³µì›
        if checkpoint.get('is_continual_mode', False):
            self.switch_to_continual_mode()
        else:
            self.switch_to_first_domain_mode()
        
        logger.info(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì™„ë£Œ: {path}")
        
        return checkpoint


def create_textvib_model(domain_stage: str = 'first_domain') -> TextVibCLIP:
    """
    ë„ë©”ì¸ ë‹¨ê³„ì— ë”°ë¥¸ TextVibCLIP ëª¨ë¸ ìƒì„±
    
    Args:
        domain_stage (str): 'first_domain' (Domain 1) ë˜ëŠ” 'continual' (Domain 2+)
        
    Returns:
        TextVibCLIP: ì„¤ì •ëœ ëª¨ë¸
    """
    model = TextVibCLIP(domain_stage=domain_stage)
    
    # íŒŒë¼ë¯¸í„° ì •ë³´ ì¶œë ¥
    param_info = model.get_trainable_parameters()
    logger.info(f"TextVibCLIP ìƒì„± ì™„ë£Œ: {domain_stage} stage")
    logger.info(f"Text encoder íŒŒë¼ë¯¸í„°: {param_info['text_total']:,} "
               f"(LoRA: {param_info['text_lora']:,})")
    logger.info(f"Vibration encoder íŒŒë¼ë¯¸í„°: {param_info['vibration']:,}")
    logger.info(f"ì´ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°: {param_info['total']:,}")
    
    return model


def compute_similarity_scores(text_embeddings: torch.Tensor, 
                            vib_embeddings: torch.Tensor) -> torch.Tensor:
    """
    í…ìŠ¤íŠ¸ì™€ ì§„ë™ ì„ë² ë”© ê°„ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° (ì¶”ë¡ ìš©)
    
    Args:
        text_embeddings: (num_texts, embedding_dim)
        vib_embeddings: (num_vibs, embedding_dim)
        
    Returns:
        torch.Tensor: ìœ ì‚¬ë„ í–‰ë ¬ (num_texts, num_vibs)
    """
    # ğŸ¯ FIXED: í‘œì¤€ L2 ì •ê·œí™” (gradient ë³´ì¡´)
    text_embeddings = F.normalize(text_embeddings, p=2, dim=1)
    vib_embeddings = F.normalize(vib_embeddings, p=2, dim=1)
    
    # Cosine similarity
    similarity_matrix = torch.matmul(text_embeddings, vib_embeddings.t())
    
    return similarity_matrix


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    print("=== TextVibCLIP í…ŒìŠ¤íŠ¸ ===")
    
    # First domain training ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("\n1. First Domain Training ëª¨ë¸")
    model_first = create_textvib_model('first_domain')
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    batch_size = 4
    input_length = MODEL_CONFIG['vibration_encoder']['input_length']
    
    test_batch = {
        'vibration': torch.randn(batch_size, input_length),
        'text': [
            "A deep groove ball bearing operating at 600 rpm with healthy rotating component and ball fault.",
            "A tapered roller bearing operating at 800 rpm with healthy rotating component and healthy bearing.",
            "A cylindrical roller bearing operating at 1000 rpm with unbalanced rotating component and inner race fault.",
            "A deep groove ball bearing operating at 1200 rpm with healthy rotating component and outer race fault."
        ]
    }
    
    # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ì´ë™
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model_first.to(device)
    test_batch['vibration'] = test_batch['vibration'].to(device)
    
    # Forward pass í…ŒìŠ¤íŠ¸
    results = model_first(test_batch, return_embeddings=True)
    
    print(f"Loss: {results['loss'].item():.4f}")
    print(f"Text embeddings shape: {results['text_embeddings'].shape}")
    print(f"Vibration embeddings shape: {results['vib_embeddings'].shape}")
    
    # Continual learning ëª¨ë“œ ì „í™˜ í…ŒìŠ¤íŠ¸
    print("\n2. Continual Learning ëª¨ë“œ ì „í™˜")
    model_first.switch_to_continual_mode()
    
    results_continual = model_first(test_batch, return_embeddings=True)
    print(f"Continual mode loss: {results_continual['loss'].item():.4f}")
    
    # ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸
    print("\n3. ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸")
    similarity_matrix = compute_similarity_scores(
        results['text_embeddings'], 
        results['vib_embeddings']
    )
    print(f"Similarity matrix shape: {similarity_matrix.shape}")
    print(f"Diagonal (positive pairs): {torch.diag(similarity_matrix)}")
    
    print("\n=== TextVibCLIP í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
