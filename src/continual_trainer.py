"""
Continual Trainer: TextVibCLIP Continual Learning ÌååÏù¥ÌîÑÎùºÏù∏
DomainÎ≥Ñ ÏàúÏ∞® ÌïôÏäµ Î∞è ÏÑ±Îä• ÌèâÍ∞Ä Í¥ÄÎ¶¨
"""

import os
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from typing import Dict, List, Tuple, Optional, Any, Union
import logging
import numpy as np
from collections import defaultdict, Counter
import matplotlib.pyplot as plt

from .textvib_model import TextVibCLIP, create_textvib_model
from .replay_buffer import ReplayBuffer
from .data_loader import create_domain_dataloaders, create_combined_dataloader, create_first_domain_dataloader
from .data_cache import create_cached_first_domain_dataloader
from .utils import setup_amp_and_scaler
from configs.model_config import TRAINING_CONFIG, DATA_CONFIG, EVAL_CONFIG, MODEL_CONFIG, CWRU_DATA_CONFIG

logger = logging.getLogger(__name__)


class ContinualTrainer:
    """
    TextVibCLIP Continual Learning Trainer
    
    DomainÎ≥Ñ ÏàúÏ∞® ÌïôÏäµ, Replay mechanism, ÏÑ±Îä• ÌèâÍ∞Ä Í¥ÄÎ¶¨
    """
    
    def __init__(self,
                 model: Optional[TextVibCLIP] = None,
                 device: torch.device = torch.device('cpu'),
                 save_dir: str = 'checkpoints',
                 use_amp: bool = True,
                 max_grad_norm: float = 0.1,
                 domain_order: List[Union[int, str]] = None,
                 data_dir: Optional[str] = None,
                 dataset_type: str = DATA_CONFIG.get('dataset_type', 'uos'),
                 patience: Optional[int] = None):
        """
        Args:
            model (TextVibCLIP, optional): ÏÇ¨Ï†Ñ Ï¥àÍ∏∞ÌôîÎêú Î™®Îç∏
            device (torch.device): ÌïôÏäµ ÎîîÎ∞îÏù¥Ïä§
            save_dir (str): Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• Í≤ΩÎ°ú
            use_amp (bool): AMP ÏÇ¨Ïö© Ïó¨Î∂Ä
            max_grad_norm (float): Gradient clipping ÏµúÎåÄ norm
            domain_order (List[Union[int, str]]): ÎèÑÎ©îÏù∏ ÏàúÏÑú (ÏóÜÏúºÎ©¥ Í∏∞Î≥∏Í∞í ÏÇ¨Ïö©)
        """
        self.device = device
        self.save_dir = save_dir
        self.max_grad_norm = max_grad_norm
        os.makedirs(save_dir, exist_ok=True)
        
        # AMP ÏÑ§Ï†ï
        self.scaler, self.use_amp = setup_amp_and_scaler(device, use_amp)
        
        # Î™®Îç∏ Ï¥àÍ∏∞Ìôî
        if model is None:
            self.model = create_textvib_model('first_domain')
        else:
            self.model = model
        
        self.model.to(device)
        
        # Replay buffer
        self.replay_buffer = ReplayBuffer()
        
        # ÌïôÏäµ ÏÉÅÌÉú Í¥ÄÎ¶¨
        self.current_domain_idx = 0
        self.completed_domains = []
        self.domain_order = domain_order if domain_order is not None else DATA_CONFIG['domain_order']
        # Îç∞Ïù¥ÌÑ∞ ÏÑ§Ï†ï (ÌèâÍ∞Ä Ïãú ÏùºÍ¥ÄÏÑ± Ïú†ÏßÄ)
        self.data_dir = data_dir if data_dir is not None else DATA_CONFIG['data_dir']
        self.dataset_type = dataset_type
        
        # ÏÑ±Îä• Ï∂îÏ†Å
        self.performance_history = defaultdict(list)  # {domain: [accuracy_list]}
        self.loss_history = defaultdict(list)
        self.forgetting_scores = []
        
        # ÌïôÏäµ ÏÑ§Ï†ï
        self.batch_size = TRAINING_CONFIG['batch_size']
        self.num_epochs = TRAINING_CONFIG['num_epochs']
        self.learning_rate = TRAINING_CONFIG['learning_rate']
        self.weight_decay = TRAINING_CONFIG['weight_decay']
        self.replay_ratio = TRAINING_CONFIG['replay_ratio']
        self.grad_accum_steps = int(TRAINING_CONFIG.get('grad_accum_steps', 1))
        self.patience = int(patience) if patience is not None else int(TRAINING_CONFIG.get('patience', 10))
        
        logger.info(f"ContinualTrainer Ï¥àÍ∏∞Ìôî ÏôÑÎ£å: device={device}")
    
    def train_first_domain(self, 
                         first_domain_dataloader: Optional[DataLoader] = None,
                         num_epochs: int = None) -> Dict[str, float]:
        """
        Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏(600 RPM) ÌïôÏäµ
        ÌÖçÏä§Ìä∏-ÏßÑÎèô Ï†ïÎ†¨ÏùÑ ÏúÑÌïú Ï¥àÍ∏∞ ÌïôÏäµ Îã®Í≥Ñ
        
        Args:
            first_domain_dataloader (DataLoader, optional): Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏ Îç∞Ïù¥ÌÑ∞Î°úÎçî
            num_epochs (int, optional): ÌïôÏäµ ÏóêÌè¨ÌÅ¨ Ïàò
            
        Returns:
            Dict[str, float]: ÌïôÏäµ Í≤∞Í≥º Î©îÌä∏Î¶≠
        """
        logger.info("=== First Domain Training ÏãúÏûë (600 RPM) ===")
        
        # Îç∞Ïù¥ÌÑ∞Î°úÎçî Ï§ÄÎπÑ
        if first_domain_dataloader is None:
            # ÏãúÎÇòÎ¶¨Ïò§Ïóê ÎßûÎäî dataset_typeÍ≥º data_dir ÏÇ¨Ïö©
            if hasattr(self, 'dataset_type'):
                dataset_type = self.dataset_type
            else:
                dataset_type = 'uos'  # Í∏∞Î≥∏Í∞í
            
            if hasattr(self, 'data_dir'):
                data_dir = self.data_dir
            else:
                data_dir = DATA_CONFIG['data_dir'] if dataset_type == 'uos' else CWRU_DATA_CONFIG['data_dir']
            
            if hasattr(self, 'domain_order'):
                domain_order = self.domain_order
            else:
                domain_order = DATA_CONFIG['domain_order'] if dataset_type == 'uos' else CWRU_DATA_CONFIG['domain_order']
            
            # üöÄ Ï∫êÏãúÎêú DataLoader ÏÇ¨Ïö© (Í≥†ÏÜçÌôî)
            first_domain_dataloader = create_cached_first_domain_dataloader(
                data_dir=data_dir,
                domain_order=domain_order,
                dataset_type=dataset_type,
                subset='train', 
                batch_size=self.batch_size
            )
        
        if num_epochs is None:
            num_epochs = self.num_epochs
        
        # Î™®Îç∏ÏùÑ Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏ ÌïôÏäµ Î™®ÎìúÎ°ú ÏÑ§Ï†ï
        self.model.switch_to_first_domain_mode()  # First domain mode (LoRA ÌôúÏÑ±Ìôî)
        
        # Optimizer ÏÑ§Ï†ï (Text LoRA + Vibration full)
        optimizer = self._create_optimizer()
        scheduler = self._create_scheduler(optimizer, len(first_domain_dataloader) * num_epochs)
        
        # ÎîîÎ≤ÑÍ∑∏/Î™®ÎãàÌÑ∞ÎßÅÏö©: Í∑∏ÎùºÎîîÏñ∏Ìä∏ ÎÖ∏Î¶Ñ Í∏∞Î°ù Î≤ÑÌçº
        if not hasattr(self, 'debug_grad_norms'):
            self.debug_grad_norms = []  # Í∞Å Ìï≠Î™©: {'step': int, 'text_lora': float, 'vib': float}

        # ÌïôÏäµ Î£®ÌîÑ
        self.model.train()
        epoch_losses = []
        
        for epoch in range(num_epochs):
            # Ï≤´ ÎèÑÎ©îÏù∏ Ïò®ÎèÑ Ïä§ÏºÄÏ§Ñ(ÏÑ†Ìòï): init -> final
            inf_cfg = MODEL_CONFIG.get('infonce', {})
            t_text_init = float(inf_cfg.get('first_domain_temperature_text_init',
                                            inf_cfg.get('first_domain_temperature_text', 0.10)))
            t_text_final = float(inf_cfg.get('first_domain_temperature_text_final',
                                             inf_cfg.get('first_domain_temperature_text', 0.10)))
            t_vib_init  = float(inf_cfg.get('first_domain_temperature_vib_init',
                                            inf_cfg.get('first_domain_temperature_vib', 0.10)))
            t_vib_final = float(inf_cfg.get('first_domain_temperature_vib_final',
                                            inf_cfg.get('first_domain_temperature_vib', 0.10)))
            if num_epochs > 1:
                ratio = epoch / (num_epochs - 1)
            else:
                ratio = 1.0
            t_text = t_text_init + (t_text_final - t_text_init) * ratio
            t_vib  = t_vib_init  + (t_vib_final  - t_vib_init)  * ratio
            self.model.infonce_loss.update_temperatures(t_text, t_vib)
            if epoch % 5 == 0 or epoch == 0:
                logger.info(f"[TempSchedule] epoch {epoch+1}/{num_epochs}: œÑ_text={t_text:.3f}, œÑ_vib={t_vib:.3f}")

            epoch_loss = 0.0
            num_batches = 0
            
            for batch_idx, batch in enumerate(first_domain_dataloader):
                # Î∞∞ÏπòÎ•º ÎîîÎ∞îÏù¥Ïä§Î°ú Ïù¥Îèô
                batch = self._move_batch_to_device(batch)
                
                # Forward pass
                # grad accumulation: ÏÇ¨Ïù¥ÌÅ¥ ÏãúÏûëÏãúÏóêÎßå zero_grad
                if (batch_idx % self.grad_accum_steps) == 0:
                    optimizer.zero_grad(set_to_none=True)
                
                if self.use_amp:
                    with torch.cuda.amp.autocast():
                        results = self.model(batch)
                        loss = results['loss'] / self.grad_accum_steps
                    
                    # Backward pass with AMP + grad accumulation
                    self.scaler.scale(loss).backward()
                    
                    if (batch_idx + 1) % self.grad_accum_steps == 0:
                        # Gradient clipping Î∞è grad norm Ï∏°Ï†ï Ï§ÄÎπÑÎ•º ÏúÑÌïú unscale (ÏÇ¨Ïù¥ÌÅ¥ ÎÅùÏóêÏÑúÎßå)
                        if self.max_grad_norm > 0:
                            self.scaler.unscale_(optimizer)
                            # ÎîîÎ≤ÑÍ∑∏: grad norm Ï∏°Ï†ï (ÌÖçÏä§Ìä∏ LoRA, ÏßÑÎèô Ïù∏ÏΩîÎçî)
                            try:
                                text_lora_params = [
                                    p for n, p in self.model.text_encoder.distilbert.named_parameters()
                                    if ('lora_' in n) and p.requires_grad and (p.grad is not None)
                                ]
                            except Exception:
                                text_lora_params = []
                            vib_params = [
                                p for p in self.model.vibration_encoder.parameters()
                                if p.requires_grad and (p.grad is not None)
                            ]
                            def _global_grad_norm(params):
                                if not params:
                                    return 0.0
                                import math
                                total = 0.0
                                for p in params:
                                    if p.grad is not None:
                                        param_norm = p.grad.data.float().norm(2).item()
                                        total += param_norm * param_norm
                                return math.sqrt(total)
                            grad_norm_text = _global_grad_norm(text_lora_params)
                            grad_norm_vib = _global_grad_norm(vib_params)
                            if batch_idx % 50 == 0:
                                self.debug_grad_norms.append({
                                    'epoch': epoch + 1,
                                    'batch': batch_idx,
                                    'text_lora': float(grad_norm_text),
                                    'vib': float(grad_norm_vib)
                                })
                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                        self.scaler.step(optimizer)
                        self.scaler.update()
                else:
                    results = self.model(batch)
                    loss = results['loss'] / self.grad_accum_steps
                    
                    # Backward pass
                    loss.backward()
                    
                    if (batch_idx + 1) % self.grad_accum_steps == 0:
                        # Gradient clipping Î∞è grad norm Ï∏°Ï†ï (ÏÇ¨Ïù¥ÌÅ¥ ÎÅùÏóêÏÑúÎßå)
                        if self.max_grad_norm > 0:
                            try:
                                text_lora_params = [
                                    p for n, p in self.model.text_encoder.distilbert.named_parameters()
                                    if ('lora_' in n) and p.requires_grad and (p.grad is not None)
                                ]
                            except Exception:
                                text_lora_params = []
                            vib_params = [
                                p for p in self.model.vibration_encoder.parameters()
                                if p.requires_grad and (p.grad is not None)
                            ]
                            def _global_grad_norm(params):
                                if not params:
                                    return 0.0
                                import math
                                total = 0.0
                                for p in params:
                                    if p.grad is not None:
                                        param_norm = p.grad.data.float().norm(2).item()
                                        total += param_norm * param_norm
                                return math.sqrt(total)
                            grad_norm_text = _global_grad_norm(text_lora_params)
                            grad_norm_vib = _global_grad_norm(vib_params)
                            if batch_idx % 50 == 0:
                                self.debug_grad_norms.append({
                                    'epoch': epoch + 1,
                                    'batch': batch_idx,
                                    'text_lora': float(grad_norm_text),
                                    'vib': float(grad_norm_vib)
                                })
                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                        optimizer.step()
                
                if (batch_idx + 1) % self.grad_accum_steps == 0:
                    scheduler.step()
                
                epoch_loss += loss.item()
                num_batches += 1
                
                # Î°úÍπÖ (Ï†ÅÏ†àÌïú Í∞ÑÍ≤©ÏúºÎ°ú)
                if batch_idx % 50 == 0:
                    logger.info(f"First Domain Epoch {epoch+1}/{num_epochs}, "
                               f"Batch {batch_idx}, Loss: {loss.item():.4f}")
            
            avg_epoch_loss = epoch_loss / num_batches
            epoch_losses.append(avg_epoch_loss)
            
            logger.info(f"First Domain Epoch {epoch+1} ÏôÑÎ£å: Avg Loss = {avg_epoch_loss:.4f}")
        
        # Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏ÏúºÎ°ú ÌëúÏãú
        first_domain = self.domain_order[0]
        self.completed_domains.append(first_domain)
        self.loss_history[first_domain] = epoch_losses
        
        # Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû•
        checkpoint_path = os.path.join(self.save_dir, 'first_domain_final.pth')
        self.model.save_checkpoint(checkpoint_path, num_epochs, optimizer.state_dict())
        
        # Ï†ÑÏ≤¥ ÎèÑÎ©îÏù∏ ÏÑ±Îä• ÌèâÍ∞Ä
        domain_dataloaders = create_domain_dataloaders(
            data_dir=self.data_dir,
            domain_order=self.domain_order,
            dataset_type=self.dataset_type,
            batch_size=self.batch_size
        )
        first_domain_performance = self._evaluate_all_domains(domain_dataloaders)
        
        # ÏÑ±Îä• Í∏∞Î°ù (Î™®Îì† Î©îÌä∏Î¶≠ Ï†ÄÏû•)
        first_domain_accuracy = 0.0
        for domain, metrics in first_domain_performance.items():
            if domain not in self.performance_history:
                self.performance_history[domain] = {'accuracy': [], 'top1_retrieval': [], 'top5_retrieval': []}
            
            self.performance_history[domain]['accuracy'].append(metrics['accuracy'])
            self.performance_history[domain]['top1_retrieval'].append(metrics.get('top1_retrieval', 0.0))
            self.performance_history[domain]['top5_retrieval'].append(metrics.get('top5_retrieval', 0.0))
            
            # Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏ Ï†ïÌôïÎèÑ Í∏∞Î°ù
            first_domain_accuracy = metrics['accuracy']
            break  # Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏Îßå ÌôïÏù∏
        
        # Ï°∞Í∏∞ Ï¢ÖÎ£å Ï≤¥ÌÅ¨ ÎπÑÌôúÏÑ±Ìôî (ÎîîÎ≤ÑÍπÖ Î∞è Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏ ÌÖåÏä§Ìä∏Ïö©)
        # if first_domain_accuracy < 0.80:
        #     error_msg = f"‚ùå Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏ Ï†ïÌôïÎèÑ {first_domain_accuracy:.4f} < 0.80 (80%)"
        #     logger.error(error_msg)
        #     logger.error("üõë Ïã§Ìóò ÏùòÎØ∏ ÏóÜÏùå - Ï°∞Í∏∞ Ï¢ÖÎ£å!")
        #     raise RuntimeError(f"First domain accuracy too low: {first_domain_accuracy:.4f} < 0.80")
        # else:
        logger.info(f"üìä Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏ Ï†ïÌôïÎèÑ: {first_domain_accuracy:.4f} (Ï°∞Í∏∞ Ï¢ÖÎ£å ÎπÑÌôúÏÑ±Ìôî)")
        
        logger.info("=== First Domain Training ÏôÑÎ£å ===")
        
        # üé® First Domain Alignment ÏãúÍ∞ÅÌôî ÏÉùÏÑ±
        logger.info("üìä First Domain Alignment ÏãúÍ∞ÅÌôî ÏÉùÏÑ± Ï§ë...")
        try:
            alignment_results = self._create_first_domain_alignment_visualization(
                domain_dataloaders, first_domain
            )
            logger.info(f"‚úÖ Alignment ÏãúÍ∞ÅÌôî ÏôÑÎ£å: {alignment_results.get('save_path', 'N/A')}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Alignment ÏãúÍ∞ÅÌôî Ïã§Ìå®: {e}")
            alignment_results = {}
        
        # grad norm ÏöîÏïΩ
        grad_text_vals = [d['text_lora'] for d in self.debug_grad_norms] if hasattr(self, 'debug_grad_norms') else []
        grad_vib_vals = [d['vib'] for d in self.debug_grad_norms] if hasattr(self, 'debug_grad_norms') else []
        grad_summary = {
            'text_lora_mean': float(np.mean(grad_text_vals)) if grad_text_vals else 0.0,
            'vib_mean': float(np.mean(grad_vib_vals)) if grad_vib_vals else 0.0,
            'samples': len(self.debug_grad_norms) if hasattr(self, 'debug_grad_norms') else 0
        }

        return {
            'final_loss': epoch_losses[-1],
            'avg_loss': np.mean(epoch_losses),
            'domain_performances': first_domain_performance,
            'grad_norms_summary': grad_summary,
            'alignment_visualization': alignment_results  # ÏãúÍ∞ÅÌôî Í≤∞Í≥º Ï∂îÍ∞Ä
        }
    
    def train_remaining_domains(self, domain_dataloaders: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ÎÇòÎ®∏ÏßÄ ÎèÑÎ©îÏù∏Îì§(800~1600 RPM) ÏàúÏ∞® ÌïôÏäµ
        Replay mechanismÏùÑ ÌôúÏö©Ìïú Ï†êÏßÑÏ†Å ÌïôÏäµ
        
        Args:
            domain_dataloaders (Dict, optional): ÎèÑÎ©îÏù∏Î≥Ñ Îç∞Ïù¥ÌÑ∞Î°úÎçî
            
        Returns:
            Dict[str, Any]: ÌïôÏäµ Í≤∞Í≥º Î∞è Î©îÌä∏Î¶≠
        """
        logger.info("=== Remaining Domains Training ÏãúÏûë (800~1600 RPM) ===")
        
        # Îç∞Ïù¥ÌÑ∞Î°úÎçî Ï§ÄÎπÑ
        if domain_dataloaders is None:
            domain_dataloaders = create_domain_dataloaders(batch_size=self.batch_size)
        
        # Continual modeÎ°ú Ï†ÑÌôò (Text freeze, Vibration adaptation)
        self.model.switch_to_continual_mode()
        
        remaining_domains_results = {}
        after_performance = {}  # Ï¥àÍ∏∞Ìôî
        
        # Domain 2Î∂ÄÌÑ∞ ÏàúÏ∞® ÌïôÏäµ (Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏ÏùÄ Ïù¥ÎØ∏ ÏôÑÎ£å)
        for domain_idx in range(1, len(self.domain_order)):
            domain_value = self.domain_order[domain_idx]
            
            logger.info(f"\n--- Domain {domain_value} ÌïôÏäµ ÏãúÏûë ---")
            
            # ÌòÑÏû¨ ÎèÑÎ©îÏù∏ Îç∞Ïù¥ÌÑ∞Î°úÎçî (ÌÇ§ Ï°¥Ïû¨ ÌôïÏù∏)
            if domain_value not in domain_dataloaders:
                logger.error(f"ÎèÑÎ©îÏù∏ {domain_value}Í∞Ä dataloadersÏóê ÏóÜÏäµÎãàÎã§. ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÎèÑÎ©îÏù∏: {list(domain_dataloaders.keys())}")
                continue
                
            current_train_loader = domain_dataloaders[domain_value]['train']
            current_val_loader = domain_dataloaders[domain_value]['val']
            
            # Ïù¥Ï†Ñ ÎèÑÎ©îÏù∏ ÏÑ±Îä• Í∏∞Î°ù (Forgetting Í≥ÑÏÇ∞Ïö©) - Í∞ÑÏÜåÌôî
            logger.info(f"Domain {domain_value} ÌïôÏäµ Ï†Ñ ÏÑ±Îä• ÌèâÍ∞Ä Ïä§ÌÇµ (Îπ†Î•∏ ÌÖåÏä§Ìä∏)")
            before_performance = {}  # ÏûÑÏãúÎ°ú ÎπÑÌôúÏÑ±Ìôî
            
            # ÌòÑÏû¨ ÎèÑÎ©îÏù∏ ÌïôÏäµ
            domain_results = self._train_single_domain(
                domain_value, current_train_loader, current_val_loader
            )
            
            # ÌïôÏäµ ÌõÑ ÏÑ±Îä• ÌèâÍ∞Ä - Í∞ÑÏÜåÌôî
            logger.info(f"Domain {domain_value} ÌïôÏäµ ÌõÑ ÏÑ±Îä• ÌèâÍ∞Ä (Îπ†Î•∏ Î≤ÑÏ†Ñ)")
            after_performance = self._evaluate_all_domains_fast(domain_dataloaders)
            
            # Forgetting Í≥ÑÏÇ∞
            forgetting_score = self._calculate_forgetting(before_performance, after_performance)
            self.forgetting_scores.append(forgetting_score)
            
            # ÏÑ±Îä• Í∏∞Î°ù (Î™®Îì† Î©îÌä∏Î¶≠ Ï†ÄÏû•)
            for eval_domain, metrics in after_performance.items():
                if eval_domain not in self.performance_history:
                    self.performance_history[eval_domain] = {'accuracy': [], 'top1_retrieval': [], 'top5_retrieval': []}
                self.performance_history[eval_domain]['accuracy'].append(metrics.get('accuracy', 0.0))
                self.performance_history[eval_domain]['top1_retrieval'].append(metrics.get('top1_retrieval', 0.0))
                self.performance_history[eval_domain]['top5_retrieval'].append(metrics.get('top5_retrieval', 0.0))

            # ÌòÑÏû¨ ÎèÑÎ©îÏù∏ ÏôÑÎ£å ÌëúÏãú Î∞è Í≤∞Í≥º Ï†ÄÏû•
            self.completed_domains.append(domain_value)
            remaining_domains_results[domain_value] = {
                'training_results': domain_results,
                'performance': after_performance,
                'forgetting_score': forgetting_score
            }
            
            logger.info(f"Domain {domain_value} ÌïôÏäµ ÏôÑÎ£å: Forgetting Score = {forgetting_score:.4f}")
            
            # üé® ÎèÑÎ©îÏù∏Î≥Ñ ÏÑ±Îä• ÏãúÍ∞ÅÌôî ÏÉùÏÑ±
            logger.info(f"üìä Domain {domain_value} ÏÑ±Îä• ÏãúÍ∞ÅÌôî ÏÉùÏÑ± Ï§ë...")
            try:
                domain_viz_results = self._create_domain_performance_visualization(
                    domain_value, after_performance, forgetting_score
                )
                logger.info(f"‚úÖ Domain {domain_value} ÏãúÍ∞ÅÌôî ÏôÑÎ£å: {domain_viz_results.get('save_path', 'N/A')}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Domain {domain_value} ÏãúÍ∞ÅÌôî Ïã§Ìå®: {e}")
        
        # ÏµúÏ¢Ö ÏÑ±Îä• ÏöîÏïΩ (ÌíÄ ÌèâÍ∞ÄÎ°ú ÎçÆÏñ¥Ïì∞Í∏∞)
        full_eval_results = self._evaluate_all_domains(domain_dataloaders)
        # Í∏∞Î°ùÏóêÎèÑ ÌíÄ ÌèâÍ∞Ä ÏµúÏã†Í∞í Ï∂îÍ∞Ä
        for eval_domain, metrics in full_eval_results.items():
            if eval_domain not in self.performance_history:
                self.performance_history[eval_domain] = {'accuracy': [], 'top1_retrieval': [], 'top5_retrieval': []}
            self.performance_history[eval_domain]['accuracy'].append(metrics.get('accuracy', 0.0))
            self.performance_history[eval_domain]['top1_retrieval'].append(metrics.get('top1_retrieval', 0.0))
            self.performance_history[eval_domain]['top5_retrieval'].append(metrics.get('top5_retrieval', 0.0))
        final_metrics = self._calculate_final_metrics()
        remaining_domains_results['final_metrics'] = final_metrics
        
        logger.info("=== Remaining Domains Training ÏôÑÎ£å ===")
        
        return remaining_domains_results
    
    def _train_single_domain(self, 
                           domain_value: Union[int, str],
                           train_loader: DataLoader,
                           val_loader: DataLoader) -> Dict[str, float]:
        """
        Îã®Ïùº ÎèÑÎ©îÏù∏ ÌïôÏäµ (Replay Ìè¨Ìï®)
        
        Args:
            domain_value (Union[int, str]): ÎèÑÎ©îÏù∏ Í∞í (RPM ÎòêÎäî HP)
            train_loader (DataLoader): ÌòÑÏû¨ ÎèÑÎ©îÏù∏ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞
            val_loader (DataLoader): ÌòÑÏû¨ ÎèÑÎ©îÏù∏ Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞
            
        Returns:
            Dict[str, float]: ÌïôÏäµ Í≤∞Í≥º
        """
        # Optimizer (Vibration encoderÎßå ÌïôÏäµ)
        optimizer = self._create_continual_optimizer()
        
        # ÌòÑÏû¨ ÎèÑÎ©îÏù∏ ÏûÑÎ≤†Îî© ÏàòÏßë (Replay bufferÏö©)
        domain_embeddings = self._collect_domain_embeddings(train_loader)
        
        # Replay bufferÏóê Ï∂îÍ∞Ä (üéØ ÎùºÎ≤® Ï†ïÎ≥¥ Ìè¨Ìï®)
        if domain_embeddings:
            self.replay_buffer.add_domain_data(
                domain_value,
                domain_embeddings['text_embeddings'],
                domain_embeddings['vib_embeddings'],
                domain_embeddings['metadata'],
                labels=domain_embeddings.get('labels', None)
            )
        
        # ÌïôÏäµ Î£®ÌîÑ
        self.model.train()
        epoch_losses = []
        best_val_acc = 0.0
        patience_counter = 0
        
        for epoch in range(self.num_epochs):
            epoch_loss = 0.0
            num_batches = 0
            
            for batch_idx, batch in enumerate(train_loader):
                # ÌòÑÏû¨ Î∞∞ÏπòÎ•º ÎîîÎ∞îÏù¥Ïä§Î°ú Ïù¥Îèô
                batch = self._move_batch_to_device(batch)
                current_batch_size = batch['vibration'].size(0)
                
                # Replay Îç∞Ïù¥ÌÑ∞ ÏÉòÌîåÎßÅ (ÏÑ±Îä• ÏµúÏ†ÅÌôî: Í∞ÑÌóêÏ†Å ÏÇ¨Ïö©)
                use_replay = (batch_idx % 3 == 0)  # 3Î∞∞ÏπòÎßàÎã§ Ìïú Î≤àÎßå replay ÏÇ¨Ïö©
                
                if use_replay:
                    replay_batch_size = min(int(current_batch_size * self.replay_ratio), 8)  # ÌÅ¨Í∏∞ Ï†úÌïú
                    replay_data = self.replay_buffer.sample_replay_data(
                        replay_batch_size, exclude_current=True, device=self.device
                    )
                    
                    # ÌòÑÏû¨ Îç∞Ïù¥ÌÑ∞ÏôÄ Replay Îç∞Ïù¥ÌÑ∞ Í≤∞Ìï©
                    if replay_data is not None:
                        combined_batch = self._combine_current_and_replay(batch, replay_data)
                    else:
                        combined_batch = batch
                else:
                    combined_batch = batch
                
                # Forward pass
                optimizer.zero_grad()
                
                if self.use_amp:
                    with torch.cuda.amp.autocast():
                        results = self.model(combined_batch)
                        loss = results['loss']
                    
                    # Backward pass with AMP
                    self.scaler.scale(loss).backward()
                    
                    # Gradient clipping
                    if self.max_grad_norm > 0:
                        self.scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                    
                    self.scaler.step(optimizer)
                    self.scaler.update()
                else:
                    results = self.model(combined_batch)
                    loss = results['loss']
                    
                    # Backward pass
                    loss.backward()
                    
                    # Gradient clipping
                    if self.max_grad_norm > 0:
                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                    
                    optimizer.step()
                
                epoch_loss += loss.item()
                num_batches += 1
                
                # Î°úÍπÖ (Îçî Í∞ÑÍ≤∞ÌïòÍ≤å)
                if batch_idx % 20 == 0:
                    replay_info = f"R:{replay_batch_size}" if replay_data else "No-R"
                    logger.info(f"D{domain_value} E{epoch+1} B{batch_idx}: "
                               f"Loss={loss.item():.4f}, {replay_info}")
            
            avg_epoch_loss = epoch_loss / num_batches
            epoch_losses.append(avg_epoch_loss)
            
            # Validation
            val_metrics = self._evaluate_single_domain(val_loader)
            val_acc = val_metrics['accuracy']
            
            logger.info(f"Domain {domain_value} Epoch {epoch+1}: "
                       f"Loss = {avg_epoch_loss:.4f}, Val Acc = {val_acc:.4f}")
            
            # Early stopping
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                
                # Best model Ï†ÄÏû•
                checkpoint_path = os.path.join(self.save_dir, f'domain_{domain_value}_best.pth')
                self.model.save_checkpoint(checkpoint_path, epoch, optimizer.state_dict())
            else:
                patience_counter += 1
                
                if patience_counter >= TRAINING_CONFIG['patience']:
                    logger.info(f"Early stopping at epoch {epoch+1}")
                    break
        
        # ÎèÑÎ©îÏù∏ ÌïôÏäµ ÏôÑÎ£å
        self.loss_history[domain_value] = epoch_losses
        
        # ÏïàÏ†ÑÌïú Í≤∞Í≥º Î∞òÌôò (epoch_lossesÍ∞Ä ÎπÑÏñ¥ÏûàÏùÑ Ïàò ÏûàÏùå)
        final_loss = epoch_losses[-1] if epoch_losses else float('inf')
        num_epochs = len(epoch_losses)
        
        return {
            'final_loss': final_loss,
            'best_val_accuracy': best_val_acc,
            'num_epochs': num_epochs
        }
    
    def _collect_domain_embeddings(self, dataloader: DataLoader) -> Optional[Dict]:
        """ÌòÑÏû¨ ÎèÑÎ©îÏù∏ Îç∞Ïù¥ÌÑ∞Ïùò ÏûÑÎ≤†Îî© ÏàòÏßë (üéØ ÎùºÎ≤® Ï†ïÎ≥¥ Ìè¨Ìï®)"""
        self.model.eval()
        
        text_embeddings = []
        vib_embeddings = []
        metadata_list = []
        labels_list = []
        
        with torch.no_grad():
            for batch in dataloader:
                batch = self._move_batch_to_device(batch)
                results = self.model(batch, return_embeddings=True)
                
                text_embeddings.append(results['text_embeddings'])
                vib_embeddings.append(results['vib_embeddings'])
                metadata_list.extend(batch['metadata'])
                
                # üéØ ÎùºÎ≤® Ï†ïÎ≥¥ÎèÑ ÏàòÏßë
                if 'labels' in batch:
                    labels_list.append(batch['labels'])
        
        if text_embeddings:
            result = {
                'text_embeddings': torch.cat(text_embeddings, dim=0),
                'vib_embeddings': torch.cat(vib_embeddings, dim=0),
                'metadata': metadata_list
            }
            
            # ÎùºÎ≤® Ï†ïÎ≥¥ Ï∂îÍ∞Ä (ÏûàÎäî Í≤ΩÏö∞Îßå)
            if labels_list:
                result['labels'] = torch.cat(labels_list, dim=0)
            
            return result
        return None
    
    def _combine_current_and_replay(self, current_batch: Dict, replay_data: Dict) -> Dict:
        """ÌòÑÏû¨ Î∞∞ÏπòÏôÄ Replay Îç∞Ïù¥ÌÑ∞ Í≤∞Ìï© (üéØ ÎùºÎ≤® Ï†ïÎ≥¥ Ìè¨Ìï®)"""
        # ÏßÑÎèô Ïã†Ìò∏Îäî ÌòÑÏû¨ Î∞∞ÏπòÏóêÏÑúÎßå (ReplayÎäî ÏûÑÎ≤†Îî©Îßå Ï†ÄÏû•)
        combined_batch = current_batch.copy()  # Í∏∞Ï°¥ Î™®Îì† Ï†ïÎ≥¥ Î≥µÏÇ¨
        
        # Replay ÏûÑÎ≤†Îî©ÏùÑ Î™®Îç∏Ïóê Ï£ºÏûÖÌïòÎäî Î∞©ÏãùÏúºÎ°ú Íµ¨ÌòÑ
        combined_batch['replay_text_embeddings'] = replay_data['text_embeddings']
        combined_batch['replay_vib_embeddings'] = replay_data['vib_embeddings']
        
        # üéØ Replay ÎùºÎ≤® Ï†ïÎ≥¥ÎèÑ Ï†ÑÎã¨ (ÌÅ¥ÎûòÏä§ Í∏∞Î∞ò contrastive learningÏö©)
        if 'labels' in replay_data:
            combined_batch['replay_labels'] = replay_data['labels']
        
        return combined_batch
    
    def _evaluate_single_domain(self, dataloader: DataLoader) -> Dict[str, float]:
        """Îã®Ïùº ÎèÑÎ©îÏù∏ ÏÑ±Îä• ÌèâÍ∞Ä (retrieval Î©îÌä∏Î¶≠ Ìè¨Ìï®)"""
        self.model.eval()
        
        all_text_embeddings = []
        all_vib_embeddings = []
        all_file_idx = []
        all_labels = []
        all_labels = []
        
        # DataLoader ÏïàÏ†ÑÏÑ± ÌôïÎ≥¥Î•º ÏúÑÌïú Ï°∞Ïπò
        try:
            with torch.no_grad():
                max_batches = int(EVAL_CONFIG.get('max_full_eval_batches', -1))
                for batch_idx, batch in enumerate(dataloader):
                    # ÏÑ§Ï†ï Í∏∞Î∞ò Î∞∞Ïπò Ï†úÌïú (Í∏∞Î≥∏ Î¨¥Ï†úÌïú)
                    if max_batches >= 0 and batch_idx >= max_batches:
                        logger.debug(f"ÌèâÍ∞Ä Ï§ëÎã®: ÏÑ§Ï†ïÎêú ÏµúÎåÄ Î∞∞Ïπò {max_batches} ÎèÑÎã¨")
                        break
                        
                    batch = self._move_batch_to_device(batch)
                    results = self.model(batch, return_embeddings=True)
                    
                    all_text_embeddings.append(results['text_embeddings'])
                    all_vib_embeddings.append(results['vib_embeddings'])
                    if 'file_idx' in batch:
                        # ÎîîÎ∞îÏù¥Ïä§ ÏùºÏπò Ïú†ÏßÄ (GPU ÏÉÅÏóêÏÑú Î∞îÎ°ú ÏÇ¨Ïö©)
                        all_file_idx.append(batch['file_idx'])
                    if 'labels' in batch:
                        all_labels.append(batch['labels'])
                    
        except Exception as e:
            logger.error(f"ÌèâÍ∞Ä Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}")
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
        
        if not all_text_embeddings:
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
        
        # Î™®Îì† ÏûÑÎ≤†Îî© Í≤∞Ìï©
        text_emb = torch.cat(all_text_embeddings, dim=0)
        vib_emb = torch.cat(all_vib_embeddings, dim=0)
        file_idx = torch.cat(all_file_idx, dim=0) if all_file_idx else None
        labels_tensor = torch.cat(all_labels, dim=0) if all_labels else None
        
        # üéØ FIXED: ÌëúÏ§Ä L2 Ï†ïÍ∑úÌôî (gradient Î≥¥Ï°¥)
        text_emb = F.normalize(text_emb, p=2, dim=1)
        vib_emb = F.normalize(vib_emb, p=2, dim=1)
        
        # 1. Retrieval Ï†ïÌôïÎèÑ
        similarity_matrix = torch.matmul(text_emb, vib_emb.t())  # (N, N)
        
        # ÎîîÎ≤ÑÍ∑∏: Ï≤´ Î≤àÏß∏ Î∞∞ÏπòÏóêÏÑú Ïú†ÏÇ¨ÎèÑ Î∂ÑÌè¨ ÌôïÏù∏
        if hasattr(self, '_debug_count'):
            self._debug_count += 1
        else:
            self._debug_count = 1
            
        if self._debug_count <= 2:  # Ï≤òÏùå 2Î≤àÎßå ÎîîÎ≤ÑÍ∑∏
            # ÏûÑÎ≤†Îî© ÌÜµÍ≥Ñ Î°úÍ∑∏
            try:
                t_mean = text_emb.mean().item(); t_std = text_emb.std(unbiased=False).item()
                v_mean = vib_emb.mean().item(); v_std = vib_emb.std(unbiased=False).item()
                logger.info(f"üîç DEBUG - ÏûÑÎ≤†Îî© ÌÜµÍ≥Ñ | text mean/std: {t_mean:.4f}/{t_std:.4f}, vib mean/std: {v_mean:.4f}/{v_std:.4f}")
            except Exception:
                pass
            logger.info(f"üîç DEBUG - Î∞∞Ïπò ÌÅ¨Í∏∞: {text_emb.size(0)}")
            logger.info(f"üîç DEBUG - ÎåÄÍ∞ÅÏÑ† Ïú†ÏÇ¨ÎèÑ (Ï†ïÎãµ): {torch.diag(similarity_matrix)[:5].tolist()}")
            logger.info(f"üîç DEBUG - Ï≤´ Ìñâ Ïú†ÏÇ¨ÎèÑ (Ï†ÑÏ≤¥): {similarity_matrix[0, :5].tolist()}")
            predicted_tmp = torch.argmax(similarity_matrix, dim=1)
            logger.info(f"üîç DEBUG - ÏµúÎåÄ Ïú†ÏÇ¨ÎèÑ Ïù∏Îç±Ïä§: {predicted_tmp[:10].tolist()}")

            # Ï∂îÍ∞Ä Î¨¥Í≤∞ÏÑ± Ï≤¥ÌÅ¨: Ïú†ÏÇ¨ÎèÑ ÌÜµÍ≥Ñ Î∞è argmax Î∂ÑÌè¨
            N = similarity_matrix.size(0)
            diag_vals = torch.diag(similarity_matrix)
            diag_mean = float(diag_vals.mean().item())
            diag_std = float(diag_vals.std(unbiased=False).item())
            diag_min = float(diag_vals.min().item())
            diag_max = float(diag_vals.max().item())
            off_mask = ~torch.eye(N, dtype=torch.bool, device=similarity_matrix.device)
            off_vals = similarity_matrix[off_mask]
            off_mean = float(off_vals.mean().item())
            off_std = float(off_vals.std(unbiased=False).item())
            logger.info(
                f"üîç DEBUG - Ïú†ÏÇ¨ÎèÑ ÌÜµÍ≥Ñ | diag mean/std/min/max: "
                f"{diag_mean:.4f}/{diag_std:.4f}/{diag_min:.4f}/{diag_max:.4f}, "
                f"off mean/std: {off_mean:.4f}/{off_std:.4f}"
            )

            binc = torch.bincount(predicted_tmp, minlength=N)
            topk = min(10, N)
            top_vals, top_idx = torch.topk(binc, k=topk)
            top_pairs = [(int(i), int(v)) for i, v in zip(top_idx.tolist(), top_vals.tolist())]
            logger.info(f"üîç DEBUG - argmax ÏÉÅÏúÑ {topk} Ïù∏Îç±Ïä§/ÎπàÎèÑ: {top_pairs}")

            # ÏÖîÌîå Î≤†Ïù¥Ïä§ÎùºÏù∏ (ÌÅ¥ÎûòÏä§ Í∏∞Î∞ò, Í≥µÏ†ïÏÑ± ÎßàÏä§ÌÅ¨ ÎØ∏Ï†ÅÏö© Îã®Ïàú Ï∞∏Ï°∞)
            if N >= 2 and labels_tensor is not None:
                # ÎùºÎ≤® Ï†ïÍ∑úÌôî
                if labels_tensor.dim() == 2 and labels_tensor.size(1) >= 1:
                    cls_dbg = labels_tensor[:, 0]
                elif labels_tensor.dim() == 1:
                    cls_dbg = labels_tensor
                else:
                    cls_dbg = labels_tensor.view(-1)
                cls_dbg = cls_dbg.to(text_emb.device)

                # üéØ FIXED: Ïò¨Î∞îÎ•∏ ÏÖîÌîå Î≤†Ïù¥Ïä§ÎùºÏù∏ Í≥ÑÏÇ∞
                perm = torch.randperm(N, device=text_emb.device)
                sim_shuf = torch.matmul(text_emb, vib_emb[perm].t())
                pred_shuf = torch.argmax(sim_shuf, dim=1)
                
                # Ïò¨Î∞îÎ•∏ Í≥ÑÏÇ∞: ÏÖîÌîåÎêú ÏàúÏÑúÏóêÏÑú ÏòàÏ∏°Ìïú ÌÅ¥ÎûòÏä§ÏôÄ ÏõêÎûò ÌÅ¥ÎûòÏä§ ÎπÑÍµê
                predicted_classes_shuf = cls_dbg[perm[pred_shuf]]  # ÏòàÏ∏°Îêú ÏúÑÏπòÏùò Ïã§Ï†ú ÌÅ¥ÎûòÏä§
                top1_shuf = (predicted_classes_shuf == cls_dbg).float().mean().item()
                
                k_dbg = min(5, N)
                _, topk_shuf = torch.topk(sim_shuf, k=k_dbg, dim=1)
                topk_classes_shuf = cls_dbg[perm[topk_shuf]]  # topk ÏúÑÏπòÎì§Ïùò Ïã§Ï†ú ÌÅ¥ÎûòÏä§
                top5_shuf = (topk_classes_shuf == cls_dbg.unsqueeze(1)).any(dim=1).float().mean().item()
                
                logger.info(f"üîç DEBUG - ÏÖîÌîå Î≤†Ïù¥Ïä§ÎùºÏù∏ Top1/Top5 (class): {top1_shuf:.4f}/{top5_shuf:.4f}")
                
                # Ï∂îÍ∞Ä ÎîîÎ≤ÑÍ∑∏: ÌÅ¥ÎûòÏä§ Î∂ÑÌè¨ ÌôïÏù∏
                unique_classes = torch.unique(cls_dbg)
                class_counts = [(cls.item(), (cls_dbg == cls).sum().item()) for cls in unique_classes]
                logger.info(f"üîç DEBUG - Î∞∞Ïπò ÎÇ¥ ÌÅ¥ÎûòÏä§ Î∂ÑÌè¨: {class_counts}")
                
                # Ïù¥Î°†Ï†Å ÎûúÎç§ Î≤†Ïù¥Ïä§ÎùºÏù∏ Í≥ÑÏÇ∞
                n_classes = len(unique_classes)
                theoretical_random = 1.0 / n_classes if n_classes > 0 else 0.0
                logger.info(f"üîç DEBUG - Ïù¥Î°†Ï†Å ÎûúÎç§ Î≤†Ïù¥Ïä§ÎùºÏù∏: {theoretical_random:.4f} (ÌÅ¥ÎûòÏä§ Ïàò: {n_classes})")
        
        # üéØ ENHANCED: ÌÅ¥ÎûòÏä§ Ïù∏Ïãù ÌèâÍ∞Ä + ÌëúÏ§Ä contrastive ÌèâÍ∞Ä
        # 1) ÌëúÏ§Ä diagonal matching (Î™®ÎãàÌÑ∞ÎßÅÏö©)
        _, predicted_indices = torch.max(similarity_matrix, dim=1)
        correct_indices = torch.arange(text_emb.size(0), device=text_emb.device)
        diagonal_accuracy = (predicted_indices == correct_indices).float().mean().item()

        # üéØ Í≥µÏ†ï ÌèâÍ∞Ä: ÏûêÍ∏∞ ÏûêÏã†(ÎåÄÍ∞ÅÏÑ†) Ï†úÍ±∞ + (ÌñâÎ≥Ñ Ï°∞Í±¥Î∂Ä) ÎèôÏùºÌååÏùº Ï†úÍ±∞
        N = similarity_matrix.size(0)
        sim_eval = similarity_matrix.clone()
        if N > 1:
            sim_eval.fill_diagonal_(-1e4)
            if file_idx is not None and file_idx.numel() == N and labels_tensor is not None:
                # ÎùºÎ≤® ÌÖêÏÑú Ï†ïÍ∑úÌôî
                if labels_tensor.dim() == 2 and labels_tensor.size(1) >= 1:
                    class_labels_for_mask = labels_tensor[:, 0]
                elif labels_tensor.dim() == 1:
                    class_labels_for_mask = labels_tensor
                else:
                    class_labels_for_mask = labels_tensor.view(-1)
                class_labels_for_mask = class_labels_for_mask.to(text_emb.device)

                same_file_mask = (file_idx.unsqueeze(1) == file_idx.unsqueeze(0))
                class_equal_mask = (class_labels_for_mask.unsqueeze(1) == class_labels_for_mask.unsqueeze(0))
                off_diag_mask = ~torch.eye(N, dtype=torch.bool, device=text_emb.device)
                # Í∞Å ÌñâÏóê ÎèôÏùºÌååÏùºÏù¥ ÏïÑÎãå Í∞ôÏùÄ ÌÅ¥ÎûòÏä§ ÌõÑÎ≥¥Í∞Ä ÌïòÎÇòÎùºÎèÑ ÏûàÏúºÎ©¥ ÎèôÏùºÌååÏùº Ï†ÑÎ∂Ä ÎßàÏä§ÌÇπ
                has_other_file_positive = ((class_equal_mask & ~same_file_mask & off_diag_mask)).any(dim=1)
                row_mask = has_other_file_positive.unsqueeze(1).expand(-1, N)
                mask_to_apply = same_file_mask & row_mask
                sim_eval = sim_eval.masked_fill(mask_to_apply, -1e4)

        # üéØ CRITICAL FIX: Ïò¨Î∞îÎ•∏ Zero-shot Î∂ÑÎ•ò ÌèâÍ∞Ä
        # Í∞Å ÏßÑÎèô Ïã†Ìò∏Î•º Î™®Îì† Í∞ÄÎä•Ìïú ÌÅ¥ÎûòÏä§ ÏÑ§Î™ÖÍ≥º ÎπÑÍµêÌïòÏó¨ Î∂ÑÎ•ò
        
        class_top1 = diagonal_accuracy  # Í∏∞Î≥∏Í∞í
        class_top5 = diagonal_accuracy
        
        if labels_tensor is not None:
            # ÎùºÎ≤® Ï†ïÍ∑úÌôî
            if labels_tensor.dim() == 2 and labels_tensor.size(1) >= 1:
                class_labels = labels_tensor[:, 0]  # UOS Ï£º Î∂ÑÎ•ò
            elif labels_tensor.dim() == 1:
                class_labels = labels_tensor
            else:
                class_labels = labels_tensor.view(-1)
            class_labels = class_labels.to(text_emb.device)
            
            # üéØ NEW: Zero-shot Î∂ÑÎ•ò ÌèâÍ∞Ä
            # Î™®Îì† Í∞ÄÎä•Ìïú ÌÅ¥ÎûòÏä§Ïùò prototype ÌÖçÏä§Ìä∏ ÏûÑÎ≤†Îî© ÏÉùÏÑ±
            unique_classes = torch.unique(class_labels)
            n_classes = len(unique_classes)
            
            if n_classes > 1:  # ÌÅ¥ÎûòÏä§Í∞Ä Ïó¨Îü¨ Í∞ú ÏûàÏùÑ ÎïåÎßå zero-shot ÌèâÍ∞Ä
                # Í∞Å ÌÅ¥ÎûòÏä§Ïùò prototype ÏûÑÎ≤†Îî© Í≥ÑÏÇ∞ (ÌèâÍ∑†)
                class_prototypes = []
                for cls in unique_classes:
                    cls_mask = (class_labels == cls)
                    if cls_mask.any():
                        cls_text_emb = text_emb[cls_mask].mean(dim=0, keepdim=True)
                        class_prototypes.append(cls_text_emb)
                
                if len(class_prototypes) == n_classes:
                    # Î™®Îì† ÌÅ¥ÎûòÏä§Ïùò prototype Í≤∞Ìï©
                    prototype_embeddings = torch.cat(class_prototypes, dim=0)  # (n_classes, embed_dim)
                    
                    # Í∞Å ÏßÑÎèô ÏûÑÎ≤†Îî©ÏùÑ Î™®Îì† ÌÅ¥ÎûòÏä§ prototypeÍ≥º ÎπÑÍµê
                    vib_to_prototype_sim = torch.matmul(vib_emb, prototype_embeddings.t())  # (N, n_classes)
                    
                    # ÏòàÏ∏°: Í∞ÄÏû• Ïú†ÏÇ¨Ìïú prototypeÏùò ÌÅ¥ÎûòÏä§
                    predicted_class_idx = torch.argmax(vib_to_prototype_sim, dim=1)
                    predicted_classes = unique_classes[predicted_class_idx]
                    
                    # Zero-shot Î∂ÑÎ•ò Ï†ïÌôïÎèÑ
                    class_top1 = (predicted_classes == class_labels).float().mean().item()
                    
                    # Top-5 Í≥ÑÏÇ∞ (ÌÅ¥ÎûòÏä§ ÏàòÍ∞Ä 5Í∞ú Ïù¥ÏÉÅÏùº Îïå)
                    if n_classes >= 5:
                        _, top5_idx = torch.topk(vib_to_prototype_sim, k=5, dim=1)
                        top5_classes = unique_classes[top5_idx]  # (N, 5)
                        class_top5 = (top5_classes == class_labels.unsqueeze(1)).any(dim=1).float().mean().item()
                    else:
                        class_top5 = class_top1
                else:
                    # Prototype ÏÉùÏÑ± Ïã§Ìå® Ïãú Í∏∞Ï°¥ Î∞©Ïãù ÏÇ¨Ïö©
                    top1_pred = torch.argmax(sim_eval, dim=1)
                    class_top1 = (class_labels[top1_pred] == class_labels).float().mean().item()
                    class_top5 = class_top1
            else:
                # ÌÅ¥ÎûòÏä§Í∞Ä 1Í∞úÎøêÏù¥Î©¥ Ìï≠ÏÉÅ 100%
                class_top1 = 1.0
                class_top5 = 1.0

        retrieval_accuracy = class_top1
        top1_accuracy = class_top1
        top5_accuracy = class_top5
        
        return {
            'accuracy': retrieval_accuracy,  # Ï£º Ï†ïÌôïÎèÑ ÏßÄÌëú
            'diagonal_accuracy': diagonal_accuracy,  # ÌëúÏ§Ä contrastive Ï†ïÌôïÎèÑ
            'class_accuracy': class_top1,  # ÌÅ¥ÎûòÏä§ Ïù∏Ïãù Ï†ïÌôïÎèÑ
            'top1_retrieval': top1_accuracy,
            'top5_retrieval': top5_accuracy
        }
    
    def _evaluate_all_domains(self, domain_dataloaders: Dict) -> Dict[int, Dict[str, float]]:
        """Î™®Îì† ÎèÑÎ©îÏù∏ ÏÑ±Îä• ÌèâÍ∞Ä"""
        results = {}
        
        for domain_value, loaders in domain_dataloaders.items():
            test_loader = loaders['test']
            metrics = self._evaluate_single_domain(test_loader)
            
            results[domain_value] = {
                **metrics,  # accuracy, top1_retrieval, top5_retrieval
                'num_samples': len(test_loader.dataset)
            }
        
        return results
    
    def _evaluate_all_domains_fast(self, domain_dataloaders: Dict) -> Dict[str, Dict[str, float]]:
        """Îπ†Î•∏ ÎèÑÎ©îÏù∏ ÌèâÍ∞Ä (Ï†ÅÏùÄ Î∞∞ÏπòÎßå ÏÇ¨Ïö©)"""
        results = {}
        
        for domain_value, loaders in domain_dataloaders.items():
            test_loader = loaders['test']
            
            # Ï≤´ 5Î∞∞ÏπòÎßå ÌèâÍ∞ÄÌïòÏó¨ Îπ†Î•∏ Í∑ºÏÇ¨Ïπò Í≥ÑÏÇ∞
            limited_metrics = self._evaluate_single_domain_fast(test_loader)
            
            results[domain_value] = {
                **limited_metrics,
                'num_samples': min(len(test_loader.dataset), 5 * test_loader.batch_size)
            }
        
        return results
    
    def _evaluate_single_domain_fast(self, dataloader: DataLoader) -> Dict[str, float]:
        """Îπ†Î•∏ Îã®Ïùº ÎèÑÎ©îÏù∏ ÌèâÍ∞Ä (5Î∞∞ÏπòÎßå)"""
        self.model.eval()
        
        all_text_embeddings = []
        all_vib_embeddings = []
        all_file_idx = []
        all_labels = []
        
        try:
            with torch.no_grad():
                max_fast = int(EVAL_CONFIG.get('max_fast_eval_batches', 5))
                for batch_idx, batch in enumerate(dataloader):
                    if batch_idx >= max_fast:
                        break
                        
                    batch = self._move_batch_to_device(batch)
                    results = self.model(batch, return_embeddings=True)
                    
                    all_text_embeddings.append(results['text_embeddings'])
                    all_vib_embeddings.append(results['vib_embeddings'])
                    if 'file_idx' in batch:
                        all_file_idx.append(batch['file_idx'])
                    if 'labels' in batch:
                        all_labels.append(batch['labels'])
                    
        except Exception as e:
            logger.error(f"Îπ†Î•∏ ÌèâÍ∞Ä Ï§ë Ïò§Î•ò: {e}")
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
        
        if not all_text_embeddings:
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
        
        # ÏûÑÎ≤†Îî© Í≤∞Ìï© Î∞è Î©îÌä∏Î¶≠ Í≥ÑÏÇ∞
        text_emb = torch.cat(all_text_embeddings, dim=0)
        vib_emb = torch.cat(all_vib_embeddings, dim=0)
        file_idx = torch.cat(all_file_idx, dim=0) if all_file_idx else None
        labels_tensor = torch.cat(all_labels, dim=0) if all_labels else None

        # üéØ FIXED: ÌëúÏ§Ä L2 Ï†ïÍ∑úÌôî (gradient Î≥¥Ï°¥)
        text_emb = F.normalize(text_emb, p=2, dim=1)
        vib_emb = F.normalize(vib_emb, p=2, dim=1)
        similarity = torch.matmul(text_emb, vib_emb.t())

        # Í≥µÏ†ïÏÑ± ÎßàÏä§ÌÅ¨: ÏûêÍ∏∞ÏûêÏã† Ï†úÍ±∞ + (ÌñâÎ≥Ñ Ï°∞Í±¥Î∂Ä) ÎèôÏùºÌååÏùº Ï†úÍ±∞
        N = similarity.size(0)
        sim_eval = similarity.clone()
        if N > 1:
            sim_eval.fill_diagonal_(-1e4)
            if file_idx is not None and file_idx.numel() == N and labels_tensor is not None:
                if labels_tensor.dim() == 2 and labels_tensor.size(1) >= 1:
                    class_labels_for_mask = labels_tensor[:, 0]
                elif labels_tensor.dim() == 1:
                    class_labels_for_mask = labels_tensor
                else:
                    class_labels_for_mask = labels_tensor.view(-1)
                class_labels_for_mask = class_labels_for_mask.to(text_emb.device)

                same_file_mask = (file_idx.unsqueeze(1) == file_idx.unsqueeze(0))
                class_equal_mask = (class_labels_for_mask.unsqueeze(1) == class_labels_for_mask.unsqueeze(0))
                off_diag_mask = ~torch.eye(N, dtype=torch.bool, device=text_emb.device)
                has_other_file_positive = ((class_equal_mask & ~same_file_mask & off_diag_mask)).any(dim=1)
                row_mask = has_other_file_positive.unsqueeze(1).expand(-1, N)
                mask_to_apply = same_file_mask & row_mask
                sim_eval = sim_eval.masked_fill(mask_to_apply, -1e4)

        # üéØ CRITICAL FIX: Ïò¨Î∞îÎ•∏ Zero-shot Î∂ÑÎ•ò ÌèâÍ∞Ä (fast Î≤ÑÏ†ÑÏóêÎèÑ Ï†ÅÏö©)
        class_top1 = 0.0
        class_top5 = 0.0
        
        if labels_tensor is not None:
            # ÎùºÎ≤® Ï†ïÍ∑úÌôî
            if labels_tensor.dim() == 2 and labels_tensor.size(1) >= 1:
                class_labels = labels_tensor[:, 0]
            elif labels_tensor.dim() == 1:
                class_labels = labels_tensor
            else:
                class_labels = labels_tensor.view(-1)
            class_labels = class_labels.to(text_emb.device)
            
            # Zero-shot Î∂ÑÎ•ò ÌèâÍ∞Ä (full Î≤ÑÏ†ÑÍ≥º ÎèôÏùºÌïú Î°úÏßÅ)
            unique_classes = torch.unique(class_labels)
            n_classes = len(unique_classes)
            
            if n_classes > 1:
                # Í∞Å ÌÅ¥ÎûòÏä§Ïùò prototype ÏûÑÎ≤†Îî© Í≥ÑÏÇ∞
                class_prototypes = []
                for cls in unique_classes:
                    cls_mask = (class_labels == cls)
                    if cls_mask.any():
                        cls_text_emb = text_emb[cls_mask].mean(dim=0, keepdim=True)
                        class_prototypes.append(cls_text_emb)
                
                if len(class_prototypes) == n_classes:
                    # Î™®Îì† ÌÅ¥ÎûòÏä§Ïùò prototype Í≤∞Ìï©
                    prototype_embeddings = torch.cat(class_prototypes, dim=0)
                    
                    # Í∞Å ÏßÑÎèô ÏûÑÎ≤†Îî©ÏùÑ Î™®Îì† ÌÅ¥ÎûòÏä§ prototypeÍ≥º ÎπÑÍµê
                    vib_to_prototype_sim = torch.matmul(vib_emb, prototype_embeddings.t())
                    
                    # ÏòàÏ∏°: Í∞ÄÏû• Ïú†ÏÇ¨Ìïú prototypeÏùò ÌÅ¥ÎûòÏä§
                    predicted_class_idx = torch.argmax(vib_to_prototype_sim, dim=1)
                    predicted_classes = unique_classes[predicted_class_idx]
                    
                    # Zero-shot Î∂ÑÎ•ò Ï†ïÌôïÎèÑ
                    class_top1 = (predicted_classes == class_labels).float().mean().item()
                    
                    # Top-5 Í≥ÑÏÇ∞
                    if n_classes >= 5:
                        _, top5_idx = torch.topk(vib_to_prototype_sim, k=5, dim=1)
                        top5_classes = unique_classes[top5_idx]
                        class_top5 = (top5_classes == class_labels.unsqueeze(1)).any(dim=1).float().mean().item()
                    else:
                        class_top5 = class_top1
                else:
                    # Prototype ÏÉùÏÑ± Ïã§Ìå® Ïãú Í∏∞Î≥∏Í∞í
                    class_top1 = 0.0
                    class_top5 = 0.0
            else:
                # ÌÅ¥ÎûòÏä§Í∞Ä 1Í∞úÎøêÏù¥Î©¥ Ìï≠ÏÉÅ 100%
                class_top1 = 1.0
                class_top5 = 1.0
        else:
            # ÎùºÎ≤® ÏóÜÏúºÎ©¥ ÎåÄÍ∞ÅÏÑ† Í∏∞Ï§ÄÏúºÎ°ú Í∑ºÏÇ¨
            _, pred = torch.max(sim_eval, dim=1)
            target = torch.arange(text_emb.size(0), device=text_emb.device)
            class_top1 = (pred == target).float().mean().item()
            k = min(5, sim_eval.size(1))
            if k > 1:
                _, topk = torch.topk(sim_eval, k=k, dim=1)
                target_expanded = target.unsqueeze(1).expand(-1, k)
                class_top5 = (topk == target_expanded).any(dim=1).float().mean().item()
            else:
                class_top5 = class_top1

        # Îπ†Î•∏ ÌèâÍ∞ÄÏóêÏÑúÎèÑ Î¨¥Í≤∞ÏÑ± ÎîîÎ≤ÑÍ∑∏(Ìïú Î≤àÎßå)
        if not hasattr(self, '_debug_fast_once'):
            self._debug_fast_once = True
            N = similarity.size(0)
            diag_vals = torch.diag(similarity)
            diag_mean = float(diag_vals.mean().item())
            diag_std = float(diag_vals.std(unbiased=False).item())
            off_mask = ~torch.eye(N, dtype=torch.bool, device=similarity.device)
            off_vals = similarity[off_mask]
            off_mean = float(off_vals.mean().item())
            off_std = float(off_vals.std(unbiased=False).item())
            logger.info(
                f"üîç DEBUG(FAST) - N={N}, diag mean/std={diag_mean:.4f}/{diag_std:.4f}, "
                f"off mean/std={off_mean:.4f}/{off_std:.4f}, Top1={class_top1:.4f}, Top5={class_top5:.4f}"
            )
            # ÏÖîÌîå Î≤†Ïù¥Ïä§ÎùºÏù∏ (ÌÅ¥ÎûòÏä§ Í∏∞Î∞ò)
            if N >= 2 and labels_tensor is not None:
                if labels_tensor.dim() == 2 and labels_tensor.size(1) >= 1:
                    cls_dbg = labels_tensor[:, 0]
                elif labels_tensor.dim() == 1:
                    cls_dbg = labels_tensor
                else:
                    cls_dbg = labels_tensor.view(-1)
                cls_dbg = cls_dbg.to(text_emb.device)
                perm = torch.randperm(N, device=text_emb.device)
                sim_shuf = torch.matmul(text_emb, vib_emb[perm].t())
                pred_shuf = torch.argmax(sim_shuf, dim=1)
                top1_shuf = (cls_dbg[perm][pred_shuf] == cls_dbg).float().mean().item()
                k_dbg = min(5, N)
                _, topk_shuf = torch.topk(sim_shuf, k=k_dbg, dim=1)
                top5_shuf = (cls_dbg.unsqueeze(1) == cls_dbg[perm][topk_shuf]).any(dim=1).float().mean().item()
                logger.info(f"üîç DEBUG(FAST) - ÏÖîÌîå Î≤†Ïù¥Ïä§ÎùºÏù∏ Top1/Top5 (class): {top1_shuf:.4f}/{top5_shuf:.4f}")

        return {
            'accuracy': class_top1,  # ÌÅ¥ÎûòÏä§ Í∏∞Î∞ò Top-1
            'diagonal_accuracy': class_top1,  # ÎùºÎ≤® Î∂ÄÏû¨ Ïãú ÎèôÏùº
            'class_accuracy': class_top1,
            'top1_retrieval': class_top1,
            'top5_retrieval': class_top5
        }
    
    def _calculate_forgetting(self, before: Dict, after: Dict) -> float:
        """Forgetting score Í≥ÑÏÇ∞"""
        if len(self.completed_domains) <= 1:
            return 0.0
        
        forgetting_scores = []
        for domain in self.completed_domains[:-1]:  # ÎßàÏßÄÎßâ ÎèÑÎ©îÏù∏ Ï†úÏô∏
            before_acc = before.get(domain, {}).get('accuracy', 0.0)
            after_acc = after.get(domain, {}).get('accuracy', 0.0)
            forgetting = max(0.0, before_acc - after_acc)
            forgetting_scores.append(forgetting)
        
        return np.mean(forgetting_scores) if forgetting_scores else 0.0
    
    def _calculate_final_metrics(self) -> Dict[str, float]:
        """ÏµúÏ¢Ö Continual Learning Î©îÌä∏Î¶≠ Í≥ÑÏÇ∞"""
        if not self.performance_history:
            return {}
        
        # Average metrics (ÎßàÏßÄÎßâ ÏÑ±Îä•)
        final_accuracies = []
        final_top1_retrievals = []
        final_top5_retrievals = []
        
        for domain in self.completed_domains:
            if domain in self.performance_history:
                if self.performance_history[domain]['accuracy']:
                    final_accuracies.append(self.performance_history[domain]['accuracy'][-1])
                if self.performance_history[domain]['top1_retrieval']:
                    final_top1_retrievals.append(self.performance_history[domain]['top1_retrieval'][-1])
                if self.performance_history[domain]['top5_retrieval']:
                    final_top5_retrievals.append(self.performance_history[domain]['top5_retrieval'][-1])
        
        avg_accuracy = np.mean(final_accuracies) if final_accuracies else 0.0
        avg_top1_retrieval = np.mean(final_top1_retrievals) if final_top1_retrievals else 0.0
        avg_top5_retrieval = np.mean(final_top5_retrievals) if final_top5_retrievals else 0.0
        
        # Average Forgetting
        avg_forgetting = np.mean(self.forgetting_scores) if self.forgetting_scores else 0.0
        
        return {
            'average_accuracy': avg_accuracy,
            'average_top1_retrieval': avg_top1_retrieval,
            'average_top5_retrieval': avg_top5_retrieval,
            'average_forgetting': avg_forgetting,
            'num_domains': len(self.completed_domains),
            'final_accuracies': final_accuracies,
            'final_top1_retrievals': final_top1_retrievals,
            'final_top5_retrievals': final_top5_retrievals
        }
    
    def _create_optimizer(self) -> torch.optim.Optimizer:
        """First domain trainingÏö© optimizer ÏÉùÏÑ± (ÌååÎùºÎØ∏ÌÑ∞ Í∑∏Î£π Î∂ÑÎ¶¨)"""
        base_lr = self.learning_rate
        lora_mult = float(TRAINING_CONFIG.get('lora_lr_mult', 3.0))
        proj_mult = float(TRAINING_CONFIG.get('proj_lr_mult', 3.0))
        vib_mult  = float(TRAINING_CONFIG.get('vib_lr_mult', 1.0))

        params = []
        seen = set()

        # Text LoRA ÌååÎùºÎØ∏ÌÑ∞ Í∑∏Î£π
        try:
            lora_params = [p for n, p in self.model.text_encoder.distilbert.named_parameters()
                           if ('lora_' in n) and p.requires_grad]
            if lora_params:
                params.append({'params': lora_params, 'lr': base_lr * lora_mult, 'weight_decay': self.weight_decay})
                for p in lora_params:
                    seen.add(id(p))
        except Exception:
            pass

        # Text projection ÌååÎùºÎØ∏ÌÑ∞ Í∑∏Î£π
        if hasattr(self.model.text_encoder, 'projection'):
            proj_params = [p for p in self.model.text_encoder.projection.parameters() if p.requires_grad]
            if proj_params:
                params.append({'params': proj_params, 'lr': base_lr * proj_mult, 'weight_decay': self.weight_decay})
                for p in proj_params:
                    seen.add(id(p))

        # Vibration encoder ÌååÎùºÎØ∏ÌÑ∞ Í∑∏Î£π
        vib_params = [p for p in self.model.vibration_encoder.parameters() if p.requires_grad]
        vib_params = [p for p in vib_params if id(p) not in seen]
        if vib_params:
            params.append({'params': vib_params, 'lr': base_lr * vib_mult, 'weight_decay': self.weight_decay})
            for p in vib_params:
                seen.add(id(p))

        # üéØ CRITICAL FIX: InfoNCE Ïò®ÎèÑ ÌååÎùºÎØ∏ÌÑ∞ Ï∂îÍ∞Ä
        temp_params = []
        if hasattr(self.model.infonce_loss, 'log_temperature_text'):
            temp_params.append(self.model.infonce_loss.log_temperature_text)
        if hasattr(self.model.infonce_loss, 'log_temperature_vib'):
            temp_params.append(self.model.infonce_loss.log_temperature_vib)
        
        if temp_params:
            params.append({'params': temp_params, 'lr': base_lr * 2.0, 'weight_decay': 0.0})  # Ïò®ÎèÑÎäî weight decay ÏóÜÏùå
            for p in temp_params:
                seen.add(id(p))

        # ÎàÑÎùΩ ÌååÎùºÎØ∏ÌÑ∞ Î≥¥ÏôÑ
        remain = [p for p in self.model.parameters() if p.requires_grad and id(p) not in seen]
        if remain:
            params.append({'params': remain, 'lr': base_lr, 'weight_decay': self.weight_decay})

        return optim.AdamW(params)
    
    def _create_scheduler(self, optimizer, total_steps):
        """ÌïôÏäµÎ•† Ïä§ÏºÄÏ§ÑÎü¨ ÏÉùÏÑ± (Îã®Ïùº Íµ¨ÌòÑ)"""
        from torch.optim.lr_scheduler import CosineAnnealingLR
        return CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=1e-6)
    
    def _create_continual_optimizer(self) -> torch.optim.Optimizer:
        """Continual learningÏö© optimizer ÏÉùÏÑ± (Vibration + Text projection + Ïò®ÎèÑ)"""
        base_lr = self.learning_rate
        proj_mult = float(TRAINING_CONFIG.get('proj_lr_mult', 5.0))
        vib_mult = float(TRAINING_CONFIG.get('vib_lr_mult', 2.0))
        
        params = []
        seen = set()
        
        # Text projection ÌååÎùºÎØ∏ÌÑ∞ (continual learningÏóêÏÑú ÌïôÏäµ Í∞ÄÎä•)
        if hasattr(self.model.text_encoder, 'projection'):
            proj_params = [p for p in self.model.text_encoder.projection.parameters() if p.requires_grad]
            if proj_params:
                params.append({'params': proj_params, 'lr': base_lr * proj_mult, 'weight_decay': self.weight_decay})
                for p in proj_params:
                    seen.add(id(p))
        
        # Vibration encoder ÌååÎùºÎØ∏ÌÑ∞
        vib_params = [p for p in self.model.vibration_encoder.parameters() if p.requires_grad]
        vib_params = [p for p in vib_params if id(p) not in seen]
        if vib_params:
            params.append({'params': vib_params, 'lr': base_lr * vib_mult, 'weight_decay': self.weight_decay})
            for p in vib_params:
                seen.add(id(p))
        
        # üéØ CRITICAL FIX: InfoNCE Ïò®ÎèÑ ÌååÎùºÎØ∏ÌÑ∞ Ï∂îÍ∞Ä
        temp_params = []
        if hasattr(self.model.infonce_loss, 'log_temperature_text'):
            temp_params.append(self.model.infonce_loss.log_temperature_text)
        if hasattr(self.model.infonce_loss, 'log_temperature_vib'):
            temp_params.append(self.model.infonce_loss.log_temperature_vib)
        
        if temp_params:
            params.append({'params': temp_params, 'lr': base_lr * 2.0, 'weight_decay': 0.0})
            for p in temp_params:
                seen.add(id(p))
        
        # ÎàÑÎùΩ ÌååÎùºÎØ∏ÌÑ∞ Î≥¥ÏôÑ
        remain = [p for p in self.model.parameters() if p.requires_grad and id(p) not in seen]
        if remain:
            params.append({'params': remain, 'lr': base_lr, 'weight_decay': self.weight_decay})
        
        return optim.AdamW(params)
    
    def _create_scheduler(self, optimizer: torch.optim.Optimizer, total_steps: int):
        """ÌïôÏäµÎ•† Ïä§ÏºÄÏ§ÑÎü¨ ÏÉùÏÑ± (Îã®Ïùº Íµ¨ÌòÑ)"""
        from torch.optim.lr_scheduler import CosineAnnealingLR
        return CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=1e-6)
    
    def _move_batch_to_device(self, batch: Dict) -> Dict:
        """Î∞∞ÏπòÎ•º ÎîîÎ∞îÏù¥Ïä§Î°ú Ïù¥Îèô"""
        if 'vibration' in batch:
            batch['vibration'] = batch['vibration'].to(self.device)
        if 'labels' in batch:
            batch['labels'] = batch['labels'].to(self.device)
        if 'file_idx' in batch:
            batch['file_idx'] = batch['file_idx'].to(self.device)
        return batch
    
    def save_training_history(self, path: str):
        """ÌïôÏäµ Ïù¥Î†• Ï†ÄÏû•"""
        history = {
            'performance_history': dict(self.performance_history),
            'loss_history': dict(self.loss_history),
            'forgetting_scores': self.forgetting_scores,
            'completed_domains': self.completed_domains,
            'domain_order': self.domain_order
        }
        
        torch.save(history, path)
        logger.info(f"ÌïôÏäµ Ïù¥Î†• Ï†ÄÏû•Îê®: {path}")
    
    def plot_continual_learning_curves(self, save_path: Optional[str] = None):
        """Continual learning Í≤∞Í≥º ÏãúÍ∞ÅÌôî"""
        if not self.performance_history:
            logger.warning("ÏãúÍ∞ÅÌôîÌï† ÏÑ±Îä• Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏùå")
            return
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. DomainÎ≥Ñ ÏÑ±Îä• Î≥ÄÌôî
        for domain in self.completed_domains:
            if domain in self.performance_history:
                ax1.plot(self.performance_history[domain], label=f'Domain {domain}')
        ax1.set_xlabel('Learning Phase')
        ax1.set_ylabel('Accuracy')
        ax1.set_title('Performance Evolution by Domain')
        ax1.legend()
        ax1.grid(True)
        
        # 2. Forgetting scores
        if self.forgetting_scores:
            ax2.plot(self.forgetting_scores, 'r-o')
            ax2.set_xlabel('Domain')
            ax2.set_ylabel('Forgetting Score')
            ax2.set_title('Catastrophic Forgetting')
            ax2.grid(True)
        
        # 3. ÏµúÏ¢Ö ÏÑ±Îä• ÎπÑÍµê
        final_accs = [self.performance_history[d][-1] if d in self.performance_history else 0
                     for d in self.completed_domains]
        ax3.bar(range(len(self.completed_domains)), final_accs)
        ax3.set_xlabel('Domain')
        ax3.set_ylabel('Final Accuracy')
        ax3.set_title('Final Performance by Domain')
        ax3.set_xticks(range(len(self.completed_domains)))
        ax3.set_xticklabels([str(d) for d in self.completed_domains])
        
        # 4. Loss curves
        for domain in self.completed_domains:
            if domain in self.loss_history:
                ax4.plot(self.loss_history[domain], label=f'Domain {domain}')
        ax4.set_xlabel('Epoch')
        ax4.set_ylabel('Loss')
        ax4.set_title('Training Loss by Domain')
        ax4.legend()
        ax4.grid(True)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"ÌïôÏäµ Í≥°ÏÑ† Ï†ÄÏû•Îê®: {save_path}")
        else:
            plt.show()
    
    def _create_first_domain_alignment_visualization(self, 
                                                   domain_dataloaders: Dict, 
                                                   first_domain: int) -> Dict[str, Any]:
        """
        Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏ÏóêÏÑú TextÏôÄ Vibration EncoderÏùò alignment ÏãúÍ∞ÅÌôî
        
        Args:
            domain_dataloaders: ÎèÑÎ©îÏù∏Î≥Ñ Îç∞Ïù¥ÌÑ∞Î°úÎçî
            first_domain: Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏ Í∞í
            
        Returns:
            Dict: ÏãúÍ∞ÅÌôî Í≤∞Í≥º Ï†ïÎ≥¥
        """
        from .visualization import create_visualizer
        
        # Ï≤´ Î≤àÏß∏ ÎèÑÎ©îÏù∏ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Î°úÎçî
        if first_domain not in domain_dataloaders:
            logger.warning(f"ÎèÑÎ©îÏù∏ {first_domain} Îç∞Ïù¥ÌÑ∞Î°úÎçîÍ∞Ä ÏóÜÏùå")
            return {}
        
        test_loader = domain_dataloaders[first_domain]['test']
        
        # ÏûÑÎ≤†Îî© ÏàòÏßë (ÏµúÎåÄ 200Í∞ú ÏÉòÌîå)
        self.model.eval()
        text_embeddings = []
        vib_embeddings = []
        labels = []
        bearing_types = []
        
        max_samples = 200
        collected_samples = 0
        
        with torch.no_grad():
            for batch in test_loader:
                if collected_samples >= max_samples:
                    break
                
                # Î∞∞Ïπò Ï≤òÎ¶¨
                vibrations = batch['vibration'].to(self.device)
                texts = batch['text']
                metadata = batch['metadata']
                
                # Î™®Îç∏ forward
                model_results = self.model({
                    'vibration': vibrations,
                    'text': texts
                }, return_embeddings=True)
                
                # ÏûÑÎ≤†Îî© ÏàòÏßë
                text_emb = model_results['text_embeddings'].cpu()
                vib_emb = model_results['vib_embeddings'].cpu()
                
                text_embeddings.append(text_emb)
                vib_embeddings.append(vib_emb)
                
                # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÏàòÏßë
                for meta in metadata:
                    labels.append(meta.get('bearing_condition', 'H'))
                    bearing_types.append(meta.get('bearing_type', '6204'))
                
                collected_samples += len(vibrations)
                
                if collected_samples >= max_samples:
                    break
        
        if not text_embeddings:
            logger.warning("ÏûÑÎ≤†Îî© ÏàòÏßë Ïã§Ìå®")
            return {}
        
        # ÌÖêÏÑú Í≤∞Ìï©
        text_embeddings = torch.cat(text_embeddings, dim=0)
        vib_embeddings = torch.cat(vib_embeddings, dim=0)
        
        # ÏÉòÌîå Ïàò ÎßûÏ∂§
        min_samples = min(len(text_embeddings), len(labels), max_samples)
        text_embeddings = text_embeddings[:min_samples]
        vib_embeddings = vib_embeddings[:min_samples]
        labels = labels[:min_samples]
        bearing_types = bearing_types[:min_samples]
        
        # ÏãúÍ∞ÅÌôî ÏÉùÏÑ±
        visualizer = create_visualizer(self.save_dir)
        
        try:
            alignment_path = visualizer.create_encoder_alignment_plot(
                text_embeddings=text_embeddings,
                vib_embeddings=vib_embeddings,
                labels=labels,
                bearing_types=bearing_types,
                domain_name=f"Domain_{first_domain}",
                save_name=f"first_domain_alignment_{first_domain}"
            )
            
            return {
                'save_path': alignment_path,
                'num_samples': min_samples,
                'domain': first_domain
            }
            
        except Exception as e:
            logger.error(f"ÏãúÍ∞ÅÌôî ÏÉùÏÑ± Ïã§Ìå®: {e}")
            return {}
    
    def _create_domain_performance_visualization(self, 
                                               current_domain: int,
                                               performance_results: Dict,
                                               forgetting_score: float) -> Dict[str, Any]:
        """
        Í∞Å ÎèÑÎ©îÏù∏ ÏôÑÎ£å ÌõÑ ÏÑ±Îä• Í≤ÄÏ¶ù ÏãúÍ∞ÅÌôî (accuracy, forgetting)
        
        Args:
            current_domain: ÌòÑÏû¨ ÏôÑÎ£åÎêú ÎèÑÎ©îÏù∏
            performance_results: ÏÑ±Îä• ÌèâÍ∞Ä Í≤∞Í≥º
            forgetting_score: ÎßùÍ∞Å Ï†êÏàò
            
        Returns:
            Dict: ÏãúÍ∞ÅÌôî Í≤∞Í≥º Ï†ïÎ≥¥
        """
        import matplotlib.pyplot as plt
        
        # ÌòÑÏû¨ÍπåÏßÄ ÏôÑÎ£åÎêú ÎèÑÎ©îÏù∏Îì§Ïùò ÏÑ±Îä• ÏàòÏßë
        domain_names = []
        accuracies = []
        
        for domain in self.completed_domains:
            domain_names.append(f"Domain_{domain}")
            if domain in performance_results:
                accuracies.append(performance_results[domain].get('accuracy', 0.0))
            else:
                accuracies.append(0.0)

        # ÎßùÍ∞Å Ï†êÏàò (Ï≤´ ÎèÑÎ©îÏù∏ÏùÄ 0), Í∏∏Ïù¥ Ï†ïÌï©ÏÑ± Î≥¥Ï†ï
        n = len(domain_names)
        forgetting_scores = [0.0] + list(self.forgetting_scores)
        if len(forgetting_scores) < n:
            forgetting_scores = forgetting_scores + [0.0] * (n - len(forgetting_scores))
        elif len(forgetting_scores) > n:
            forgetting_scores = forgetting_scores[:n]
        
        # ÏãúÍ∞ÅÌôî ÏÉùÏÑ±
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # 1. ÎèÑÎ©îÏù∏Î≥Ñ Ï†ïÌôïÎèÑ
        bars1 = ax1.bar(range(len(domain_names)), accuracies, 
                       color=['#2E86AB', '#F24236', '#F6AE2D', '#2F9B69', '#F18F01', '#6C757D'][:len(domain_names)],
                       alpha=0.8)
        ax1.set_xlabel('Domains')
        ax1.set_ylabel('Accuracy')
        ax1.set_title(f'Accuracy after Domain {current_domain}')
        ax1.set_xticks(range(len(domain_names)))
        ax1.set_xticklabels(domain_names, rotation=45)
        ax1.set_ylim(0, 1)
        ax1.grid(True, alpha=0.3)
        
        # Ï†ïÌôïÎèÑ Í∞í ÌëúÏãú
        for i, (bar, acc) in enumerate(zip(bars1, accuracies)):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{acc:.3f}', ha='center', va='bottom', fontsize=10)
        
        # 2. ÎßùÍ∞Å Ï†êÏàò
        bars2 = ax2.bar(range(len(domain_names)), forgetting_scores,
                       color='#F24236', alpha=0.7)
        ax2.set_xlabel('Domains')
        ax2.set_ylabel('Forgetting Score')
        ax2.set_title(f'Forgetting Score after Domain {current_domain}')
        ax2.set_xticks(range(len(domain_names)))
        ax2.set_xticklabels(domain_names, rotation=45)
        ax2.set_ylim(0, max(0.5, max(forgetting_scores) * 1.1) if forgetting_scores else 0.5)
        ax2.grid(True, alpha=0.3)
        
        # ÎßùÍ∞Å Ï†êÏàò Í∞í ÌëúÏãú
        for i, (bar, forget) in enumerate(zip(bars2, forgetting_scores)):
            if forget > 0:
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                        f'{forget:.3f}', ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        
        # Ï†ÄÏû•
        save_path = os.path.join(self.save_dir, f'domain_{current_domain}_performance.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return {
            'save_path': save_path,
            'current_domain': current_domain,
            'num_completed_domains': len(self.completed_domains),
            'avg_accuracy': np.mean(accuracies) if accuracies else 0.0,
            'avg_forgetting': np.mean(forgetting_scores) if forgetting_scores else 0.0
        }


if __name__ == "__main__":
    # ÌÖåÏä§Ìä∏ ÏΩîÎìú
    logging.basicConfig(level=logging.INFO)
    
    print("=== ContinualTrainer ÌÖåÏä§Ìä∏ ===")
    
    # GPU ÏÇ¨Ïö© Í∞ÄÎä•ÌïòÎ©¥ GPU ÏÇ¨Ïö©
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Trainer ÏÉùÏÑ±
    trainer = ContinualTrainer(device=device)
    
    print(f"Trainer Ï¥àÍ∏∞Ìôî ÏôÑÎ£å: device={device}")
    print(f"ÎèÑÎ©îÏù∏ ÏàúÏÑú: {trainer.domain_order}")
    print(f"Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞: {trainer.model.get_trainable_parameters()}")
    
    print("\n=== ContinualTrainer ÌÖåÏä§Ìä∏ ÏôÑÎ£å ===")
