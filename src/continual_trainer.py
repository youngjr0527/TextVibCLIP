"""
Continual Trainer: TextVibCLIP Continual Learning íŒŒì´í”„ë¼ì¸
Domainë³„ ìˆœì°¨ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€ ê´€ë¦¬
"""

import os
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from typing import Dict, List, Tuple, Optional, Any, Union
import logging
import numpy as np
from collections import defaultdict, Counter
import matplotlib.pyplot as plt

from .textvib_model import TextVibCLIP, create_textvib_model
from .replay_buffer import ReplayBuffer
from .data_loader import create_domain_dataloaders, create_combined_dataloader, create_first_domain_dataloader
from .data_cache import create_cached_first_domain_dataloader
from .utils import setup_amp_and_scaler
from configs.model_config import TRAINING_CONFIG, DATA_CONFIG, EVAL_CONFIG, MODEL_CONFIG, CWRU_DATA_CONFIG

logger = logging.getLogger(__name__)


class ContinualTrainer:
    """
    TextVibCLIP Continual Learning Trainer
    
    Domainë³„ ìˆœì°¨ í•™ìŠµ, Replay mechanism, ì„±ëŠ¥ í‰ê°€ ê´€ë¦¬
    """
    
    def __init__(self,
                 model: Optional[TextVibCLIP] = None,
                 device: torch.device = torch.device('cpu'),
                 save_dir: str = 'checkpoints',
                 use_amp: bool = True,
                 max_grad_norm: float = 0.1,
                 domain_order: List[Union[int, str]] = None,
                 data_dir: Optional[str] = None,
                 dataset_type: str = DATA_CONFIG.get('dataset_type', 'uos'),
                 patience: Optional[int] = None):
        """
        Args:
            model (TextVibCLIP, optional): ì‚¬ì „ ì´ˆê¸°í™”ëœ ëª¨ë¸
            device (torch.device): í•™ìŠµ ë””ë°”ì´ìŠ¤
            save_dir (str): ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ
            use_amp (bool): AMP ì‚¬ìš© ì—¬ë¶€
            max_grad_norm (float): Gradient clipping ìµœëŒ€ norm
            domain_order (List[Union[int, str]]): ë„ë©”ì¸ ìˆœì„œ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        self.device = device
        self.save_dir = save_dir
        self.max_grad_norm = max_grad_norm
        os.makedirs(save_dir, exist_ok=True)
        
        # AMP ì„¤ì •
        self.scaler, self.use_amp = setup_amp_and_scaler(device, use_amp)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        if model is None:
            self.model = create_textvib_model('first_domain')
        else:
            self.model = model
        
        self.model.to(device)
        
        # Replay buffer
        self.replay_buffer = ReplayBuffer()
        
        # í•™ìŠµ ìƒíƒœ ê´€ë¦¬
        self.current_domain_idx = 0
        self.completed_domains = []
        self.domain_order = domain_order if domain_order is not None else DATA_CONFIG['domain_order']
        # ë°ì´í„° ì„¤ì • (í‰ê°€ ì‹œ ì¼ê´€ì„± ìœ ì§€)
        self.data_dir = data_dir if data_dir is not None else DATA_CONFIG['data_dir']
        self.dataset_type = dataset_type
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_history = defaultdict(list)  # {domain: [accuracy_list]}
        self.loss_history = defaultdict(list)
        self.forgetting_scores = []
        
        # í•™ìŠµ ì„¤ì •
        self.batch_size = TRAINING_CONFIG['batch_size']
        self.num_epochs = TRAINING_CONFIG['num_epochs']
        self.learning_rate = TRAINING_CONFIG['learning_rate']
        self.weight_decay = TRAINING_CONFIG['weight_decay']
        self.replay_ratio = TRAINING_CONFIG['replay_ratio']
        self.grad_accum_steps = int(TRAINING_CONFIG.get('grad_accum_steps', 1))
        self.patience = int(patience) if patience is not None else int(TRAINING_CONFIG.get('patience', 10))
        
        logger.info(f"ContinualTrainer ì´ˆê¸°í™” ì™„ë£Œ: device={device}")
    
    def train_first_domain(self, 
                         first_domain_dataloader: Optional[DataLoader] = None,
                         num_epochs: int = None) -> Dict[str, float]:
        """
        ì²« ë²ˆì§¸ ë„ë©”ì¸(600 RPM) í•™ìŠµ
        í…ìŠ¤íŠ¸-ì§„ë™ ì •ë ¬ì„ ìœ„í•œ ì´ˆê¸° í•™ìŠµ ë‹¨ê³„
        
        Args:
            first_domain_dataloader (DataLoader, optional): ì²« ë²ˆì§¸ ë„ë©”ì¸ ë°ì´í„°ë¡œë”
            num_epochs (int, optional): í•™ìŠµ ì—í¬í¬ ìˆ˜
            
        Returns:
            Dict[str, float]: í•™ìŠµ ê²°ê³¼ ë©”íŠ¸ë¦­
        """
        logger.info("=== First Domain Training ì‹œì‘ (600 RPM) ===")
        
        # ë°ì´í„°ë¡œë” ì¤€ë¹„
        if first_domain_dataloader is None:
            # ì‹œë‚˜ë¦¬ì˜¤ì— ë§ëŠ” dataset_typeê³¼ data_dir ì‚¬ìš©
            if hasattr(self, 'dataset_type'):
                dataset_type = self.dataset_type
            else:
                dataset_type = 'uos'  # ê¸°ë³¸ê°’
            
            if hasattr(self, 'data_dir'):
                data_dir = self.data_dir
            else:
                data_dir = DATA_CONFIG['data_dir'] if dataset_type == 'uos' else CWRU_DATA_CONFIG['data_dir']
            
            if hasattr(self, 'domain_order'):
                domain_order = self.domain_order
            else:
                domain_order = DATA_CONFIG['domain_order'] if dataset_type == 'uos' else CWRU_DATA_CONFIG['domain_order']
            
            # ğŸš€ ìºì‹œëœ DataLoader ì‚¬ìš© (ê³ ì†í™”)
            first_domain_dataloader = create_cached_first_domain_dataloader(
                data_dir=data_dir,
                domain_order=domain_order,
                dataset_type=dataset_type,
                subset='train', 
                batch_size=self.batch_size
            )
        
        if num_epochs is None:
            num_epochs = self.num_epochs
        
        # ëª¨ë¸ì„ ì²« ë²ˆì§¸ ë„ë©”ì¸ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •
        self.model.switch_to_first_domain_mode()  # First domain mode (LoRA í™œì„±í™”)
        
        # Optimizer ì„¤ì • (Text LoRA + Vibration full)
        optimizer = self._create_optimizer()
        scheduler = self._create_scheduler(optimizer, len(first_domain_dataloader) * num_epochs)
        
        # ë””ë²„ê·¸/ëª¨ë‹ˆí„°ë§ìš©: ê·¸ë¼ë””ì–¸íŠ¸ ë…¸ë¦„ ê¸°ë¡ ë²„í¼
        if not hasattr(self, 'debug_grad_norms'):
            self.debug_grad_norms = []  # ê° í•­ëª©: {'step': int, 'text_lora': float, 'vib': float}

        # í•™ìŠµ ë£¨í”„
        self.model.train()
        epoch_losses = []
        
        for epoch in range(num_epochs):
            # ì²« ë„ë©”ì¸ ì˜¨ë„ ìŠ¤ì¼€ì¤„(ì„ í˜•): init -> final
            inf_cfg = MODEL_CONFIG.get('infonce', {})
            t_text_init = float(inf_cfg.get('first_domain_temperature_text_init',
                                            inf_cfg.get('first_domain_temperature_text', 0.10)))
            t_text_final = float(inf_cfg.get('first_domain_temperature_text_final',
                                             inf_cfg.get('first_domain_temperature_text', 0.10)))
            t_vib_init  = float(inf_cfg.get('first_domain_temperature_vib_init',
                                            inf_cfg.get('first_domain_temperature_vib', 0.10)))
            t_vib_final = float(inf_cfg.get('first_domain_temperature_vib_final',
                                            inf_cfg.get('first_domain_temperature_vib', 0.10)))
            if num_epochs > 1:
                ratio = epoch / (num_epochs - 1)
            else:
                ratio = 1.0
            t_text = t_text_init + (t_text_final - t_text_init) * ratio
            t_vib  = t_vib_init  + (t_vib_final  - t_vib_init)  * ratio
            self.model.infonce_loss.update_temperatures(t_text, t_vib)
            if epoch % 5 == 0 or epoch == 0:
                logger.info(f"[TempSchedule] epoch {epoch+1}/{num_epochs}: Ï„_text={t_text:.3f}, Ï„_vib={t_vib:.3f}")

            epoch_loss = 0.0
            num_batches = 0
            
            for batch_idx, batch in enumerate(first_domain_dataloader):
                # ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                batch = self._move_batch_to_device(batch)
                
                # Forward pass
                # grad accumulation: ì‚¬ì´í´ ì‹œì‘ì‹œì—ë§Œ zero_grad
                if (batch_idx % self.grad_accum_steps) == 0:
                    optimizer.zero_grad(set_to_none=True)
                
                if self.use_amp:
                    with torch.cuda.amp.autocast():
                        results = self.model(batch)
                        loss = results['loss'] / self.grad_accum_steps
                    
                    # Backward pass with AMP + grad accumulation
                    self.scaler.scale(loss).backward()
                    
                    if (batch_idx + 1) % self.grad_accum_steps == 0:
                        # Gradient clipping ë° grad norm ì¸¡ì • ì¤€ë¹„ë¥¼ ìœ„í•œ unscale (ì‚¬ì´í´ ëì—ì„œë§Œ)
                        if self.max_grad_norm > 0:
                            self.scaler.unscale_(optimizer)
                            # ë””ë²„ê·¸: grad norm ì¸¡ì • (í…ìŠ¤íŠ¸ LoRA, ì§„ë™ ì¸ì½”ë”)
                            try:
                                text_lora_params = [
                                    p for n, p in self.model.text_encoder.distilbert.named_parameters()
                                    if ('lora_' in n) and p.requires_grad and (p.grad is not None)
                                ]
                            except Exception:
                                text_lora_params = []
                            vib_params = [
                                p for p in self.model.vibration_encoder.parameters()
                                if p.requires_grad and (p.grad is not None)
                            ]
                            def _global_grad_norm(params):
                                if not params:
                                    return 0.0
                                import math
                                total = 0.0
                                for p in params:
                                    if p.grad is not None:
                                        param_norm = p.grad.data.float().norm(2).item()
                                        total += param_norm * param_norm
                                return math.sqrt(total)
                            grad_norm_text = _global_grad_norm(text_lora_params)
                            grad_norm_vib = _global_grad_norm(vib_params)
                            if batch_idx % 50 == 0:
                                self.debug_grad_norms.append({
                                    'epoch': epoch + 1,
                                    'batch': batch_idx,
                                    'text_lora': float(grad_norm_text),
                                    'vib': float(grad_norm_vib)
                                })
                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                        self.scaler.step(optimizer)
                        self.scaler.update()
                else:
                    results = self.model(batch)
                    loss = results['loss'] / self.grad_accum_steps
                    
                    # Backward pass
                    loss.backward()
                    
                    if (batch_idx + 1) % self.grad_accum_steps == 0:
                        # Gradient clipping ë° grad norm ì¸¡ì • (ì‚¬ì´í´ ëì—ì„œë§Œ)
                        if self.max_grad_norm > 0:
                            try:
                                text_lora_params = [
                                    p for n, p in self.model.text_encoder.distilbert.named_parameters()
                                    if ('lora_' in n) and p.requires_grad and (p.grad is not None)
                                ]
                            except Exception:
                                text_lora_params = []
                            vib_params = [
                                p for p in self.model.vibration_encoder.parameters()
                                if p.requires_grad and (p.grad is not None)
                            ]
                            def _global_grad_norm(params):
                                if not params:
                                    return 0.0
                                import math
                                total = 0.0
                                for p in params:
                                    if p.grad is not None:
                                        param_norm = p.grad.data.float().norm(2).item()
                                        total += param_norm * param_norm
                                return math.sqrt(total)
                            grad_norm_text = _global_grad_norm(text_lora_params)
                            grad_norm_vib = _global_grad_norm(vib_params)
                            if batch_idx % 50 == 0:
                                self.debug_grad_norms.append({
                                    'epoch': epoch + 1,
                                    'batch': batch_idx,
                                    'text_lora': float(grad_norm_text),
                                    'vib': float(grad_norm_vib)
                                })
                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                        optimizer.step()
                
                if (batch_idx + 1) % self.grad_accum_steps == 0:
                    scheduler.step()
                
                epoch_loss += loss.item()
                num_batches += 1
                
                # ë¡œê¹… (ì ì ˆí•œ ê°„ê²©ìœ¼ë¡œ)
                if batch_idx % 50 == 0:
                    logger.info(f"First Domain Epoch {epoch+1}/{num_epochs}, "
                               f"Batch {batch_idx}, Loss: {loss.item():.4f}")
            
            avg_epoch_loss = epoch_loss / num_batches
            epoch_losses.append(avg_epoch_loss)
            
            logger.info(f"First Domain Epoch {epoch+1} ì™„ë£Œ: Avg Loss = {avg_epoch_loss:.4f}")
        
        # ì²« ë²ˆì§¸ ë„ë©”ì¸ìœ¼ë¡œ í‘œì‹œ
        first_domain = self.domain_order[0]
        self.completed_domains.append(first_domain)
        self.loss_history[first_domain] = epoch_losses
        
        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        checkpoint_path = os.path.join(self.save_dir, 'first_domain_final.pth')
        self.model.save_checkpoint(checkpoint_path, num_epochs, optimizer.state_dict())
        
        # ì „ì²´ ë„ë©”ì¸ ì„±ëŠ¥ í‰ê°€
        domain_dataloaders = create_domain_dataloaders(
            data_dir=self.data_dir,
            domain_order=self.domain_order,
            dataset_type=self.dataset_type,
            batch_size=self.batch_size
        )
        first_domain_performance = self._evaluate_all_domains(domain_dataloaders)
        
        # ì„±ëŠ¥ ê¸°ë¡ (ëª¨ë“  ë©”íŠ¸ë¦­ ì €ì¥)
        first_domain_accuracy = 0.0
        for domain, metrics in first_domain_performance.items():
            if domain not in self.performance_history:
                self.performance_history[domain] = {'accuracy': [], 'top1_retrieval': [], 'top5_retrieval': []}
            
            self.performance_history[domain]['accuracy'].append(metrics['accuracy'])
            self.performance_history[domain]['top1_retrieval'].append(metrics.get('top1_retrieval', 0.0))
            self.performance_history[domain]['top5_retrieval'].append(metrics.get('top5_retrieval', 0.0))
            
            # ì²« ë²ˆì§¸ ë„ë©”ì¸ ì •í™•ë„ ê¸°ë¡
            first_domain_accuracy = metrics['accuracy']
            break  # ì²« ë²ˆì§¸ ë„ë©”ì¸ë§Œ í™•ì¸
        
        # ì¡°ê¸° ì¢…ë£Œ ì²´í¬ ë¹„í™œì„±í™” (ë””ë²„ê¹… ë° ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ìš©)
        # if first_domain_accuracy < 0.80:
        #     error_msg = f"âŒ ì²« ë²ˆì§¸ ë„ë©”ì¸ ì •í™•ë„ {first_domain_accuracy:.4f} < 0.80 (80%)"
        #     logger.error(error_msg)
        #     logger.error("ğŸ›‘ ì‹¤í—˜ ì˜ë¯¸ ì—†ìŒ - ì¡°ê¸° ì¢…ë£Œ!")
        #     raise RuntimeError(f"First domain accuracy too low: {first_domain_accuracy:.4f} < 0.80")
        # else:
        logger.info(f"ğŸ“Š ì²« ë²ˆì§¸ ë„ë©”ì¸ ì •í™•ë„: {first_domain_accuracy:.4f} (ì¡°ê¸° ì¢…ë£Œ ë¹„í™œì„±í™”)")
        
        logger.info("=== First Domain Training ì™„ë£Œ ===")
        
        # ğŸ¨ First Domain Alignment ì‹œê°í™” ìƒì„±
        logger.info("ğŸ“Š First Domain Alignment ì‹œê°í™” ìƒì„± ì¤‘...")
        try:
            alignment_results = self._create_first_domain_alignment_visualization(
                domain_dataloaders, first_domain
            )
            logger.info(f"âœ… Alignment ì‹œê°í™” ì™„ë£Œ: {alignment_results.get('save_path', 'N/A')}")
        except Exception as e:
            logger.warning(f"âš ï¸ Alignment ì‹œê°í™” ì‹¤íŒ¨: {e}")
            alignment_results = {}
        
        # grad norm ìš”ì•½
        grad_text_vals = [d['text_lora'] for d in self.debug_grad_norms] if hasattr(self, 'debug_grad_norms') else []
        grad_vib_vals = [d['vib'] for d in self.debug_grad_norms] if hasattr(self, 'debug_grad_norms') else []
        grad_summary = {
            'text_lora_mean': float(np.mean(grad_text_vals)) if grad_text_vals else 0.0,
            'vib_mean': float(np.mean(grad_vib_vals)) if grad_vib_vals else 0.0,
            'samples': len(self.debug_grad_norms) if hasattr(self, 'debug_grad_norms') else 0
        }

        return {
            'final_loss': epoch_losses[-1],
            'avg_loss': np.mean(epoch_losses),
            'domain_performances': first_domain_performance,
            'grad_norms_summary': grad_summary,
            'alignment_visualization': alignment_results  # ì‹œê°í™” ê²°ê³¼ ì¶”ê°€
        }
    
    def train_remaining_domains(self, domain_dataloaders: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ë‚˜ë¨¸ì§€ ë„ë©”ì¸ë“¤(800~1600 RPM) ìˆœì°¨ í•™ìŠµ
        Replay mechanismì„ í™œìš©í•œ ì ì§„ì  í•™ìŠµ
        
        Args:
            domain_dataloaders (Dict, optional): ë„ë©”ì¸ë³„ ë°ì´í„°ë¡œë”
            
        Returns:
            Dict[str, Any]: í•™ìŠµ ê²°ê³¼ ë° ë©”íŠ¸ë¦­
        """
        logger.info("=== Remaining Domains Training ì‹œì‘ (800~1600 RPM) ===")
        
        # ë°ì´í„°ë¡œë” ì¤€ë¹„
        if domain_dataloaders is None:
            domain_dataloaders = create_domain_dataloaders(batch_size=self.batch_size)
        
        # Continual modeë¡œ ì „í™˜ (Text freeze, Vibration adaptation)
        self.model.switch_to_continual_mode()
        
        remaining_domains_results = {}
        after_performance = {}  # ì´ˆê¸°í™”
        
        # Domain 2ë¶€í„° ìˆœì°¨ í•™ìŠµ (ì²« ë²ˆì§¸ ë„ë©”ì¸ì€ ì´ë¯¸ ì™„ë£Œ)
        for domain_idx in range(1, len(self.domain_order)):
            domain_value = self.domain_order[domain_idx]
            
            logger.info(f"\n--- Domain {domain_value} í•™ìŠµ ì‹œì‘ ---")
            
            # í˜„ì¬ ë„ë©”ì¸ ë°ì´í„°ë¡œë” (í‚¤ ì¡´ì¬ í™•ì¸)
            if domain_value not in domain_dataloaders:
                logger.error(f"ë„ë©”ì¸ {domain_value}ê°€ dataloadersì— ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ë„ë©”ì¸: {list(domain_dataloaders.keys())}")
                continue
                
            current_train_loader = domain_dataloaders[domain_value]['train']
            current_val_loader = domain_dataloaders[domain_value]['val']
            
            # ì´ì „ ë„ë©”ì¸ ì„±ëŠ¥ ê¸°ë¡ (Forgetting ê³„ì‚°ìš©) - ê°„ì†Œí™”
            logger.info(f"Domain {domain_value} í•™ìŠµ ì „ ì„±ëŠ¥ í‰ê°€ ìŠ¤í‚µ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)")
            before_performance = {}  # ì„ì‹œë¡œ ë¹„í™œì„±í™”
            
            # í˜„ì¬ ë„ë©”ì¸ í•™ìŠµ
            domain_results = self._train_single_domain(
                domain_value, current_train_loader, current_val_loader
            )
            
            # í•™ìŠµ í›„ ì„±ëŠ¥ í‰ê°€ - ê°„ì†Œí™”
            logger.info(f"Domain {domain_value} í•™ìŠµ í›„ ì„±ëŠ¥ í‰ê°€ (ë¹ ë¥¸ ë²„ì „)")
            after_performance = self._evaluate_all_domains_fast(domain_dataloaders)
            
            # Forgetting ê³„ì‚°
            forgetting_score = self._calculate_forgetting(before_performance, after_performance)
            self.forgetting_scores.append(forgetting_score)
            
            # ì„±ëŠ¥ ê¸°ë¡ (ëª¨ë“  ë©”íŠ¸ë¦­ ì €ì¥)
            for eval_domain, metrics in after_performance.items():
                if eval_domain not in self.performance_history:
                    self.performance_history[eval_domain] = {'accuracy': [], 'top1_retrieval': [], 'top5_retrieval': []}
                self.performance_history[eval_domain]['accuracy'].append(metrics.get('accuracy', 0.0))
                self.performance_history[eval_domain]['top1_retrieval'].append(metrics.get('top1_retrieval', 0.0))
                self.performance_history[eval_domain]['top5_retrieval'].append(metrics.get('top5_retrieval', 0.0))

            # í˜„ì¬ ë„ë©”ì¸ ì™„ë£Œ í‘œì‹œ ë° ê²°ê³¼ ì €ì¥
            self.completed_domains.append(domain_value)
            remaining_domains_results[domain_value] = {
                'training_results': domain_results,
                'performance': after_performance,
                'forgetting_score': forgetting_score
            }
            
            logger.info(f"Domain {domain_value} í•™ìŠµ ì™„ë£Œ: Forgetting Score = {forgetting_score:.4f}")
            
            # ğŸ¨ ë„ë©”ì¸ë³„ ì„±ëŠ¥ ì‹œê°í™” ìƒì„±
            logger.info(f"ğŸ“Š Domain {domain_value} ì„±ëŠ¥ ì‹œê°í™” ìƒì„± ì¤‘...")
            try:
                domain_viz_results = self._create_domain_performance_visualization(
                    domain_value, after_performance, forgetting_score
                )
                logger.info(f"âœ… Domain {domain_value} ì‹œê°í™” ì™„ë£Œ: {domain_viz_results.get('save_path', 'N/A')}")
            except Exception as e:
                logger.warning(f"âš ï¸ Domain {domain_value} ì‹œê°í™” ì‹¤íŒ¨: {e}")
        
        # ìµœì¢… ì„±ëŠ¥ ìš”ì•½ (í’€ í‰ê°€ë¡œ ë®ì–´ì“°ê¸°)
        full_eval_results = self._evaluate_all_domains(domain_dataloaders)
        # ê¸°ë¡ì—ë„ í’€ í‰ê°€ ìµœì‹ ê°’ ì¶”ê°€
        for eval_domain, metrics in full_eval_results.items():
            if eval_domain not in self.performance_history:
                self.performance_history[eval_domain] = {'accuracy': [], 'top1_retrieval': [], 'top5_retrieval': []}
            self.performance_history[eval_domain]['accuracy'].append(metrics.get('accuracy', 0.0))
            self.performance_history[eval_domain]['top1_retrieval'].append(metrics.get('top1_retrieval', 0.0))
            self.performance_history[eval_domain]['top5_retrieval'].append(metrics.get('top5_retrieval', 0.0))
        final_metrics = self._calculate_final_metrics()
        remaining_domains_results['final_metrics'] = final_metrics
        
        logger.info("=== Remaining Domains Training ì™„ë£Œ ===")
        
        return remaining_domains_results
    
    def _train_single_domain(self, 
                           domain_value: Union[int, str],
                           train_loader: DataLoader,
                           val_loader: DataLoader) -> Dict[str, float]:
        """
        ë‹¨ì¼ ë„ë©”ì¸ í•™ìŠµ (Replay í¬í•¨)
        
        Args:
            domain_value (Union[int, str]): ë„ë©”ì¸ ê°’ (RPM ë˜ëŠ” HP)
            train_loader (DataLoader): í˜„ì¬ ë„ë©”ì¸ í•™ìŠµ ë°ì´í„°
            val_loader (DataLoader): í˜„ì¬ ë„ë©”ì¸ ê²€ì¦ ë°ì´í„°
            
        Returns:
            Dict[str, float]: í•™ìŠµ ê²°ê³¼
        """
        # Optimizer (Vibration encoderë§Œ í•™ìŠµ)
        optimizer = self._create_continual_optimizer()
        
        # í˜„ì¬ ë„ë©”ì¸ ì„ë² ë”© ìˆ˜ì§‘ (Replay bufferìš©)
        domain_embeddings = self._collect_domain_embeddings(train_loader)
        
        # Replay bufferì— ì¶”ê°€ (ğŸ¯ ë¼ë²¨ ì •ë³´ í¬í•¨)
        if domain_embeddings:
            self.replay_buffer.add_domain_data(
                domain_value,
                domain_embeddings['text_embeddings'],
                domain_embeddings['vib_embeddings'],
                domain_embeddings['metadata'],
                labels=domain_embeddings.get('labels', None)
            )
        
        # í•™ìŠµ ë£¨í”„
        self.model.train()
        epoch_losses = []
        best_val_acc = 0.0
        patience_counter = 0
        
        for epoch in range(self.num_epochs):
            epoch_loss = 0.0
            num_batches = 0
            
            for batch_idx, batch in enumerate(train_loader):
                # í˜„ì¬ ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                batch = self._move_batch_to_device(batch)
                current_batch_size = batch['vibration'].size(0)
                
                # Replay ë°ì´í„° ìƒ˜í”Œë§ (ì„±ëŠ¥ ìµœì í™”: ê°„í—ì  ì‚¬ìš©)
                use_replay = (batch_idx % 3 == 0)  # 3ë°°ì¹˜ë§ˆë‹¤ í•œ ë²ˆë§Œ replay ì‚¬ìš©
                
                if use_replay:
                    replay_batch_size = min(int(current_batch_size * self.replay_ratio), 8)  # í¬ê¸° ì œí•œ
                    replay_data = self.replay_buffer.sample_replay_data(
                        replay_batch_size, exclude_current=True, device=self.device
                    )
                    
                    # í˜„ì¬ ë°ì´í„°ì™€ Replay ë°ì´í„° ê²°í•©
                    if replay_data is not None:
                        combined_batch = self._combine_current_and_replay(batch, replay_data)
                    else:
                        combined_batch = batch
                else:
                    combined_batch = batch
                
                # Forward pass
                optimizer.zero_grad()
                
                if self.use_amp:
                    with torch.cuda.amp.autocast():
                        results = self.model(combined_batch)
                        loss = results['loss']
                    
                    # Backward pass with AMP
                    self.scaler.scale(loss).backward()
                    
                    # Gradient clipping
                    if self.max_grad_norm > 0:
                        self.scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                    
                    self.scaler.step(optimizer)
                    self.scaler.update()
                else:
                    results = self.model(combined_batch)
                    loss = results['loss']
                    
                    # Backward pass
                    loss.backward()
                    
                    # Gradient clipping
                    if self.max_grad_norm > 0:
                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                    
                    optimizer.step()
                
                epoch_loss += loss.item()
                num_batches += 1
                
                # ë¡œê¹… (ë” ê°„ê²°í•˜ê²Œ)
                if batch_idx % 20 == 0:
                    replay_info = f"R:{replay_batch_size}" if replay_data else "No-R"
                    logger.info(f"D{domain_value} E{epoch+1} B{batch_idx}: "
                               f"Loss={loss.item():.4f}, {replay_info}")
            
            avg_epoch_loss = epoch_loss / num_batches
            epoch_losses.append(avg_epoch_loss)
            
            # Validation
            val_metrics = self._evaluate_single_domain(val_loader)
            val_acc = val_metrics['accuracy']
            
            logger.info(f"Domain {domain_value} Epoch {epoch+1}: "
                       f"Loss = {avg_epoch_loss:.4f}, Val Acc = {val_acc:.4f}")
            
            # Early stopping
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                
                # Best model ì €ì¥
                checkpoint_path = os.path.join(self.save_dir, f'domain_{domain_value}_best.pth')
                self.model.save_checkpoint(checkpoint_path, epoch, optimizer.state_dict())
            else:
                patience_counter += 1
                
                if patience_counter >= TRAINING_CONFIG['patience']:
                    logger.info(f"Early stopping at epoch {epoch+1}")
                    break
        
        # ë„ë©”ì¸ í•™ìŠµ ì™„ë£Œ
        self.loss_history[domain_value] = epoch_losses
        
        # ì•ˆì „í•œ ê²°ê³¼ ë°˜í™˜ (epoch_lossesê°€ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ)
        final_loss = epoch_losses[-1] if epoch_losses else float('inf')
        num_epochs = len(epoch_losses)
        
        return {
            'final_loss': final_loss,
            'best_val_accuracy': best_val_acc,
            'num_epochs': num_epochs
        }
    
    def _collect_domain_embeddings(self, dataloader: DataLoader) -> Optional[Dict]:
        """í˜„ì¬ ë„ë©”ì¸ ë°ì´í„°ì˜ ì„ë² ë”© ìˆ˜ì§‘ (ğŸ¯ ë¼ë²¨ ì •ë³´ í¬í•¨)"""
        self.model.eval()
        
        text_embeddings = []
        vib_embeddings = []
        metadata_list = []
        labels_list = []
        
        with torch.no_grad():
            for batch in dataloader:
                batch = self._move_batch_to_device(batch)
                results = self.model(batch, return_embeddings=True)
                
                text_embeddings.append(results['text_embeddings'])
                vib_embeddings.append(results['vib_embeddings'])
                metadata_list.extend(batch['metadata'])
                
                # ğŸ¯ ë¼ë²¨ ì •ë³´ë„ ìˆ˜ì§‘
                if 'labels' in batch:
                    labels_list.append(batch['labels'])
        
        if text_embeddings:
            result = {
                'text_embeddings': torch.cat(text_embeddings, dim=0),
                'vib_embeddings': torch.cat(vib_embeddings, dim=0),
                'metadata': metadata_list
            }
            
            # ë¼ë²¨ ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ)
            if labels_list:
                result['labels'] = torch.cat(labels_list, dim=0)
            
            return result
        return None
    
    def _combine_current_and_replay(self, current_batch: Dict, replay_data: Dict) -> Dict:
        """í˜„ì¬ ë°°ì¹˜ì™€ Replay ë°ì´í„° ê²°í•© (ğŸ¯ ë¼ë²¨ ì •ë³´ í¬í•¨)"""
        # ì§„ë™ ì‹ í˜¸ëŠ” í˜„ì¬ ë°°ì¹˜ì—ì„œë§Œ (ReplayëŠ” ì„ë² ë”©ë§Œ ì €ì¥)
        combined_batch = current_batch.copy()  # ê¸°ì¡´ ëª¨ë“  ì •ë³´ ë³µì‚¬
        
        # Replay ì„ë² ë”©ì„ ëª¨ë¸ì— ì£¼ì…í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„
        combined_batch['replay_text_embeddings'] = replay_data['text_embeddings']
        combined_batch['replay_vib_embeddings'] = replay_data['vib_embeddings']
        
        # ğŸ¯ Replay ë¼ë²¨ ì •ë³´ë„ ì „ë‹¬ (í´ë˜ìŠ¤ ê¸°ë°˜ contrastive learningìš©)
        if 'labels' in replay_data:
            combined_batch['replay_labels'] = replay_data['labels']
        
        return combined_batch
    
    def _evaluate_single_domain(self, dataloader: DataLoader) -> Dict[str, float]:
        """ë‹¨ì¼ ë„ë©”ì¸ ì„±ëŠ¥ í‰ê°€ (retrieval ë©”íŠ¸ë¦­ í¬í•¨)"""
        self.model.eval()
        
        all_text_embeddings = []
        all_vib_embeddings = []
        all_file_idx = []
        all_labels = []
        all_labels = []
        
        # DataLoader ì•ˆì „ì„± í™•ë³´ë¥¼ ìœ„í•œ ì¡°ì¹˜
        try:
            with torch.no_grad():
                max_batches = int(EVAL_CONFIG.get('max_full_eval_batches', -1))
                for batch_idx, batch in enumerate(dataloader):
                    # ì„¤ì • ê¸°ë°˜ ë°°ì¹˜ ì œí•œ (ê¸°ë³¸ ë¬´ì œí•œ)
                    if max_batches >= 0 and batch_idx >= max_batches:
                        logger.debug(f"í‰ê°€ ì¤‘ë‹¨: ì„¤ì •ëœ ìµœëŒ€ ë°°ì¹˜ {max_batches} ë„ë‹¬")
                        break
                        
                    batch = self._move_batch_to_device(batch)
                    results = self.model(batch, return_embeddings=True)
                    
                    all_text_embeddings.append(results['text_embeddings'])
                    all_vib_embeddings.append(results['vib_embeddings'])
                    if 'file_idx' in batch:
                        # ë””ë°”ì´ìŠ¤ ì¼ì¹˜ ìœ ì§€ (GPU ìƒì—ì„œ ë°”ë¡œ ì‚¬ìš©)
                        all_file_idx.append(batch['file_idx'])
                    if 'labels' in batch:
                        all_labels.append(batch['labels'])
                    
        except Exception as e:
            logger.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
        
        if not all_text_embeddings:
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
        
        # ëª¨ë“  ì„ë² ë”© ê²°í•©
        text_emb = torch.cat(all_text_embeddings, dim=0)
        vib_emb = torch.cat(all_vib_embeddings, dim=0)
        file_idx = torch.cat(all_file_idx, dim=0) if all_file_idx else None
        labels_tensor = torch.cat(all_labels, dim=0) if all_labels else None
        
        # ğŸ¯ FIXED: í‘œì¤€ L2 ì •ê·œí™” (gradient ë³´ì¡´)
        text_emb = F.normalize(text_emb, p=2, dim=1)
        vib_emb = F.normalize(vib_emb, p=2, dim=1)
        
        # 1. Retrieval ì •í™•ë„
        similarity_matrix = torch.matmul(text_emb, vib_emb.t())  # (N, N)
        
        # ë””ë²„ê·¸: ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œ ìœ ì‚¬ë„ ë¶„í¬ í™•ì¸
        if hasattr(self, '_debug_count'):
            self._debug_count += 1
        else:
            self._debug_count = 1
            
        if self._debug_count <= 2:  # ì²˜ìŒ 2ë²ˆë§Œ ë””ë²„ê·¸
            # ì„ë² ë”© í†µê³„ ë¡œê·¸
            try:
                t_mean = text_emb.mean().item(); t_std = text_emb.std(unbiased=False).item()
                v_mean = vib_emb.mean().item(); v_std = vib_emb.std(unbiased=False).item()
                logger.info(f"ğŸ” DEBUG - ì„ë² ë”© í†µê³„ | text mean/std: {t_mean:.4f}/{t_std:.4f}, vib mean/std: {v_mean:.4f}/{v_std:.4f}")
            except Exception:
                pass
            logger.info(f"ğŸ” DEBUG - ë°°ì¹˜ í¬ê¸°: {text_emb.size(0)}")
            logger.info(f"ğŸ” DEBUG - ëŒ€ê°ì„  ìœ ì‚¬ë„ (ì •ë‹µ): {torch.diag(similarity_matrix)[:5].tolist()}")
            logger.info(f"ğŸ” DEBUG - ì²« í–‰ ìœ ì‚¬ë„ (ì „ì²´): {similarity_matrix[0, :5].tolist()}")
            predicted_tmp = torch.argmax(similarity_matrix, dim=1)
            logger.info(f"ğŸ” DEBUG - ìµœëŒ€ ìœ ì‚¬ë„ ì¸ë±ìŠ¤: {predicted_tmp[:10].tolist()}")

            # ì¶”ê°€ ë¬´ê²°ì„± ì²´í¬: ìœ ì‚¬ë„ í†µê³„ ë° argmax ë¶„í¬
            N = similarity_matrix.size(0)
            diag_vals = torch.diag(similarity_matrix)
            diag_mean = float(diag_vals.mean().item())
            diag_std = float(diag_vals.std(unbiased=False).item())
            diag_min = float(diag_vals.min().item())
            diag_max = float(diag_vals.max().item())
            off_mask = ~torch.eye(N, dtype=torch.bool, device=similarity_matrix.device)
            off_vals = similarity_matrix[off_mask]
            off_mean = float(off_vals.mean().item())
            off_std = float(off_vals.std(unbiased=False).item())
            logger.info(
                f"ğŸ” DEBUG - ìœ ì‚¬ë„ í†µê³„ | diag mean/std/min/max: "
                f"{diag_mean:.4f}/{diag_std:.4f}/{diag_min:.4f}/{diag_max:.4f}, "
                f"off mean/std: {off_mean:.4f}/{off_std:.4f}"
            )

            binc = torch.bincount(predicted_tmp, minlength=N)
            topk = min(10, N)
            top_vals, top_idx = torch.topk(binc, k=topk)
            top_pairs = [(int(i), int(v)) for i, v in zip(top_idx.tolist(), top_vals.tolist())]
            logger.info(f"ğŸ” DEBUG - argmax ìƒìœ„ {topk} ì¸ë±ìŠ¤/ë¹ˆë„: {top_pairs}")

            # ì…”í”Œ ë² ì´ìŠ¤ë¼ì¸ (í´ë˜ìŠ¤ ê¸°ë°˜, ê³µì •ì„± ë§ˆìŠ¤í¬ ë¯¸ì ìš© ë‹¨ìˆœ ì°¸ì¡°)
            if N >= 2 and labels_tensor is not None:
                # ë¼ë²¨ ì •ê·œí™”
                if labels_tensor.dim() == 2 and labels_tensor.size(1) >= 1:
                    cls_dbg = labels_tensor[:, 0]
                elif labels_tensor.dim() == 1:
                    cls_dbg = labels_tensor
                else:
                    cls_dbg = labels_tensor.view(-1)
                cls_dbg = cls_dbg.to(text_emb.device)

                # ğŸ¯ FIXED: ì˜¬ë°”ë¥¸ ì…”í”Œ ë² ì´ìŠ¤ë¼ì¸ ê³„ì‚°
                perm = torch.randperm(N, device=text_emb.device)
                sim_shuf = torch.matmul(text_emb, vib_emb[perm].t())
                pred_shuf = torch.argmax(sim_shuf, dim=1)
                
                # ì˜¬ë°”ë¥¸ ê³„ì‚°: ì…”í”Œëœ ìˆœì„œì—ì„œ ì˜ˆì¸¡í•œ í´ë˜ìŠ¤ì™€ ì›ë˜ í´ë˜ìŠ¤ ë¹„êµ
                predicted_classes_shuf = cls_dbg[perm[pred_shuf]]  # ì˜ˆì¸¡ëœ ìœ„ì¹˜ì˜ ì‹¤ì œ í´ë˜ìŠ¤
                top1_shuf = (predicted_classes_shuf == cls_dbg).float().mean().item()
                
                k_dbg = min(5, N)
                _, topk_shuf = torch.topk(sim_shuf, k=k_dbg, dim=1)
                topk_classes_shuf = cls_dbg[perm[topk_shuf]]  # topk ìœ„ì¹˜ë“¤ì˜ ì‹¤ì œ í´ë˜ìŠ¤
                top5_shuf = (topk_classes_shuf == cls_dbg.unsqueeze(1)).any(dim=1).float().mean().item()
                
                logger.info(f"ğŸ” DEBUG - ì…”í”Œ ë² ì´ìŠ¤ë¼ì¸ Top1/Top5 (class): {top1_shuf:.4f}/{top5_shuf:.4f}")
                
                # ì¶”ê°€ ë””ë²„ê·¸: í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
                unique_classes = torch.unique(cls_dbg)
                class_counts = [(cls.item(), (cls_dbg == cls).sum().item()) for cls in unique_classes]
                logger.info(f"ğŸ” DEBUG - ë°°ì¹˜ ë‚´ í´ë˜ìŠ¤ ë¶„í¬: {class_counts}")
                
                # ì´ë¡ ì  ëœë¤ ë² ì´ìŠ¤ë¼ì¸ ê³„ì‚°
                n_classes = len(unique_classes)
                theoretical_random = 1.0 / n_classes if n_classes > 0 else 0.0
                logger.info(f"ğŸ” DEBUG - ì´ë¡ ì  ëœë¤ ë² ì´ìŠ¤ë¼ì¸: {theoretical_random:.4f} (í´ë˜ìŠ¤ ìˆ˜: {n_classes})")
        
        # ğŸ¯ ENHANCED: í´ë˜ìŠ¤ ì¸ì‹ í‰ê°€ + í‘œì¤€ contrastive í‰ê°€
        # 1) í‘œì¤€ diagonal matching (ëª¨ë‹ˆí„°ë§ìš©)
        _, predicted_indices = torch.max(similarity_matrix, dim=1)
        correct_indices = torch.arange(text_emb.size(0), device=text_emb.device)
        diagonal_accuracy = (predicted_indices == correct_indices).float().mean().item()

        # ğŸ¯ ê³µì • í‰ê°€: ìê¸° ìì‹ (ëŒ€ê°ì„ ) ì œê±° + (í–‰ë³„ ì¡°ê±´ë¶€) ë™ì¼íŒŒì¼ ì œê±°
        N = similarity_matrix.size(0)
        sim_eval = similarity_matrix.clone()
        if N > 1:
            sim_eval.fill_diagonal_(-1e4)
            if file_idx is not None and file_idx.numel() == N and labels_tensor is not None:
                # ë¼ë²¨ í…ì„œ ì •ê·œí™”
                if labels_tensor.dim() == 2 and labels_tensor.size(1) >= 1:
                    class_labels_for_mask = labels_tensor[:, 0]
                elif labels_tensor.dim() == 1:
                    class_labels_for_mask = labels_tensor
                else:
                    class_labels_for_mask = labels_tensor.view(-1)
                class_labels_for_mask = class_labels_for_mask.to(text_emb.device)

                same_file_mask = (file_idx.unsqueeze(1) == file_idx.unsqueeze(0))
                class_equal_mask = (class_labels_for_mask.unsqueeze(1) == class_labels_for_mask.unsqueeze(0))
                off_diag_mask = ~torch.eye(N, dtype=torch.bool, device=text_emb.device)
                # ê° í–‰ì— ë™ì¼íŒŒì¼ì´ ì•„ë‹Œ ê°™ì€ í´ë˜ìŠ¤ í›„ë³´ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ë™ì¼íŒŒì¼ ì „ë¶€ ë§ˆìŠ¤í‚¹
                has_other_file_positive = ((class_equal_mask & ~same_file_mask & off_diag_mask)).any(dim=1)
                row_mask = has_other_file_positive.unsqueeze(1).expand(-1, N)
                mask_to_apply = same_file_mask & row_mask
                sim_eval = sim_eval.masked_fill(mask_to_apply, -1e4)

        # ğŸ¯ CRITICAL FIX: ì˜¬ë°”ë¥¸ Zero-shot ë¶„ë¥˜ í‰ê°€
        # ê° ì§„ë™ ì‹ í˜¸ë¥¼ ëª¨ë“  ê°€ëŠ¥í•œ í´ë˜ìŠ¤ ì„¤ëª…ê³¼ ë¹„êµí•˜ì—¬ ë¶„ë¥˜
        
        class_top1 = diagonal_accuracy  # ê¸°ë³¸ê°’
        class_top5 = diagonal_accuracy
        
        if labels_tensor is not None:
            # ë¼ë²¨ ì •ê·œí™”
            if labels_tensor.dim() == 2 and labels_tensor.size(1) >= 1:
                class_labels = labels_tensor[:, 0]  # UOS ì£¼ ë¶„ë¥˜
            elif labels_tensor.dim() == 1:
                class_labels = labels_tensor
            else:
                class_labels = labels_tensor.view(-1)
            class_labels = class_labels.to(text_emb.device)
            
            # ğŸ¯ NEW: Zero-shot ë¶„ë¥˜ í‰ê°€
            # ëª¨ë“  ê°€ëŠ¥í•œ í´ë˜ìŠ¤ì˜ prototype í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            unique_classes = torch.unique(class_labels)
            n_classes = len(unique_classes)
            
            if n_classes > 1:  # í´ë˜ìŠ¤ê°€ ì—¬ëŸ¬ ê°œ ìˆì„ ë•Œë§Œ zero-shot í‰ê°€
                # ê° í´ë˜ìŠ¤ì˜ prototype ì„ë² ë”© ê³„ì‚° (í‰ê· )
                class_prototypes = []
                for cls in unique_classes:
                    cls_mask = (class_labels == cls)
                    if cls_mask.any():
                        cls_text_emb = text_emb[cls_mask].mean(dim=0, keepdim=True)
                        class_prototypes.append(cls_text_emb)
                
                if len(class_prototypes) == n_classes:
                    # ëª¨ë“  í´ë˜ìŠ¤ì˜ prototype ê²°í•©
                    prototype_embeddings = torch.cat(class_prototypes, dim=0)  # (n_classes, embed_dim)
                    
                    # ê° ì§„ë™ ì„ë² ë”©ì„ ëª¨ë“  í´ë˜ìŠ¤ prototypeê³¼ ë¹„êµ
                    vib_to_prototype_sim = torch.matmul(vib_emb, prototype_embeddings.t())  # (N, n_classes)
                    
                    # ì˜ˆì¸¡: ê°€ì¥ ìœ ì‚¬í•œ prototypeì˜ í´ë˜ìŠ¤
                    predicted_class_idx = torch.argmax(vib_to_prototype_sim, dim=1)
                    predicted_classes = unique_classes[predicted_class_idx]
                    
                    # Zero-shot ë¶„ë¥˜ ì •í™•ë„
                    class_top1 = (predicted_classes == class_labels).float().mean().item()
                    
                    # Top-5 ê³„ì‚° (í´ë˜ìŠ¤ ìˆ˜ê°€ 5ê°œ ì´ìƒì¼ ë•Œ)
                    if n_classes >= 5:
                        _, top5_idx = torch.topk(vib_to_prototype_sim, k=5, dim=1)
                        top5_classes = unique_classes[top5_idx]  # (N, 5)
                        class_top5 = (top5_classes == class_labels.unsqueeze(1)).any(dim=1).float().mean().item()
                    else:
                        class_top5 = class_top1
                else:
                    # Prototype ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                    top1_pred = torch.argmax(sim_eval, dim=1)
                    class_top1 = (class_labels[top1_pred] == class_labels).float().mean().item()
                    class_top5 = class_top1
            else:
                # í´ë˜ìŠ¤ê°€ 1ê°œë¿ì´ë©´ í•­ìƒ 100%
                class_top1 = 1.0
                class_top5 = 1.0

        retrieval_accuracy = class_top1
        top1_accuracy = class_top1
        top5_accuracy = class_top5
        
        return {
            'accuracy': retrieval_accuracy,  # ì£¼ ì •í™•ë„ ì§€í‘œ
            'diagonal_accuracy': diagonal_accuracy,  # í‘œì¤€ contrastive ì •í™•ë„
            'class_accuracy': class_top1,  # í´ë˜ìŠ¤ ì¸ì‹ ì •í™•ë„
            'top1_retrieval': top1_accuracy,
            'top5_retrieval': top5_accuracy
        }
    
    def _evaluate_all_domains(self, domain_dataloaders: Dict) -> Dict[int, Dict[str, float]]:
        """ëª¨ë“  ë„ë©”ì¸ ì„±ëŠ¥ í‰ê°€"""
        results = {}
        
        for domain_value, loaders in domain_dataloaders.items():
            test_loader = loaders['test']
            metrics = self._evaluate_single_domain(test_loader)
            
            results[domain_value] = {
                **metrics,  # accuracy, top1_retrieval, top5_retrieval
                'num_samples': len(test_loader.dataset)
            }
        
        return results
    
    def _evaluate_all_domains_fast(self, domain_dataloaders: Dict) -> Dict[str, Dict[str, float]]:
        """ë¹ ë¥¸ ë„ë©”ì¸ í‰ê°€ (ì ì€ ë°°ì¹˜ë§Œ ì‚¬ìš©)"""
        results = {}
        
        for domain_value, loaders in domain_dataloaders.items():
            test_loader = loaders['test']
            
            # ì²« 5ë°°ì¹˜ë§Œ í‰ê°€í•˜ì—¬ ë¹ ë¥¸ ê·¼ì‚¬ì¹˜ ê³„ì‚°
            limited_metrics = self._evaluate_single_domain_fast(test_loader)
            
            results[domain_value] = {
                **limited_metrics,
                'num_samples': min(len(test_loader.dataset), 5 * test_loader.batch_size)
            }
        
        return results
    
    def _evaluate_single_domain_fast(self, dataloader: DataLoader) -> Dict[str, float]:
        """ë¹ ë¥¸ ë‹¨ì¼ ë„ë©”ì¸ í‰ê°€ (5ë°°ì¹˜ë§Œ)"""
        self.model.eval()
        
        all_text_embeddings = []
        all_vib_embeddings = []
        all_file_idx = []
        all_labels = []
        
        try:
            with torch.no_grad():
                max_fast = int(EVAL_CONFIG.get('max_fast_eval_batches', 5))
                for batch_idx, batch in enumerate(dataloader):
                    if batch_idx >= max_fast:
                        break
                        
                    batch = self._move_batch_to_device(batch)
                    results = self.model(batch, return_embeddings=True)
                    
                    all_text_embeddings.append(results['text_embeddings'])
                    all_vib_embeddings.append(results['vib_embeddings'])
                    if 'file_idx' in batch:
                        all_file_idx.append(batch['file_idx'])
                    if 'labels' in batch:
                        all_labels.append(batch['labels'])
                    
        except Exception as e:
            logger.error(f"ë¹ ë¥¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
        
        if not all_text_embeddings:
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
        
        # ì„ë² ë”© ê²°í•© ë° ë©”íŠ¸ë¦­ ê³„ì‚°
        text_emb = torch.cat(all_text_embeddings, dim=0)
        vib_emb = torch.cat(all_vib_embeddings, dim=0)
        file_idx = torch.cat(all_file_idx, dim=0) if all_file_idx else None
        labels_tensor = torch.cat(all_labels, dim=0) if all_labels else None

        # ğŸ¯ FIXED: í‘œì¤€ L2 ì •ê·œí™” (gradient ë³´ì¡´)
        text_emb = F.normalize(text_emb, p=2, dim=1)
        vib_emb = F.normalize(vib_emb, p=2, dim=1)
        similarity = torch.matmul(text_emb, vib_emb.t())

        # ê³µì •ì„± ë§ˆìŠ¤í¬: ìê¸°ìì‹  ì œê±° + (í–‰ë³„ ì¡°ê±´ë¶€) ë™ì¼íŒŒì¼ ì œê±°
        N = similarity.size(0)
        sim_eval = similarity.clone()
        if N > 1:
            sim_eval.fill_diagonal_(-1e4)
            if file_idx is not None and file_idx.numel() == N and labels_tensor is not None:
                if labels_tensor.dim() == 2 and labels_tensor.size(1) >= 1:
                    class_labels_for_mask = labels_tensor[:, 0]
                elif labels_tensor.dim() == 1:
                    class_labels_for_mask = labels_tensor
                else:
                    class_labels_for_mask = labels_tensor.view(-1)
                class_labels_for_mask = class_labels_for_mask.to(text_emb.device)

                same_file_mask = (file_idx.unsqueeze(1) == file_idx.unsqueeze(0))
                class_equal_mask = (class_labels_for_mask.unsqueeze(1) == class_labels_for_mask.unsqueeze(0))
                off_diag_mask = ~torch.eye(N, dtype=torch.bool, device=text_emb.device)
                has_other_file_positive = ((class_equal_mask & ~same_file_mask & off_diag_mask)).any(dim=1)
                row_mask = has_other_file_positive.unsqueeze(1).expand(-1, N)
                mask_to_apply = same_file_mask & row_mask
                sim_eval = sim_eval.masked_fill(mask_to_apply, -1e4)

        # ğŸ¯ CRITICAL FIX: ì˜¬ë°”ë¥¸ Zero-shot ë¶„ë¥˜ í‰ê°€ (fast ë²„ì „ì—ë„ ì ìš©)
        class_top1 = 0.0
        class_top5 = 0.0
        
        if labels_tensor is not None:
            # ë¼ë²¨ ì •ê·œí™”
            if labels_tensor.dim() == 2 and labels_tensor.size(1) >= 1:
                class_labels = labels_tensor[:, 0]
            elif labels_tensor.dim() == 1:
                class_labels = labels_tensor
            else:
                class_labels = labels_tensor.view(-1)
            class_labels = class_labels.to(text_emb.device)
            
            # Zero-shot ë¶„ë¥˜ í‰ê°€ (full ë²„ì „ê³¼ ë™ì¼í•œ ë¡œì§)
            unique_classes = torch.unique(class_labels)
            n_classes = len(unique_classes)
            
            if n_classes > 1:
                # ê° í´ë˜ìŠ¤ì˜ prototype ì„ë² ë”© ê³„ì‚°
                class_prototypes = []
                for cls in unique_classes:
                    cls_mask = (class_labels == cls)
                    if cls_mask.any():
                        cls_text_emb = text_emb[cls_mask].mean(dim=0, keepdim=True)
                        class_prototypes.append(cls_text_emb)
                
                if len(class_prototypes) == n_classes:
                    # ëª¨ë“  í´ë˜ìŠ¤ì˜ prototype ê²°í•©
                    prototype_embeddings = torch.cat(class_prototypes, dim=0)
                    
                    # ê° ì§„ë™ ì„ë² ë”©ì„ ëª¨ë“  í´ë˜ìŠ¤ prototypeê³¼ ë¹„êµ
                    vib_to_prototype_sim = torch.matmul(vib_emb, prototype_embeddings.t())
                    
                    # ì˜ˆì¸¡: ê°€ì¥ ìœ ì‚¬í•œ prototypeì˜ í´ë˜ìŠ¤
                    predicted_class_idx = torch.argmax(vib_to_prototype_sim, dim=1)
                    predicted_classes = unique_classes[predicted_class_idx]
                    
                    # Zero-shot ë¶„ë¥˜ ì •í™•ë„
                    class_top1 = (predicted_classes == class_labels).float().mean().item()
                    
                    # Top-5 ê³„ì‚°
                    if n_classes >= 5:
                        _, top5_idx = torch.topk(vib_to_prototype_sim, k=5, dim=1)
                        top5_classes = unique_classes[top5_idx]
                        class_top5 = (top5_classes == class_labels.unsqueeze(1)).any(dim=1).float().mean().item()
                    else:
                        class_top5 = class_top1
                else:
                    # Prototype ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
                    class_top1 = 0.0
                    class_top5 = 0.0
            else:
                # í´ë˜ìŠ¤ê°€ 1ê°œë¿ì´ë©´ í•­ìƒ 100%
                class_top1 = 1.0
                class_top5 = 1.0
        else:
            # ë¼ë²¨ ì—†ìœ¼ë©´ ëŒ€ê°ì„  ê¸°ì¤€ìœ¼ë¡œ ê·¼ì‚¬
            _, pred = torch.max(sim_eval, dim=1)
            target = torch.arange(text_emb.size(0), device=text_emb.device)
            class_top1 = (pred == target).float().mean().item()
            k = min(5, sim_eval.size(1))
            if k > 1:
                _, topk = torch.topk(sim_eval, k=k, dim=1)
                target_expanded = target.unsqueeze(1).expand(-1, k)
                class_top5 = (topk == target_expanded).any(dim=1).float().mean().item()
            else:
                class_top5 = class_top1

        # ë¹ ë¥¸ í‰ê°€ì—ì„œë„ ë¬´ê²°ì„± ë””ë²„ê·¸(í•œ ë²ˆë§Œ)
        if not hasattr(self, '_debug_fast_once'):
            self._debug_fast_once = True
            N = similarity.size(0)
            diag_vals = torch.diag(similarity)
            diag_mean = float(diag_vals.mean().item())
            diag_std = float(diag_vals.std(unbiased=False).item())
            off_mask = ~torch.eye(N, dtype=torch.bool, device=similarity.device)
            off_vals = similarity[off_mask]
            off_mean = float(off_vals.mean().item())
            off_std = float(off_vals.std(unbiased=False).item())
            logger.info(
                f"ğŸ” DEBUG(FAST) - N={N}, diag mean/std={diag_mean:.4f}/{diag_std:.4f}, "
                f"off mean/std={off_mean:.4f}/{off_std:.4f}, Top1={class_top1:.4f}, Top5={class_top5:.4f}"
            )
            # ì…”í”Œ ë² ì´ìŠ¤ë¼ì¸ (í´ë˜ìŠ¤ ê¸°ë°˜)
            if N >= 2 and labels_tensor is not None:
                if labels_tensor.dim() == 2 and labels_tensor.size(1) >= 1:
                    cls_dbg = labels_tensor[:, 0]
                elif labels_tensor.dim() == 1:
                    cls_dbg = labels_tensor
                else:
                    cls_dbg = labels_tensor.view(-1)
                cls_dbg = cls_dbg.to(text_emb.device)
                perm = torch.randperm(N, device=text_emb.device)
                sim_shuf = torch.matmul(text_emb, vib_emb[perm].t())
                pred_shuf = torch.argmax(sim_shuf, dim=1)
                top1_shuf = (cls_dbg[perm][pred_shuf] == cls_dbg).float().mean().item()
                k_dbg = min(5, N)
                _, topk_shuf = torch.topk(sim_shuf, k=k_dbg, dim=1)
                top5_shuf = (cls_dbg.unsqueeze(1) == cls_dbg[perm][topk_shuf]).any(dim=1).float().mean().item()
                logger.info(f"ğŸ” DEBUG(FAST) - ì…”í”Œ ë² ì´ìŠ¤ë¼ì¸ Top1/Top5 (class): {top1_shuf:.4f}/{top5_shuf:.4f}")

        return {
            'accuracy': class_top1,  # í´ë˜ìŠ¤ ê¸°ë°˜ Top-1
            'diagonal_accuracy': class_top1,  # ë¼ë²¨ ë¶€ì¬ ì‹œ ë™ì¼
            'class_accuracy': class_top1,
            'top1_retrieval': class_top1,
            'top5_retrieval': class_top5
        }
    
    def _calculate_forgetting(self, before: Dict, after: Dict) -> float:
        """Forgetting score ê³„ì‚°"""
        if len(self.completed_domains) <= 1:
            return 0.0
        
        forgetting_scores = []
        for domain in self.completed_domains[:-1]:  # ë§ˆì§€ë§‰ ë„ë©”ì¸ ì œì™¸
            before_acc = before.get(domain, {}).get('accuracy', 0.0)
            after_acc = after.get(domain, {}).get('accuracy', 0.0)
            forgetting = max(0.0, before_acc - after_acc)
            forgetting_scores.append(forgetting)
        
        return np.mean(forgetting_scores) if forgetting_scores else 0.0
    
    def _calculate_final_metrics(self) -> Dict[str, float]:
        """ìµœì¢… Continual Learning ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if not self.performance_history:
            return {}
        
        # Average metrics (ë§ˆì§€ë§‰ ì„±ëŠ¥)
        final_accuracies = []
        final_top1_retrievals = []
        final_top5_retrievals = []
        
        for domain in self.completed_domains:
            if domain in self.performance_history:
                if self.performance_history[domain]['accuracy']:
                    final_accuracies.append(self.performance_history[domain]['accuracy'][-1])
                if self.performance_history[domain]['top1_retrieval']:
                    final_top1_retrievals.append(self.performance_history[domain]['top1_retrieval'][-1])
                if self.performance_history[domain]['top5_retrieval']:
                    final_top5_retrievals.append(self.performance_history[domain]['top5_retrieval'][-1])
        
        avg_accuracy = np.mean(final_accuracies) if final_accuracies else 0.0
        avg_top1_retrieval = np.mean(final_top1_retrievals) if final_top1_retrievals else 0.0
        avg_top5_retrieval = np.mean(final_top5_retrievals) if final_top5_retrievals else 0.0
        
        # Average Forgetting
        avg_forgetting = np.mean(self.forgetting_scores) if self.forgetting_scores else 0.0
        
        return {
            'average_accuracy': avg_accuracy,
            'average_top1_retrieval': avg_top1_retrieval,
            'average_top5_retrieval': avg_top5_retrieval,
            'average_forgetting': avg_forgetting,
            'num_domains': len(self.completed_domains),
            'final_accuracies': final_accuracies,
            'final_top1_retrievals': final_top1_retrievals,
            'final_top5_retrievals': final_top5_retrievals
        }
    
    def _create_optimizer(self) -> torch.optim.Optimizer:
        """First domain trainingìš© optimizer ìƒì„± (íŒŒë¼ë¯¸í„° ê·¸ë£¹ ë¶„ë¦¬)"""
        base_lr = self.learning_rate
        lora_mult = float(TRAINING_CONFIG.get('lora_lr_mult', 3.0))
        proj_mult = float(TRAINING_CONFIG.get('proj_lr_mult', 3.0))
        vib_mult  = float(TRAINING_CONFIG.get('vib_lr_mult', 1.0))

        params = []
        seen = set()

        # Text LoRA íŒŒë¼ë¯¸í„° ê·¸ë£¹
        try:
            lora_params = [p for n, p in self.model.text_encoder.distilbert.named_parameters()
                           if ('lora_' in n) and p.requires_grad]
            if lora_params:
                params.append({'params': lora_params, 'lr': base_lr * lora_mult, 'weight_decay': self.weight_decay})
                for p in lora_params:
                    seen.add(id(p))
        except Exception:
            pass

        # Text projection íŒŒë¼ë¯¸í„° ê·¸ë£¹
        if hasattr(self.model.text_encoder, 'projection'):
            proj_params = [p for p in self.model.text_encoder.projection.parameters() if p.requires_grad]
            if proj_params:
                params.append({'params': proj_params, 'lr': base_lr * proj_mult, 'weight_decay': self.weight_decay})
                for p in proj_params:
                    seen.add(id(p))

        # Vibration encoder íŒŒë¼ë¯¸í„° ê·¸ë£¹
        vib_params = [p for p in self.model.vibration_encoder.parameters() if p.requires_grad]
        vib_params = [p for p in vib_params if id(p) not in seen]
        if vib_params:
            params.append({'params': vib_params, 'lr': base_lr * vib_mult, 'weight_decay': self.weight_decay})
            for p in vib_params:
                seen.add(id(p))

        # ğŸ¯ CRITICAL FIX: InfoNCE ì˜¨ë„ íŒŒë¼ë¯¸í„° ì¶”ê°€
        temp_params = []
        if hasattr(self.model.infonce_loss, 'log_temperature_text'):
            temp_params.append(self.model.infonce_loss.log_temperature_text)
        if hasattr(self.model.infonce_loss, 'log_temperature_vib'):
            temp_params.append(self.model.infonce_loss.log_temperature_vib)
        
        if temp_params:
            params.append({'params': temp_params, 'lr': base_lr * 2.0, 'weight_decay': 0.0})  # ì˜¨ë„ëŠ” weight decay ì—†ìŒ
            for p in temp_params:
                seen.add(id(p))

        # ëˆ„ë½ íŒŒë¼ë¯¸í„° ë³´ì™„
        remain = [p for p in self.model.parameters() if p.requires_grad and id(p) not in seen]
        if remain:
            params.append({'params': remain, 'lr': base_lr, 'weight_decay': self.weight_decay})

        return optim.AdamW(params)
    
    def _create_scheduler(self, optimizer, total_steps):
        """í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„± (ë‹¨ì¼ êµ¬í˜„)"""
        from torch.optim.lr_scheduler import CosineAnnealingLR
        return CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=1e-6)
    
    def _create_continual_optimizer(self) -> torch.optim.Optimizer:
        """Continual learningìš© optimizer ìƒì„± (Vibration + Text projection + ì˜¨ë„)"""
        base_lr = self.learning_rate
        proj_mult = float(TRAINING_CONFIG.get('proj_lr_mult', 5.0))
        vib_mult = float(TRAINING_CONFIG.get('vib_lr_mult', 2.0))
        
        params = []
        seen = set()
        
        # Text projection íŒŒë¼ë¯¸í„° (continual learningì—ì„œ í•™ìŠµ ê°€ëŠ¥)
        if hasattr(self.model.text_encoder, 'projection'):
            proj_params = [p for p in self.model.text_encoder.projection.parameters() if p.requires_grad]
            if proj_params:
                params.append({'params': proj_params, 'lr': base_lr * proj_mult, 'weight_decay': self.weight_decay})
                for p in proj_params:
                    seen.add(id(p))
        
        # Vibration encoder íŒŒë¼ë¯¸í„°
        vib_params = [p for p in self.model.vibration_encoder.parameters() if p.requires_grad]
        vib_params = [p for p in vib_params if id(p) not in seen]
        if vib_params:
            params.append({'params': vib_params, 'lr': base_lr * vib_mult, 'weight_decay': self.weight_decay})
            for p in vib_params:
                seen.add(id(p))
        
        # ğŸ¯ CRITICAL FIX: InfoNCE ì˜¨ë„ íŒŒë¼ë¯¸í„° ì¶”ê°€
        temp_params = []
        if hasattr(self.model.infonce_loss, 'log_temperature_text'):
            temp_params.append(self.model.infonce_loss.log_temperature_text)
        if hasattr(self.model.infonce_loss, 'log_temperature_vib'):
            temp_params.append(self.model.infonce_loss.log_temperature_vib)
        
        if temp_params:
            params.append({'params': temp_params, 'lr': base_lr * 2.0, 'weight_decay': 0.0})
            for p in temp_params:
                seen.add(id(p))
        
        # ëˆ„ë½ íŒŒë¼ë¯¸í„° ë³´ì™„
        remain = [p for p in self.model.parameters() if p.requires_grad and id(p) not in seen]
        if remain:
            params.append({'params': remain, 'lr': base_lr, 'weight_decay': self.weight_decay})
        
        return optim.AdamW(params)
    
    def _create_scheduler(self, optimizer: torch.optim.Optimizer, total_steps: int):
        """í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„± (ë‹¨ì¼ êµ¬í˜„)"""
        from torch.optim.lr_scheduler import CosineAnnealingLR
        return CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=1e-6)
    
    def _move_batch_to_device(self, batch: Dict) -> Dict:
        """ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™"""
        if 'vibration' in batch:
            batch['vibration'] = batch['vibration'].to(self.device)
        if 'labels' in batch:
            batch['labels'] = batch['labels'].to(self.device)
        if 'file_idx' in batch:
            batch['file_idx'] = batch['file_idx'].to(self.device)
        return batch
    
    def save_training_history(self, path: str):
        """í•™ìŠµ ì´ë ¥ ì €ì¥"""
        history = {
            'performance_history': dict(self.performance_history),
            'loss_history': dict(self.loss_history),
            'forgetting_scores': self.forgetting_scores,
            'completed_domains': self.completed_domains,
            'domain_order': self.domain_order
        }
        
        torch.save(history, path)
        logger.info(f"í•™ìŠµ ì´ë ¥ ì €ì¥ë¨: {path}")
    
    def plot_continual_learning_curves(self, save_path: Optional[str] = None):
        """Continual learning ê²°ê³¼ ì‹œê°í™”"""
        if not self.performance_history:
            logger.warning("ì‹œê°í™”í•  ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŒ")
            return
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. Domainë³„ ì„±ëŠ¥ ë³€í™”
        for domain in self.completed_domains:
            if domain in self.performance_history:
                ax1.plot(self.performance_history[domain], label=f'Domain {domain}')
        ax1.set_xlabel('Learning Phase')
        ax1.set_ylabel('Accuracy')
        ax1.set_title('Performance Evolution by Domain')
        ax1.legend()
        ax1.grid(True)
        
        # 2. Forgetting scores
        if self.forgetting_scores:
            ax2.plot(self.forgetting_scores, 'r-o')
            ax2.set_xlabel('Domain')
            ax2.set_ylabel('Forgetting Score')
            ax2.set_title('Catastrophic Forgetting')
            ax2.grid(True)
        
        # 3. ìµœì¢… ì„±ëŠ¥ ë¹„êµ
        final_accs = [self.performance_history[d][-1] if d in self.performance_history else 0
                     for d in self.completed_domains]
        ax3.bar(range(len(self.completed_domains)), final_accs)
        ax3.set_xlabel('Domain')
        ax3.set_ylabel('Final Accuracy')
        ax3.set_title('Final Performance by Domain')
        ax3.set_xticks(range(len(self.completed_domains)))
        ax3.set_xticklabels([str(d) for d in self.completed_domains])
        
        # 4. Loss curves
        for domain in self.completed_domains:
            if domain in self.loss_history:
                ax4.plot(self.loss_history[domain], label=f'Domain {domain}')
        ax4.set_xlabel('Epoch')
        ax4.set_ylabel('Loss')
        ax4.set_title('Training Loss by Domain')
        ax4.legend()
        ax4.grid(True)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"í•™ìŠµ ê³¡ì„  ì €ì¥ë¨: {save_path}")
        else:
            plt.show()
    
    def _create_first_domain_alignment_visualization(self, 
                                                   domain_dataloaders: Dict, 
                                                   first_domain: int) -> Dict[str, Any]:
        """
        ì²« ë²ˆì§¸ ë„ë©”ì¸ì—ì„œ Textì™€ Vibration Encoderì˜ alignment ì‹œê°í™”
        
        Args:
            domain_dataloaders: ë„ë©”ì¸ë³„ ë°ì´í„°ë¡œë”
            first_domain: ì²« ë²ˆì§¸ ë„ë©”ì¸ ê°’
            
        Returns:
            Dict: ì‹œê°í™” ê²°ê³¼ ì •ë³´
        """
        from .visualization import create_visualizer
        
        # ì²« ë²ˆì§¸ ë„ë©”ì¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë”
        if first_domain not in domain_dataloaders:
            logger.warning(f"ë„ë©”ì¸ {first_domain} ë°ì´í„°ë¡œë”ê°€ ì—†ìŒ")
            return {}
        
        test_loader = domain_dataloaders[first_domain]['test']
        
        # ì„ë² ë”© ìˆ˜ì§‘ (ìµœëŒ€ 200ê°œ ìƒ˜í”Œ)
        self.model.eval()
        text_embeddings = []
        vib_embeddings = []
        labels = []
        bearing_types = []
        
        max_samples = 200
        collected_samples = 0
        
        with torch.no_grad():
            for batch in test_loader:
                if collected_samples >= max_samples:
                    break
                
                # ë°°ì¹˜ ì²˜ë¦¬
                vibrations = batch['vibration'].to(self.device)
                texts = batch['text']
                metadata = batch['metadata']
                
                # ëª¨ë¸ forward
                model_results = self.model({
                    'vibration': vibrations,
                    'text': texts
                }, return_embeddings=True)
                
                # ì„ë² ë”© ìˆ˜ì§‘
                text_emb = model_results['text_embeddings'].cpu()
                vib_emb = model_results['vib_embeddings'].cpu()
                
                text_embeddings.append(text_emb)
                vib_embeddings.append(vib_emb)
                
                # ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
                for meta in metadata:
                    labels.append(meta.get('bearing_condition', 'H'))
                    bearing_types.append(meta.get('bearing_type', '6204'))
                
                collected_samples += len(vibrations)
                
                if collected_samples >= max_samples:
                    break
        
        if not text_embeddings:
            logger.warning("ì„ë² ë”© ìˆ˜ì§‘ ì‹¤íŒ¨")
            return {}
        
        # í…ì„œ ê²°í•©
        text_embeddings = torch.cat(text_embeddings, dim=0)
        vib_embeddings = torch.cat(vib_embeddings, dim=0)
        
        # ìƒ˜í”Œ ìˆ˜ ë§ì¶¤
        min_samples = min(len(text_embeddings), len(labels), max_samples)
        text_embeddings = text_embeddings[:min_samples]
        vib_embeddings = vib_embeddings[:min_samples]
        labels = labels[:min_samples]
        bearing_types = bearing_types[:min_samples]
        
        # ì‹œê°í™” ìƒì„±
        visualizer = create_visualizer(self.save_dir)
        
        try:
            alignment_path = visualizer.create_encoder_alignment_plot(
                text_embeddings=text_embeddings,
                vib_embeddings=vib_embeddings,
                labels=labels,
                bearing_types=bearing_types,
                domain_name=f"Domain_{first_domain}",
                save_name=f"first_domain_alignment_{first_domain}"
            )
            
            return {
                'save_path': alignment_path,
                'num_samples': min_samples,
                'domain': first_domain
            }
            
        except Exception as e:
            logger.error(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {}
    
    def _create_domain_performance_visualization(self, 
                                               current_domain: int,
                                               performance_results: Dict,
                                               forgetting_score: float) -> Dict[str, Any]:
        """
        ê° ë„ë©”ì¸ ì™„ë£Œ í›„ ì„±ëŠ¥ ê²€ì¦ ì‹œê°í™” (accuracy, forgetting)
        
        Args:
            current_domain: í˜„ì¬ ì™„ë£Œëœ ë„ë©”ì¸
            performance_results: ì„±ëŠ¥ í‰ê°€ ê²°ê³¼
            forgetting_score: ë§ê° ì ìˆ˜
            
        Returns:
            Dict: ì‹œê°í™” ê²°ê³¼ ì •ë³´
        """
        import matplotlib.pyplot as plt
        
        # í˜„ì¬ê¹Œì§€ ì™„ë£Œëœ ë„ë©”ì¸ë“¤ì˜ ì„±ëŠ¥ ìˆ˜ì§‘
        domain_names = []
        accuracies = []
        
        for domain in self.completed_domains:
            domain_names.append(f"Domain_{domain}")
            if domain in performance_results:
                accuracies.append(performance_results[domain].get('accuracy', 0.0))
            else:
                accuracies.append(0.0)

        # ë§ê° ì ìˆ˜ (ì²« ë„ë©”ì¸ì€ 0), ê¸¸ì´ ì •í•©ì„± ë³´ì •
        n = len(domain_names)
        forgetting_scores = [0.0] + list(self.forgetting_scores)
        if len(forgetting_scores) < n:
            forgetting_scores = forgetting_scores + [0.0] * (n - len(forgetting_scores))
        elif len(forgetting_scores) > n:
            forgetting_scores = forgetting_scores[:n]
        
        # ì‹œê°í™” ìƒì„±
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # 1. ë„ë©”ì¸ë³„ ì •í™•ë„
        bars1 = ax1.bar(range(len(domain_names)), accuracies, 
                       color=['#2E86AB', '#F24236', '#F6AE2D', '#2F9B69', '#F18F01', '#6C757D'][:len(domain_names)],
                       alpha=0.8)
        ax1.set_xlabel('Domains')
        ax1.set_ylabel('Accuracy')
        ax1.set_title(f'Accuracy after Domain {current_domain}')
        ax1.set_xticks(range(len(domain_names)))
        ax1.set_xticklabels(domain_names, rotation=45)
        ax1.set_ylim(0, 1)
        ax1.grid(True, alpha=0.3)
        
        # ì •í™•ë„ ê°’ í‘œì‹œ
        for i, (bar, acc) in enumerate(zip(bars1, accuracies)):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{acc:.3f}', ha='center', va='bottom', fontsize=10)
        
        # 2. ë§ê° ì ìˆ˜
        bars2 = ax2.bar(range(len(domain_names)), forgetting_scores,
                       color='#F24236', alpha=0.7)
        ax2.set_xlabel('Domains')
        ax2.set_ylabel('Forgetting Score')
        ax2.set_title(f'Forgetting Score after Domain {current_domain}')
        ax2.set_xticks(range(len(domain_names)))
        ax2.set_xticklabels(domain_names, rotation=45)
        ax2.set_ylim(0, max(0.5, max(forgetting_scores) * 1.1) if forgetting_scores else 0.5)
        ax2.grid(True, alpha=0.3)
        
        # ë§ê° ì ìˆ˜ ê°’ í‘œì‹œ
        for i, (bar, forget) in enumerate(zip(bars2, forgetting_scores)):
            if forget > 0:
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                        f'{forget:.3f}', ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        
        # ì €ì¥
        save_path = os.path.join(self.save_dir, f'domain_{current_domain}_performance.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return {
            'save_path': save_path,
            'current_domain': current_domain,
            'num_completed_domains': len(self.completed_domains),
            'avg_accuracy': np.mean(accuracies) if accuracies else 0.0,
            'avg_forgetting': np.mean(forgetting_scores) if forgetting_scores else 0.0
        }


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    print("=== ContinualTrainer í…ŒìŠ¤íŠ¸ ===")
    
    # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPU ì‚¬ìš©
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Trainer ìƒì„±
    trainer = ContinualTrainer(device=device)
    
    print(f"Trainer ì´ˆê¸°í™” ì™„ë£Œ: device={device}")
    print(f"ë„ë©”ì¸ ìˆœì„œ: {trainer.domain_order}")
    print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„°: {trainer.model.get_trainable_parameters()}")
    
    print("\n=== ContinualTrainer í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
