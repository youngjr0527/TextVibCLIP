"""
ContinualTrainer v2: Ranking-based TextVibCLIPìš© í•™ìŠµ íŒŒì´í”„ë¼ì¸
InfoNCE ëŒ€ì‹  Triplet/Ranking Loss ì‚¬ìš©ìœ¼ë¡œ ì†Œê·œëª¨ ë°ì´í„°ì— ìµœì í™”
"""

import os
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from typing import Dict, List, Tuple, Optional, Any, Union
import logging
import numpy as np
from collections import defaultdict

from .textvib_model import TextVibCLIP, create_textvib_model
from .replay_buffer import ReplayBuffer
from .data_loader import create_domain_dataloaders, create_first_domain_dataloader
from .data_cache import create_cached_first_domain_dataloader
from configs.model_config import TRAINING_CONFIG, DATA_CONFIG, EVAL_CONFIG, MODEL_CONFIG, CWRU_DATA_CONFIG, FIRST_DOMAIN_CONFIG, CONTINUAL_CONFIG, CWRU_SPECIFIC_CONFIG, CWRU_FIRST_DOMAIN_CONFIG

logger = logging.getLogger(__name__)


class ContinualTrainer:
    """
    TextVibCLIP v2 Continual Learning Trainer
    
    Ranking-based learning with simplified architecture
    """
    
    def __init__(self,
                 model: Optional[TextVibCLIP] = None,
                 device: torch.device = torch.device('cpu'),
                 save_dir: str = 'checkpoints',
                 max_grad_norm: float = 0.1,
                 domain_order: List[Union[int, str]] = None,
                 data_dir: Optional[str] = None,
                 dataset_type: str = 'uos',
                 patience: Optional[int] = None,
                 results_save_dir: Optional[str] = None):
        """
        Args:
            model: ì‚¬ì „ ì´ˆê¸°í™”ëœ ëª¨ë¸
            device: í•™ìŠµ ë””ë°”ì´ìŠ¤
            save_dir: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ
            max_grad_norm: Gradient clipping
            domain_order: ë„ë©”ì¸ ìˆœì„œ
            data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬
            dataset_type: ë°ì´í„°ì…‹ íƒ€ì…
            patience: Early stopping patience
        """
        self.device = device
        self.save_dir = save_dir
        self.max_grad_norm = max_grad_norm
        os.makedirs(save_dir, exist_ok=True)
        # ê²°ê³¼ í´ë” ë‚´ ì²´í¬í¬ì¸íŠ¸ ë¯¸ëŸ¬ ì €ì¥ì†Œ (ì„ íƒ)
        self.mirror_save_dir = results_save_dir
        if self.mirror_save_dir:
            os.makedirs(self.mirror_save_dir, exist_ok=True)
        
        # ëª¨ë¸ ì´ˆê¸°í™” (ë°ì´í„°ì…‹ íƒ€ì… ì „ë‹¬)
        if model is None:
            self.model = create_textvib_model('first_domain', dataset_type)
        else:
            self.model = model
        
        self.model.to(device)
        
        # Replay buffer
        self.replay_buffer = ReplayBuffer()
        
        # í•™ìŠµ ìƒíƒœ ê´€ë¦¬
        self.current_domain_idx = 0
        self.completed_domains = []
        self.domain_order = domain_order if domain_order is not None else DATA_CONFIG['domain_order']
        self.data_dir = data_dir if data_dir is not None else DATA_CONFIG['data_dir']
        self.dataset_type = dataset_type
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_history = defaultdict(list)
        self.loss_history = defaultdict(list)
        self.forgetting_scores = []
        self.best_accuracy_per_domain: Dict[Union[int, str], float] = {}
        
        # í•™ìŠµ ì„¤ì •
        self.batch_size = TRAINING_CONFIG['batch_size']
        self.num_epochs = TRAINING_CONFIG['num_epochs']
        self.learning_rate = TRAINING_CONFIG['learning_rate']
        self.weight_decay = TRAINING_CONFIG['weight_decay']
        self.replay_ratio = TRAINING_CONFIG['replay_ratio']
        self.grad_accum_steps = int(TRAINING_CONFIG.get('grad_accum_steps', 1))
        self.patience = int(patience) if patience is not None else int(TRAINING_CONFIG.get('patience', 10))
        
        logger.info(f"ContinualTrainer v2 ì´ˆê¸°í™” ì™„ë£Œ: device={device}")
    
    def train_first_domain(self, 
                         first_domain_dataloader: Optional[DataLoader] = None,
                         num_epochs: int = None) -> Dict[str, float]:
        """
        ì²« ë²ˆì§¸ ë„ë©”ì¸ í•™ìŠµ (Foundation Learning)
        """
        logger.info("=== First Domain Training v2 ì‹œì‘ ===")
        
        # ë°ì´í„°ë¡œë” ì¤€ë¹„
        if first_domain_dataloader is None:
            first_domain_dataloader = create_cached_first_domain_dataloader(
                data_dir=self.data_dir,
                domain_order=self.domain_order,
                dataset_type=self.dataset_type,
                subset='train', 
                batch_size=self.batch_size
            )
        
        # ë°ì´í„°ì…‹ë³„ First domain ì„¤ì • ì ìš©
        if self.dataset_type == 'cwru':
            # CWRU: ê·¹ì†Œ ë°ì´í„° ì „ìš© ì„¤ì •
            config = CWRU_FIRST_DOMAIN_CONFIG
            logger.info("ğŸ¯ CWRU ê·¹ì†Œ ë°ì´í„° ì „ìš© First Domain ì„¤ì • ì ìš©")
        else:
            # UOS: í‘œì¤€ First Domain ì„¤ì •
            config = FIRST_DOMAIN_CONFIG
            logger.info("ğŸ¯ UOS í‘œì¤€ First Domain ì„¤ì • ì ìš©")
        
        if num_epochs is None:
            num_epochs = config['num_epochs']
        
        self.learning_rate = config['learning_rate']
        self.weight_decay = config['weight_decay']
        
        logger.info(f"First Domain ì„¤ì •: ì—í¬í¬={num_epochs}, LR={self.learning_rate:.1e}, WD={self.weight_decay:.1e}")
        
        # ëª¨ë¸ì„ ì²« ë²ˆì§¸ ë„ë©”ì¸ ëª¨ë“œë¡œ ì„¤ì •
        self.model.switch_to_first_domain_mode()
        
        # Optimizer ì„¤ì •
        optimizer = self._create_optimizer()
        scheduler = self._create_scheduler(optimizer)
        
        # í•™ìŠµ ë£¨í”„
        self.model.train()
        epoch_losses = []
        
        for epoch in range(num_epochs):
            epoch_loss = 0.0
            num_batches = 0
            
            for batch_idx, batch in enumerate(first_domain_dataloader):
                batch = self._move_batch_to_device(batch)
                
                # Forward pass
                if (batch_idx % self.grad_accum_steps) == 0:
                    optimizer.zero_grad(set_to_none=True)
                
                    results = self.model(batch)
                    loss = results['loss'] / self.grad_accum_steps
                    
                    # Backward pass
                    loss.backward()
                    
                    if (batch_idx + 1) % self.grad_accum_steps == 0:
                        if self.max_grad_norm > 0:
                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                        optimizer.step()
                
                epoch_loss += loss.item()
                num_batches += 1
                
                # ë¡œê¹…
                if batch_idx % 100 == 0:
                    logger.debug(f"First Domain Epoch {epoch+1}/{num_epochs}, "
                                 f"Batch {batch_idx}, Loss: {loss.item():.4f}")
            
            avg_epoch_loss = epoch_loss / num_batches
            epoch_losses.append(avg_epoch_loss)
            
            # ì—í¬í¬ ëì—ì„œ scheduler step
            scheduler.step()
            
            logger.info(f"First Domain Epoch {epoch+1} ì™„ë£Œ: Avg Loss = {avg_epoch_loss:.4f}")
        
        # ì²« ë²ˆì§¸ ë„ë©”ì¸ ì™„ë£Œ í‘œì‹œ
        first_domain = self.domain_order[0]
        self.completed_domains.append(first_domain)
        self.loss_history[first_domain] = epoch_losses
        
        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        checkpoint_path = os.path.join(self.save_dir, 'first_domain_final_v2.pth')
        self.model.save_checkpoint(checkpoint_path, num_epochs, optimizer.state_dict())
        # ë¯¸ëŸ¬ ì €ì¥
        if self.mirror_save_dir:
            mirror_path = os.path.join(self.mirror_save_dir, 'first_domain_final_v2.pth')
            self.model.save_checkpoint(mirror_path, num_epochs, optimizer.state_dict())
        
        # ì„±ëŠ¥ í‰ê°€
        domain_dataloaders = create_domain_dataloaders(
            data_dir=self.data_dir,
            domain_order=self.domain_order,
            dataset_type=self.dataset_type,
            batch_size=self.batch_size
        )
        first_domain_performance = self._evaluate_all_domains(domain_dataloaders)
        
        # ì„±ëŠ¥ ê¸°ë¡
        first_domain_accuracy = 0.0
        for domain, metrics in first_domain_performance.items():
            if domain not in self.performance_history:
                self.performance_history[domain] = {'accuracy': [], 'top1_retrieval': [], 'top5_retrieval': []}
            
            self.performance_history[domain]['accuracy'].append(metrics['accuracy'])
            self.performance_history[domain]['top1_retrieval'].append(metrics.get('top1_retrieval', 0.0))
            if self.dataset_type != 'cwru' and 'top5_retrieval' in metrics:
                self.performance_history[domain]['top5_retrieval'].append(metrics.get('top5_retrieval', 0.0))
            
            first_domain_accuracy = metrics['accuracy']
            self.best_accuracy_per_domain[domain] = max(self.best_accuracy_per_domain.get(domain, 0.0), float(first_domain_accuracy))
            break
        
        logger.info(f"ì²« ë²ˆì§¸ ë„ë©”ì¸ ì •í™•ë„: {first_domain_accuracy:.4f}")
        logger.info("=== First Domain Training v2 ì™„ë£Œ ===")
        
        return {
            'final_loss': epoch_losses[-1] if epoch_losses else float('nan'),
            'avg_loss': np.mean(epoch_losses) if epoch_losses else float('nan'),
            'domain_performances': first_domain_performance
        }
    
    def train_remaining_domains(self, domain_dataloaders: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ë‚˜ë¨¸ì§€ ë„ë©”ì¸ë“¤ ìˆœì°¨ í•™ìŠµ (Continual Learning)
        """
        logger.info("=== Remaining Domains Training v2 ì‹œì‘ ===")
        
        # ë°ì´í„°ì…‹ë³„ ì°¨ë³„í™”ëœ ì„¤ì • ì ìš©
        if self.dataset_type == 'cwru':
            # CWRU: ê·¹ì†Œ ë°ì´í„° ì „ìš© ì„¤ì •
            config = CWRU_SPECIFIC_CONFIG
            logger.info("ğŸ¯ CWRU ê·¹ì†Œ ë°ì´í„° ì „ìš© ì„¤ì • ì ìš©")
        else:
            # UOS: í‘œì¤€ Continual ì„¤ì •
            config = CONTINUAL_CONFIG
            logger.info("ğŸ¯ UOS í‘œì¤€ Continual ì„¤ì • ì ìš©")
        
        self.num_epochs = config['num_epochs']
        self.learning_rate = config['learning_rate']
        self.weight_decay = config['weight_decay']
        self.patience = config['patience']
        
        logger.info(f"ì„¤ì •: ì—í¬í¬={self.num_epochs}, LR={self.learning_rate:.1e}, WD={self.weight_decay:.1e}")
        
        # ë°ì´í„°ë¡œë” ì¤€ë¹„
        if domain_dataloaders is None:
            domain_dataloaders = create_domain_dataloaders(
                data_dir=self.data_dir,
                domain_order=self.domain_order,
                dataset_type=self.dataset_type,
                batch_size=self.batch_size
            )
        
        # Continual modeë¡œ ì „í™˜
        self.model.switch_to_continual_mode()
        
        remaining_domains_results = {}
        
        # Domain 2ë¶€í„° ìˆœì°¨ í•™ìŠµ
        for domain_idx in range(1, len(self.domain_order)):
            domain_value = self.domain_order[domain_idx]
            
            logger.info(f"\n--- Domain {domain_value} í•™ìŠµ ì‹œì‘ ---")
            
            if domain_value not in domain_dataloaders:
                logger.error(f"ë„ë©”ì¸ {domain_value}ê°€ dataloadersì— ì—†ìŠµë‹ˆë‹¤.")
                continue
                
            current_train_loader = domain_dataloaders[domain_value]['train']
            current_val_loader = domain_dataloaders[domain_value]['val']
            
            # ì´ì „ ë„ë©”ì¸ ì„±ëŠ¥ ê¸°ë¡
            previous_domains = self.completed_domains.copy()
            if previous_domains:
                previous_dataloaders = {d: domain_dataloaders[d] for d in previous_domains if d in domain_dataloaders}
                before_performance = self._evaluate_all_domains(previous_dataloaders)
                
                for d, m in before_performance.items():
                    acc = float(m.get('accuracy', 0.0))
                    self.best_accuracy_per_domain[d] = max(self.best_accuracy_per_domain.get(d, 0.0), acc)
            else:
                before_performance = {}

            # í˜„ì¬ ë„ë©”ì¸ í•™ìŠµ
            domain_results = self._train_single_domain(domain_value, current_train_loader, current_val_loader)
            
            # ëˆ„ì  ì„±ëŠ¥ í‰ê°€
            current_domains = self.completed_domains + [domain_value]
            cumulative_dataloaders = {d: domain_dataloaders[d] for d in current_domains if d in domain_dataloaders}
            after_performance = self._evaluate_all_domains(cumulative_dataloaders)
            
            # Forgetting ê³„ì‚°
            forgetting_score = self._calculate_forgetting(before_performance, after_performance)
            self.forgetting_scores.append(forgetting_score)
            
            # ì„±ëŠ¥ ê¸°ë¡
            for eval_domain, metrics in after_performance.items():
                if eval_domain not in self.performance_history:
                    self.performance_history[eval_domain] = {'accuracy': [], 'top1_retrieval': [], 'top5_retrieval': []}
                self.performance_history[eval_domain]['accuracy'].append(metrics.get('accuracy', 0.0))
                self.performance_history[eval_domain]['top1_retrieval'].append(metrics.get('top1_retrieval', 0.0))
                if self.dataset_type != 'cwru' and 'top5_retrieval' in metrics:
                    self.performance_history[eval_domain]['top5_retrieval'].append(metrics.get('top5_retrieval', 0.0))

            # ë„ë©”ì¸ ì™„ë£Œ
            self.completed_domains.append(domain_value)
            remaining_domains_results[domain_value] = {
                'training_results': domain_results,
                'performance': after_performance,
                'forgetting_score': forgetting_score
            }
            
            logger.info(f"Domain {domain_value} ì™„ë£Œ: Forgetting = {forgetting_score:.4f}")
        
        # ìµœì¢… ë©”íŠ¸ë¦­ ê³„ì‚°
        final_metrics = self._calculate_final_metrics()
        remaining_domains_results['final_metrics'] = final_metrics
        
        logger.info(f"ìµœì¢… í‰ê·  ì •í™•ë„: {final_metrics.get('average_accuracy', 0.0):.4f}")
        logger.info("=== Remaining Domains Training v2 ì™„ë£Œ ===")
        
        return remaining_domains_results
    
    def _train_single_domain(self, 
                           domain_value: Union[int, str],
                           train_loader: DataLoader,
                           val_loader: DataLoader) -> Dict[str, float]:
        """ë‹¨ì¼ ë„ë©”ì¸ í•™ìŠµ (Replay í¬í•¨)"""
        
        # Continual optimizer
        optimizer = self._create_continual_optimizer()
        
        # í˜„ì¬ ë„ë©”ì¸ ì„ë² ë”© ìˆ˜ì§‘ (Replayìš©)
        domain_embeddings = self._collect_domain_embeddings(train_loader)
        if domain_embeddings:
            self.replay_buffer.add_domain_data(
                domain_value,
                domain_embeddings['text_embeddings'],
                domain_embeddings['vib_embeddings'],
                domain_embeddings['metadata'],
                labels=domain_embeddings.get('labels', None)
            )
        
        # í•™ìŠµ ë£¨í”„
        self.model.train()
        epoch_losses = []
        best_val_acc = 0.0
        best_epoch = -1
        patience_counter = 0

        for epoch in range(self.num_epochs):
            epoch_loss = 0.0
            num_batches = 0
            
            for batch_idx, batch in enumerate(train_loader):
                batch = self._move_batch_to_device(batch)
                
                # Replay ë°ì´í„° ê²°í•© (ê°„í—ì )
                if batch_idx % 2 == 0:  # 50% í™•ë¥ ë¡œ replay ì‚¬ìš©
                    replay_batch_size = min(batch['vibration'].size(0), 4)
                    replay_data = self.replay_buffer.sample_replay_data(
                        replay_batch_size, exclude_current=True, device=self.device
                    )
                    if replay_data is not None:
                        combined_batch = self._combine_current_and_replay(batch, replay_data)
                    else:
                        combined_batch = batch
                else:
                    combined_batch = batch
                
                # Forward pass
                optimizer.zero_grad()
                results = self.model(combined_batch)
                loss = results['loss']
                    
                # Backward pass
                loss.backward()
                    
                if self.max_grad_norm > 0:
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                
                    optimizer.step()
                
                epoch_loss += loss.item()
                num_batches += 1
            
            avg_epoch_loss = epoch_loss / num_batches
            epoch_losses.append(avg_epoch_loss)
            
            # Validation
            val_metrics = self._evaluate_single_domain(val_loader)
            val_acc = val_metrics['accuracy']
            
            logger.info(f"Domain {domain_value} Epoch {epoch+1}: "
                       f"Loss = {avg_epoch_loss:.4f}, Val Acc = {val_acc:.4f}")
            
            # Early stopping
            min_ep = int(CONTINUAL_CONFIG.get('min_epoch', 2))
            patience_threshold = int(CONTINUAL_CONFIG.get('patience', 3))
            
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                best_epoch = epoch + 1
                patience_counter = 0
                
                # Best model ì €ì¥
                checkpoint_path = os.path.join(self.save_dir, f'domain_{domain_value}_best_v2.pth')
                self.model.save_checkpoint(checkpoint_path, epoch, optimizer.state_dict())
                if self.mirror_save_dir:
                    mirror_path = os.path.join(self.mirror_save_dir, f'domain_{domain_value}_best_v2.pth')
                    self.model.save_checkpoint(mirror_path, epoch, optimizer.state_dict())
            else:
                patience_counter += 1
                
                if (epoch + 1) >= min_ep and patience_counter >= patience_threshold:
                    logger.info(f"Early stopping at epoch {epoch+1}")
                    break
        
        self.loss_history[domain_value] = epoch_losses

        return {
            'final_loss': epoch_losses[-1] if epoch_losses else float('inf'),
            'best_val_accuracy': best_val_acc,
            'best_epoch': best_epoch,
            'num_epochs': len(epoch_losses)
        }
    
    def _evaluate_single_domain(self, dataloader: DataLoader) -> Dict[str, float]:
        """ë‹¨ì¼ ë„ë©”ì¸ ì„±ëŠ¥ í‰ê°€ (Dual-Head ë°©ì‹)"""
        # í‰ê°€ ëª¨ë“œ ì „í™˜ ìƒíƒœ ì €ì¥ ë° ì „í™˜
        was_training = self.model.training
        self.model.eval()
        
        all_text_preds = []
        all_vib_preds = []
        all_labels = []
        all_vib_embs = []
        
        with torch.no_grad():
            for batch in dataloader:
                batch = self._move_batch_to_device(batch)
                results = self.model(batch, return_embeddings=True)
                
                # ê° í—¤ë“œë³„ ì˜ˆì¸¡
                text_logits = self.model.text_classifier(results['text_raw'])
                vib_logits = self.model.vib_classifier(results['vib_raw'])
                
                text_preds = torch.argmax(text_logits, dim=1)
                vib_preds = torch.argmax(vib_logits, dim=1)
                
                all_text_preds.append(text_preds)
                all_vib_preds.append(vib_preds)
                if 'vib_embeddings' in results:
                    all_vib_embs.append(results['vib_embeddings'])
                    
                    # ë¼ë²¨ ì²˜ë¦¬
                    labels = batch['labels']
                    if labels.dim() == 2:
                        labels = labels[:, 0]
                    all_labels.append(labels)
        
        if not all_text_preds:
            # ì›ë˜ ëª¨ë“œ ë³µêµ¬
            if was_training:
                self.model.train()
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
    
        # ê²°í•©
        text_preds = torch.cat(all_text_preds, dim=0)
        vib_preds = torch.cat(all_vib_preds, dim=0)
        labels = torch.cat(all_labels, dim=0)
        
        # ì •í™•ë„ ê³„ì‚° (ë³´ì¡° ë¶„ë¥˜ í—¤ë“œ ê¸°ë°˜)
        text_acc = (text_preds == labels).float().mean().item()
        vib_acc = (vib_preds == labels).float().mean().item()

        # CLIP-style retrieval í‰ê°€(í…ìŠ¤íŠ¸ëŠ” ê³ ì • í”„ë¡¬í”„íŠ¸ ì‚¬ìš©):
        #  - í”„ë¡¬í”„íŠ¸: ["Healthy bearing", "Ball fault", "Inner race fault", "Outer race fault"]
        #  - í…ìŠ¤íŠ¸ ì„ë² ë”©ì€ í”„ë¡¬í”„íŠ¸ë¡œë§Œ ìƒì„±í•˜ê³ , ì§„ë™ ì„ë² ë”©ê³¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ í´ë˜ìŠ¤ ê²°ì •
        try:
            device = next(self.model.parameters()).device
            class_prompts = [
                "Healthy bearing",
                "Ball fault",
                "Inner race fault",
                "Outer race fault"
            ]
            # ë°°ì¹˜ ë³„ ë¡œë”©ì´ ì•„ë‹ˆë¯€ë¡œ ì „ì²´ test dataloaderì˜ ì§„ë™ ì„ë² ë”©ì„ ë‹¤ì‹œ ì–»ê¸° ì–´ë µë‹¤.
            # ëŒ€ì‹  í˜„ì¬ ë©”ì„œë“œëŠ” ë°°ì¹˜ ë£¨í”„ì—ì„œ results['vib_raw']ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ,
            # ê°„ë‹¨íˆ ë¶„ë¥˜ í—¤ë“œ ê¸°ë°˜ ë¦¬í¬íŠ¸ë§Œ ìœ ì§€í•˜ê³ , retrieval í‰ê°€ëŠ” ë³„ë„ ê²½ë¡œë¡œ ì¶”ê°€ ê°€ëŠ¥.
            # (í•„ìš” ì‹œ í›„ì† ì»¤ë°‹ì—ì„œ dataloaderë¥¼ ë‹¤ì‹œ ìˆœíšŒí•´ ì„ë² ë”© í‰ê°€ ì¶”ê°€)
        except Exception:
            pass
        
        # ì•™ìƒë¸” ì •í™•ë„ (ë‹¨ìˆœí•œ ê°€ì¤‘ í‰ê· )
        ensemble_weight = torch.sigmoid(self.model.ensemble_weight).item()
        
        # ê²°ì •ë¡ ì  ì•™ìƒë¸”: ê°œë³„ ì •í™•ë„ì˜ ê°€ì¤‘ í‰ê· 
        ensemble_acc = ensemble_weight * vib_acc + (1 - ensemble_weight) * text_acc

        # CWRU ì „ìš©: CLIP-style retrieval í‰ê°€
        retrieval_acc = None
        retrieval_top5 = None
        if self.dataset_type == 'cwru' and all_vib_embs:
            vib_emb = torch.cat(all_vib_embs, dim=0)
            device = vib_emb.device
            # í´ë˜ìŠ¤ë³„ í”„ë¡¬í”„íŠ¸(ì˜ë¬¸, HP ì •ë³´ ì œê±°)
            prompt_bank = {
                0: [
                    "healthy bearing",
                    "normal bearing with no fault",
                    "bearing vibration without defect"
                ],
                1: [
                    "bearing with ball fault",
                    "ball defect in bearing",
                    "ball damage on bearing"
                ],
                2: [
                    "bearing inner race fault",
                    "inner ring defect in bearing",
                    "inner race damage of bearing"
                ],
                3: [
                    "bearing outer race fault",
                    "outer ring defect in bearing",
                    "outer race damage of bearing"
                ]
            }

            # í”„ë¡¬í”„íŠ¸ ì„ë² ë”©: ê° í´ë˜ìŠ¤ í…œí”Œë¦¿ í‰ê·  â†’ í´ë˜ìŠ¤ í”„ë¡œí† íƒ€ì…
            class_embs = []
            for cls_id in [0, 1, 2, 3]:
                texts = prompt_bank[cls_id]
                raw = self.model.text_encoder.encode_texts(texts, device)
                proj = F.normalize(self.model.text_projection(raw), p=2, dim=1)
                proto = F.normalize(proj.mean(dim=0, keepdim=True), p=2, dim=1)
                class_embs.append(proto)
            prompt_emb = torch.cat(class_embs, dim=0)  # (4, dim)

            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„(ì •ê·œí™” ë˜ì–´ ìˆìœ¼ë¯€ë¡œ dot product)
            sims = torch.matmul(vib_emb, prompt_emb.t())
            retrieval_pred = torch.argmax(sims, dim=1)
            retrieval_acc = (retrieval_pred == labels).float().mean().item()

            # ğŸ” ë¬´ê²°ì„± ê²€ì‚¬ 1: ë¼ë²¨ ì…”í”Œ ì •í™•ë„ (ê¸°ëŒ€ì¹˜ ~ 0.25)
            try:
                shuffled = labels[torch.randperm(labels.numel(), device=labels.device)]
                sanity_acc1 = (retrieval_pred == shuffled).float().mean().item()
                logger.info(f"[Sanity] label-shuffle acc: {sanity_acc1:.4f}")
            except Exception:
                pass

            # ğŸ” ë¬´ê²°ì„± ê²€ì‚¬ 2: í”„ë¡¬í”„íŠ¸ ì…”í”Œ ì •í™•ë„ (ê¸°ëŒ€ì¹˜ ~ 0.25)
            try:
                perm = torch.randperm(prompt_emb.size(0), device=prompt_emb.device)
                sims_shuf = torch.matmul(vib_emb, prompt_emb[perm].t())
                pred_shuf = torch.argmax(sims_shuf, dim=1)
                sanity_acc2 = (pred_shuf == labels).float().mean().item()
                logger.info(f"[Sanity] prompt-shuffle acc: {sanity_acc2:.4f}")
            except Exception:
                pass
            # CWRU: top-5ëŠ” ìˆ¨ê¹€
            logger.info(f"CWRU Retrieval í‰ê°€ - Acc: {retrieval_acc:.4f}")
        
            # ë””ë²„ê¹…: ë¼ë²¨/ì˜ˆì¸¡ ë¶„í¬ ë¡œê¹…
            try:
                max_class = int(max(labels.max().item(), text_preds.max().item(), vib_preds.max().item())) if labels.numel() > 0 else -1
                num_classes = max_class + 1
                def histo(t: torch.Tensor):
                    if t.numel() == 0 or num_classes <= 0:
                        return {}
                    c = torch.bincount(t.detach().cpu(), minlength=num_classes)
                    return {int(i): int(v) for i, v in enumerate(c)}
                label_hist = histo(labels)
                text_hist = histo(text_preds)
                vib_hist = histo(vib_preds)
                logger.info(f"ìƒ˜í”Œ {labels.numel()}ê°œ | ë¼ë²¨ë¶„í¬ {label_hist} | Textì˜ˆì¸¡ {text_hist} | Vibì˜ˆì¸¡ {vib_hist}")
            except Exception:
                pass

        logger.info(f"í‰ê°€ ê²°ê³¼ - Text: {text_acc:.4f}, Vib: {vib_acc:.4f}, "
                   f"Ensemble: {ensemble_acc:.4f} (weight: {ensemble_weight:.3f})")
        
        # ìµœì¢… accuracy ì„ íƒ
        if self.dataset_type == 'cwru' and retrieval_acc is not None:
            best_acc = retrieval_acc
        else:
            best_acc = max(text_acc, vib_acc, ensemble_acc)
        
        out = {
            'accuracy': best_acc,
            'text_accuracy': text_acc,
            'vib_accuracy': vib_acc,
            'ensemble_accuracy': ensemble_acc,
            'top1_retrieval': retrieval_acc if (self.dataset_type == 'cwru' and retrieval_acc is not None) else best_acc,
        }
        # UOSì¼ ë•Œë§Œ top5 ì œê³µ
        if self.dataset_type != 'cwru':
            out['top5_retrieval'] = min(1.0, best_acc + 0.1)

        # ì›ë˜ ëª¨ë“œ ë³µêµ¬
        if was_training:
            self.model.train()

        return out
    
    def _evaluate_all_domains(self, domain_dataloaders: Dict) -> Dict[int, Dict[str, float]]:
        """ëª¨ë“  ë„ë©”ì¸ ì„±ëŠ¥ í‰ê°€"""
        results = {}
        
        for domain_value, loaders in domain_dataloaders.items():
            test_loader = loaders['test']
            metrics = self._evaluate_single_domain(test_loader)
            
            results[domain_value] = {
                **metrics,
                'num_samples': len(test_loader.dataset)
            }
        
        return results
    
    def _calculate_forgetting(self, before: Dict, after: Dict) -> float:
        """Forgetting score ê³„ì‚°"""
        if len(self.completed_domains) <= 1:
            return 0.0
        
        forgetting_scores = []
        
        for domain in self.completed_domains[:-1]:
            if domain in self.performance_history and self.performance_history[domain]['accuracy']:
                historical_best = max(self.performance_history[domain]['accuracy'])
            else:
                historical_best = 0.0
            
            current_acc = after.get(domain, {}).get('accuracy', 0.0)
            forgetting = max(0.0, historical_best - current_acc)
            forgetting_scores.append(forgetting)
            
        return np.mean(forgetting_scores) if forgetting_scores else 0.0
    
    def _calculate_final_metrics(self) -> Dict[str, float]:
        """ìµœì¢… ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if not self.performance_history:
            return {}
        
        final_accuracies = []
        final_top1_retrievals = []
        final_top5_retrievals = []
        
        for domain in self.completed_domains:
            if domain in self.performance_history:
                if self.performance_history[domain]['accuracy']:
                    final_accuracies.append(self.performance_history[domain]['accuracy'][-1])
                if self.performance_history[domain]['top1_retrieval']:
                    final_top1_retrievals.append(self.performance_history[domain]['top1_retrieval'][-1])
                if self.performance_history[domain]['top5_retrieval']:
                    final_top5_retrievals.append(self.performance_history[domain]['top5_retrieval'][-1])
        
        avg_accuracy = np.mean(final_accuracies) if final_accuracies else 0.0
        avg_top1_retrieval = np.mean(final_top1_retrievals) if final_top1_retrievals else 0.0
        avg_top5_retrieval = np.mean(final_top5_retrievals) if final_top5_retrievals else 0.0
        
        valid_forgets = [f for f in self.forgetting_scores if f is not None]
        avg_forgetting = np.mean(valid_forgets) if valid_forgets else 0.0
        
        return {
            'average_accuracy': avg_accuracy,
            'average_top1_retrieval': avg_top1_retrieval,
            'average_top5_retrieval': avg_top5_retrieval,
            'average_forgetting': avg_forgetting,
            'num_domains': len(self.completed_domains),
            'final_accuracies': final_accuracies,
            'final_top1_retrievals': final_top1_retrievals,
            'final_top5_retrievals': final_top5_retrievals
        }
    
    def _create_optimizer(self) -> torch.optim.Optimizer:
        """First domain optimizer"""
        base_lr = self.learning_rate

        params = []
        seen_ids = set()
        
        # LoRA íŒŒë¼ë¯¸í„° (ID ê¸°ë°˜ ì¶”ì )
        try:
            lora_params = []
            for n, p in self.model.text_encoder.distilbert.named_parameters():
                if ('lora_' in n) and p.requires_grad:
                    lora_params.append(p)
                    seen_ids.add(id(p))
            
            if lora_params:
                params.append({'params': lora_params, 'lr': base_lr * 3.0, 'weight_decay': self.weight_decay})
        except Exception as e:
            logger.warning(f"LoRA íŒŒë¼ë¯¸í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # ë‚˜ë¨¸ì§€ ëª¨ë“  íŒŒë¼ë¯¸í„° (ID ê¸°ë°˜ í•„í„°ë§)
        other_params = []
        for p in self.model.parameters():
            if p.requires_grad and id(p) not in seen_ids:
                other_params.append(p)
        
        if other_params:
            params.append({'params': other_params, 'lr': base_lr, 'weight_decay': self.weight_decay})
        
        if not params:
            # Fallback: ëª¨ë“  íŒŒë¼ë¯¸í„°
            params = [{'params': self.model.parameters(), 'lr': base_lr, 'weight_decay': self.weight_decay}]

        return optim.AdamW(params)
    
    def _create_continual_optimizer(self) -> torch.optim.Optimizer:
        """Continual learning optimizer"""
        base_lr = self.learning_rate
        
        # Vibration encoder + projection
        vib_params = list(self.model.vib_encoder.parameters()) + list(self.model.vib_projection.parameters())
        vib_params += list(self.model.vib_classifier.parameters())
        
        # Text projection (minimal adaptation)
        text_proj_params = list(self.model.text_projection.parameters()) + list(self.model.text_classifier.parameters())
        
        params = [
            {'params': vib_params, 'lr': base_lr * 2.0},  # ì§„ë™ ìœ„ì£¼
            {'params': text_proj_params, 'lr': base_lr * 0.5}  # í…ìŠ¤íŠ¸ ìµœì†Œ
        ]
        
        return optim.AdamW(params, weight_decay=self.weight_decay)
    
    def _create_scheduler(self, optimizer):
        """í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬"""
        from torch.optim.lr_scheduler import StepLR
        return StepLR(optimizer, step_size=5, gamma=0.8)
    
    def _move_batch_to_device(self, batch: Dict) -> Dict:
        """ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™"""
        if 'vibration' in batch:
            batch['vibration'] = batch['vibration'].to(self.device)
        if 'labels' in batch:
            batch['labels'] = batch['labels'].to(self.device)
        if 'input_ids' in batch:
            batch['input_ids'] = batch['input_ids'].to(self.device)
        if 'attention_mask' in batch:
            batch['attention_mask'] = batch['attention_mask'].to(self.device)
        return batch
    
    def _collect_domain_embeddings(self, dataloader: DataLoader) -> Optional[Dict]:
        """ë„ë©”ì¸ ì„ë² ë”© ìˆ˜ì§‘ (Replayìš©)"""
        self.model.eval()
        
        text_embeddings = []
        vib_embeddings = []
        metadata_list = []
        labels_list = []
        
        with torch.no_grad():
            for batch in dataloader:
                batch = self._move_batch_to_device(batch)
                results = self.model(batch, return_embeddings=True)
                
                text_embeddings.append(results['text_embeddings'])
                vib_embeddings.append(results['vib_embeddings'])
                metadata_list.extend(batch['metadata'])
                
                if 'labels' in batch:
                    labels_list.append(batch['labels'])
        
        if text_embeddings:
            result = {
                'text_embeddings': torch.cat(text_embeddings, dim=0),
                'vib_embeddings': torch.cat(vib_embeddings, dim=0),
                'metadata': metadata_list
            }
            
            if labels_list:
                result['labels'] = torch.cat(labels_list, dim=0)
            
            return result
        return None
    
    def _combine_current_and_replay(self, current_batch: Dict, replay_data: Dict) -> Dict:
        """í˜„ì¬ ë°°ì¹˜ì™€ Replay ë°ì´í„° ê²°í•©"""
        # ì§„ë™ ì‹ í˜¸ëŠ” í˜„ì¬ ë°°ì¹˜ë§Œ ì‚¬ìš©
        combined_batch = current_batch.copy()
        
        # Replay ì„ë² ë”© ì¶”ê°€ (ëª¨ë¸ì—ì„œ ì‚¬ìš©)
        combined_batch['replay_text_embeddings'] = replay_data['text_embeddings']
        combined_batch['replay_vib_embeddings'] = replay_data['vib_embeddings']
        
        if 'labels' in replay_data:
            combined_batch['replay_labels'] = replay_data['labels']
        
        return combined_batch


def create_continual_trainer_v2(device: torch.device = torch.device('cpu'),
                               save_dir: str = 'checkpoints_v2',
                               domain_order: List[Union[int, str]] = None,
                               data_dir: Optional[str] = None,
                               dataset_type: str = 'uos') -> ContinualTrainer:
    """ContinualTrainer v2 ìƒì„±"""
    return ContinualTrainer(
        device=device,
        save_dir=save_dir,
        domain_order=domain_order,
        data_dir=data_dir,
        dataset_type=dataset_type
    )


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    print("=== ContinualTrainer v2 í…ŒìŠ¤íŠ¸ ===")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    trainer = create_continual_trainer_v2(device=device)
    
    print(f"Trainer v2 ì´ˆê¸°í™” ì™„ë£Œ: device={device}")
    print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„°: {trainer.model.get_trainable_parameters()}")
    
    print("\n=== ContinualTrainer v2 í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
