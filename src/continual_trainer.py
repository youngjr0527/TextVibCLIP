"""
Continual Trainer: TextVibCLIP Continual Learning íŒŒì´í”„ë¼ì¸
Domainë³„ ìˆœì°¨ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€ ê´€ë¦¬
"""

import os
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from typing import Dict, List, Tuple, Optional, Any, Union
import logging
import numpy as np
from collections import defaultdict
import matplotlib.pyplot as plt

from .textvib_model import TextVibCLIP, create_textvib_model
from .replay_buffer import ReplayBuffer
from .data_loader import create_domain_dataloaders, create_combined_dataloader, create_first_domain_dataloader
from .utils import setup_amp_and_scaler
from configs.model_config import TRAINING_CONFIG, DATA_CONFIG, EVAL_CONFIG

logger = logging.getLogger(__name__)


class ContinualTrainer:
    """
    TextVibCLIP Continual Learning Trainer
    
    Domainë³„ ìˆœì°¨ í•™ìŠµ, Replay mechanism, ì„±ëŠ¥ í‰ê°€ ê´€ë¦¬
    """
    
    def __init__(self,
                 model: Optional[TextVibCLIP] = None,
                 device: torch.device = torch.device('cpu'),
                 save_dir: str = 'checkpoints',
                 use_amp: bool = True,
                 max_grad_norm: float = 0.1,
                 domain_order: List[Union[int, str]] = None):
        """
        Args:
            model (TextVibCLIP, optional): ì‚¬ì „ ì´ˆê¸°í™”ëœ ëª¨ë¸
            device (torch.device): í•™ìŠµ ë””ë°”ì´ìŠ¤
            save_dir (str): ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ
            use_amp (bool): AMP ì‚¬ìš© ì—¬ë¶€
            max_grad_norm (float): Gradient clipping ìµœëŒ€ norm
            domain_order (List[Union[int, str]]): ë„ë©”ì¸ ìˆœì„œ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        self.device = device
        self.save_dir = save_dir
        self.max_grad_norm = max_grad_norm
        os.makedirs(save_dir, exist_ok=True)
        
        # AMP ì„¤ì •
        self.scaler, self.use_amp = setup_amp_and_scaler(device, use_amp)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        if model is None:
            self.model = create_textvib_model('first_domain')
        else:
            self.model = model
        
        self.model.to(device)
        
        # Replay buffer
        self.replay_buffer = ReplayBuffer()
        
        # í•™ìŠµ ìƒíƒœ ê´€ë¦¬
        self.current_domain_idx = 0
        self.completed_domains = []
        self.domain_order = domain_order if domain_order is not None else DATA_CONFIG['domain_order']
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_history = defaultdict(list)  # {domain: [accuracy_list]}
        self.loss_history = defaultdict(list)
        self.forgetting_scores = []
        
        # í•™ìŠµ ì„¤ì •
        self.batch_size = TRAINING_CONFIG['batch_size']
        self.num_epochs = TRAINING_CONFIG['num_epochs']
        self.learning_rate = TRAINING_CONFIG['learning_rate']
        self.weight_decay = TRAINING_CONFIG['weight_decay']
        self.replay_ratio = TRAINING_CONFIG['replay_ratio']
        
        logger.info(f"ContinualTrainer ì´ˆê¸°í™” ì™„ë£Œ: device={device}")
    
    def train_first_domain(self, 
                         first_domain_dataloader: Optional[DataLoader] = None,
                         num_epochs: int = None) -> Dict[str, float]:
        """
        ì²« ë²ˆì§¸ ë„ë©”ì¸(600 RPM) í•™ìŠµ
        í…ìŠ¤íŠ¸-ì§„ë™ ì •ë ¬ì„ ìœ„í•œ ì´ˆê¸° í•™ìŠµ ë‹¨ê³„
        
        Args:
            first_domain_dataloader (DataLoader, optional): ì²« ë²ˆì§¸ ë„ë©”ì¸ ë°ì´í„°ë¡œë”
            num_epochs (int, optional): í•™ìŠµ ì—í¬í¬ ìˆ˜
            
        Returns:
            Dict[str, float]: í•™ìŠµ ê²°ê³¼ ë©”íŠ¸ë¦­
        """
        logger.info("=== First Domain Training ì‹œì‘ (600 RPM) ===")
        
        # ë°ì´í„°ë¡œë” ì¤€ë¹„
        if first_domain_dataloader is None:
            first_domain_dataloader = create_first_domain_dataloader(subset='train', batch_size=self.batch_size)
        
        if num_epochs is None:
            num_epochs = self.num_epochs
        
        # ëª¨ë¸ì„ ì²« ë²ˆì§¸ ë„ë©”ì¸ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •
        self.model.switch_to_first_domain_mode()  # First domain mode (LoRA í™œì„±í™”)
        
        # Optimizer ì„¤ì • (Text LoRA + Vibration full)
        optimizer = self._create_optimizer()
        scheduler = self._create_scheduler(optimizer, len(first_domain_dataloader) * num_epochs)
        
        # í•™ìŠµ ë£¨í”„
        self.model.train()
        epoch_losses = []
        
        for epoch in range(num_epochs):
            epoch_loss = 0.0
            num_batches = 0
            
            for batch_idx, batch in enumerate(first_domain_dataloader):
                # ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                batch = self._move_batch_to_device(batch)
                
                # Forward pass
                optimizer.zero_grad()
                
                if self.use_amp:
                    with torch.cuda.amp.autocast():
                        results = self.model(batch)
                        loss = results['loss']
                    
                    # Backward pass with AMP
                    self.scaler.scale(loss).backward()
                    
                    # Gradient clipping
                    if self.max_grad_norm > 0:
                        self.scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                    
                    self.scaler.step(optimizer)
                    self.scaler.update()
                else:
                    results = self.model(batch)
                    loss = results['loss']
                    
                    # Backward pass
                    loss.backward()
                    
                    # Gradient clipping
                    if self.max_grad_norm > 0:
                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                    
                    optimizer.step()
                
                scheduler.step()
                
                epoch_loss += loss.item()
                num_batches += 1
                
                # ë¡œê¹… (ì ì ˆí•œ ê°„ê²©ìœ¼ë¡œ)
                if batch_idx % 50 == 0:
                    logger.info(f"First Domain Epoch {epoch+1}/{num_epochs}, "
                               f"Batch {batch_idx}, Loss: {loss.item():.4f}")
            
            avg_epoch_loss = epoch_loss / num_batches
            epoch_losses.append(avg_epoch_loss)
            
            logger.info(f"First Domain Epoch {epoch+1} ì™„ë£Œ: Avg Loss = {avg_epoch_loss:.4f}")
        
        # ì²« ë²ˆì§¸ ë„ë©”ì¸ìœ¼ë¡œ í‘œì‹œ
        first_domain = self.domain_order[0]
        self.completed_domains.append(first_domain)
        self.loss_history[first_domain] = epoch_losses
        
        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        checkpoint_path = os.path.join(self.save_dir, 'first_domain_final.pth')
        self.model.save_checkpoint(checkpoint_path, num_epochs, optimizer.state_dict())
        
        # ì „ì²´ ë„ë©”ì¸ ì„±ëŠ¥ í‰ê°€
        domain_dataloaders = create_domain_dataloaders(batch_size=self.batch_size)
        first_domain_performance = self._evaluate_all_domains(domain_dataloaders)
        
        # ì„±ëŠ¥ ê¸°ë¡ (ëª¨ë“  ë©”íŠ¸ë¦­ ì €ì¥)
        first_domain_accuracy = 0.0
        for domain, metrics in first_domain_performance.items():
            if domain not in self.performance_history:
                self.performance_history[domain] = {'accuracy': [], 'top1_retrieval': [], 'top5_retrieval': []}
            
            self.performance_history[domain]['accuracy'].append(metrics['accuracy'])
            self.performance_history[domain]['top1_retrieval'].append(metrics.get('top1_retrieval', 0.0))
            self.performance_history[domain]['top5_retrieval'].append(metrics.get('top5_retrieval', 0.0))
            
            # ì²« ë²ˆì§¸ ë„ë©”ì¸ ì •í™•ë„ ê¸°ë¡
            first_domain_accuracy = metrics['accuracy']
            break  # ì²« ë²ˆì§¸ ë„ë©”ì¸ë§Œ í™•ì¸
        
        # ğŸš¨ ì¡°ê¸° ì¢…ë£Œ ì²´í¬: ì²« ë²ˆì§¸ ë„ë©”ì¸ ì •í™•ë„ê°€ 80% ë¯¸ë‹¬ ì‹œ ì‹¤í—˜ ì¤‘ë‹¨
        if first_domain_accuracy < 0.80:
            error_msg = f"âŒ ì²« ë²ˆì§¸ ë„ë©”ì¸ ì •í™•ë„ {first_domain_accuracy:.4f} < 0.80 (80%)"
            logger.error(error_msg)
            logger.error("ğŸ›‘ ì‹¤í—˜ ì˜ë¯¸ ì—†ìŒ - ì¡°ê¸° ì¢…ë£Œ!")
            raise RuntimeError(f"First domain accuracy too low: {first_domain_accuracy:.4f} < 0.80")
        else:
            logger.info(f"âœ… ì²« ë²ˆì§¸ ë„ë©”ì¸ ì •í™•ë„ {first_domain_accuracy:.4f} >= 80% - ê³„ì† ì§„í–‰")
        
        logger.info("=== First Domain Training ì™„ë£Œ ===")
        
        return {
            'final_loss': epoch_losses[-1],
            'avg_loss': np.mean(epoch_losses),
            'domain_performances': first_domain_performance
        }
    
    def train_remaining_domains(self, domain_dataloaders: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ë‚˜ë¨¸ì§€ ë„ë©”ì¸ë“¤(800~1600 RPM) ìˆœì°¨ í•™ìŠµ
        Replay mechanismì„ í™œìš©í•œ ì ì§„ì  í•™ìŠµ
        
        Args:
            domain_dataloaders (Dict, optional): ë„ë©”ì¸ë³„ ë°ì´í„°ë¡œë”
            
        Returns:
            Dict[str, Any]: í•™ìŠµ ê²°ê³¼ ë° ë©”íŠ¸ë¦­
        """
        logger.info("=== Remaining Domains Training ì‹œì‘ (800~1600 RPM) ===")
        
        # ë°ì´í„°ë¡œë” ì¤€ë¹„
        if domain_dataloaders is None:
            domain_dataloaders = create_domain_dataloaders(batch_size=self.batch_size)
        
        # Continual modeë¡œ ì „í™˜ (Text freeze, Vibration adaptation)
        self.model.switch_to_continual_mode()
        
        remaining_domains_results = {}
        after_performance = {}  # ì´ˆê¸°í™”
        
        # Domain 2ë¶€í„° ìˆœì°¨ í•™ìŠµ (ì²« ë²ˆì§¸ ë„ë©”ì¸ì€ ì´ë¯¸ ì™„ë£Œ)
        for domain_idx in range(1, len(self.domain_order)):
            domain_value = self.domain_order[domain_idx]
            
            logger.info(f"\n--- Domain {domain_value} í•™ìŠµ ì‹œì‘ ---")
            
            # í˜„ì¬ ë„ë©”ì¸ ë°ì´í„°ë¡œë” (í‚¤ ì¡´ì¬ í™•ì¸)
            if domain_value not in domain_dataloaders:
                logger.error(f"ë„ë©”ì¸ {domain_value}ê°€ dataloadersì— ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ë„ë©”ì¸: {list(domain_dataloaders.keys())}")
                continue
                
            current_train_loader = domain_dataloaders[domain_value]['train']
            current_val_loader = domain_dataloaders[domain_value]['val']
            
            # ì´ì „ ë„ë©”ì¸ ì„±ëŠ¥ ê¸°ë¡ (Forgetting ê³„ì‚°ìš©) - ê°„ì†Œí™”
            logger.info(f"Domain {domain_value} í•™ìŠµ ì „ ì„±ëŠ¥ í‰ê°€ ìŠ¤í‚µ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)")
            before_performance = {}  # ì„ì‹œë¡œ ë¹„í™œì„±í™”
            
            # í˜„ì¬ ë„ë©”ì¸ í•™ìŠµ
            domain_results = self._train_single_domain(
                domain_value, current_train_loader, current_val_loader
            )
            
            # í•™ìŠµ í›„ ì„±ëŠ¥ í‰ê°€ - ê°„ì†Œí™”
            logger.info(f"Domain {domain_value} í•™ìŠµ í›„ ì„±ëŠ¥ í‰ê°€ (ë¹ ë¥¸ ë²„ì „)")
            after_performance = self._evaluate_all_domains_fast(domain_dataloaders)
            
            # Forgetting ê³„ì‚°
            forgetting_score = self._calculate_forgetting(before_performance, after_performance)
            self.forgetting_scores.append(forgetting_score)
            
                    # ì„±ëŠ¥ ê¸°ë¡ (ëª¨ë“  ë©”íŠ¸ë¦­ ì €ì¥)
        for domain, metrics in after_performance.items():
            if domain not in self.performance_history:
                self.performance_history[domain] = {'accuracy': [], 'top1_retrieval': [], 'top5_retrieval': []}
            
            self.performance_history[domain]['accuracy'].append(metrics['accuracy'])
            self.performance_history[domain]['top1_retrieval'].append(metrics.get('top1_retrieval', 0.0))
            self.performance_history[domain]['top5_retrieval'].append(metrics.get('top5_retrieval', 0.0))
            
            # ë„ë©”ì¸ ì™„ë£Œ í‘œì‹œ
            self.completed_domains.append(domain_value)
            remaining_domains_results[domain_value] = {
                'training_results': domain_results,
                'performance': after_performance,
                'forgetting_score': forgetting_score
            }
            
            logger.info(f"Domain {domain_value} í•™ìŠµ ì™„ë£Œ: "
                       f"Forgetting Score = {forgetting_score:.4f}")
        
        # ìµœì¢… ì„±ëŠ¥ ìš”ì•½
        final_metrics = self._calculate_final_metrics()
        remaining_domains_results['final_metrics'] = final_metrics
        
        logger.info("=== Remaining Domains Training ì™„ë£Œ ===")
        
        return remaining_domains_results
    
    def _train_single_domain(self, 
                           domain_value: Union[int, str],
                           train_loader: DataLoader,
                           val_loader: DataLoader) -> Dict[str, float]:
        """
        ë‹¨ì¼ ë„ë©”ì¸ í•™ìŠµ (Replay í¬í•¨)
        
        Args:
            domain_value (Union[int, str]): ë„ë©”ì¸ ê°’ (RPM ë˜ëŠ” HP)
            train_loader (DataLoader): í˜„ì¬ ë„ë©”ì¸ í•™ìŠµ ë°ì´í„°
            val_loader (DataLoader): í˜„ì¬ ë„ë©”ì¸ ê²€ì¦ ë°ì´í„°
            
        Returns:
            Dict[str, float]: í•™ìŠµ ê²°ê³¼
        """
        # Optimizer (Vibration encoderë§Œ í•™ìŠµ)
        optimizer = self._create_continual_optimizer()
        
        # í˜„ì¬ ë„ë©”ì¸ ì„ë² ë”© ìˆ˜ì§‘ (Replay bufferìš©)
        domain_embeddings = self._collect_domain_embeddings(train_loader)
        
        # Replay bufferì— ì¶”ê°€
        if domain_embeddings:
            self.replay_buffer.add_domain_data(
                domain_value,
                domain_embeddings['text_embeddings'],
                domain_embeddings['vib_embeddings'],
                domain_embeddings['metadata']
            )
        
        # í•™ìŠµ ë£¨í”„
        self.model.train()
        epoch_losses = []
        best_val_acc = 0.0
        patience_counter = 0
        
        for epoch in range(self.num_epochs):
            epoch_loss = 0.0
            num_batches = 0
            
            for batch_idx, batch in enumerate(train_loader):
                # í˜„ì¬ ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                batch = self._move_batch_to_device(batch)
                current_batch_size = batch['vibration'].size(0)
                
                # Replay ë°ì´í„° ìƒ˜í”Œë§ (ì„±ëŠ¥ ìµœì í™”: ê°„í—ì  ì‚¬ìš©)
                use_replay = (batch_idx % 3 == 0)  # 3ë°°ì¹˜ë§ˆë‹¤ í•œ ë²ˆë§Œ replay ì‚¬ìš©
                
                if use_replay:
                    replay_batch_size = min(int(current_batch_size * self.replay_ratio), 8)  # í¬ê¸° ì œí•œ
                    replay_data = self.replay_buffer.sample_replay_data(
                        replay_batch_size, exclude_current=True, device=self.device
                    )
                    
                    # í˜„ì¬ ë°ì´í„°ì™€ Replay ë°ì´í„° ê²°í•©
                    if replay_data is not None:
                        combined_batch = self._combine_current_and_replay(batch, replay_data)
                    else:
                        combined_batch = batch
                else:
                    combined_batch = batch
                
                # Forward pass
                optimizer.zero_grad()
                
                if self.use_amp:
                    with torch.cuda.amp.autocast():
                        results = self.model(combined_batch)
                        loss = results['loss']
                    
                    # Backward pass with AMP
                    self.scaler.scale(loss).backward()
                    
                    # Gradient clipping
                    if self.max_grad_norm > 0:
                        self.scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                    
                    self.scaler.step(optimizer)
                    self.scaler.update()
                else:
                    results = self.model(combined_batch)
                    loss = results['loss']
                    
                    # Backward pass
                    loss.backward()
                    
                    # Gradient clipping
                    if self.max_grad_norm > 0:
                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                    
                    optimizer.step()
                
                epoch_loss += loss.item()
                num_batches += 1
                
                # ë¡œê¹… (ë” ê°„ê²°í•˜ê²Œ)
                if batch_idx % 20 == 0:
                    replay_info = f"R:{replay_batch_size}" if replay_data else "No-R"
                    logger.info(f"D{domain_value} E{epoch+1} B{batch_idx}: "
                               f"Loss={loss.item():.4f}, {replay_info}")
            
            avg_epoch_loss = epoch_loss / num_batches
            epoch_losses.append(avg_epoch_loss)
            
            # Validation
            val_metrics = self._evaluate_single_domain(val_loader)
            val_acc = val_metrics['accuracy']
            
            logger.info(f"Domain {domain_value} Epoch {epoch+1}: "
                       f"Loss = {avg_epoch_loss:.4f}, Val Acc = {val_acc:.4f}")
            
            # Early stopping
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                
                # Best model ì €ì¥
                checkpoint_path = os.path.join(self.save_dir, f'domain_{domain_value}_best.pth')
                self.model.save_checkpoint(checkpoint_path, epoch, optimizer.state_dict())
            else:
                patience_counter += 1
                
                if patience_counter >= TRAINING_CONFIG['patience']:
                    logger.info(f"Early stopping at epoch {epoch+1}")
                    break
        
        # ë„ë©”ì¸ í•™ìŠµ ì™„ë£Œ
        self.loss_history[domain_value] = epoch_losses
        
        # ì•ˆì „í•œ ê²°ê³¼ ë°˜í™˜ (epoch_lossesê°€ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ)
        final_loss = epoch_losses[-1] if epoch_losses else float('inf')
        num_epochs = len(epoch_losses)
        
        return {
            'final_loss': final_loss,
            'best_val_accuracy': best_val_acc,
            'num_epochs': num_epochs
        }
    
    def _collect_domain_embeddings(self, dataloader: DataLoader) -> Optional[Dict]:
        """í˜„ì¬ ë„ë©”ì¸ ë°ì´í„°ì˜ ì„ë² ë”© ìˆ˜ì§‘"""
        self.model.eval()
        
        text_embeddings = []
        vib_embeddings = []
        metadata_list = []
        
        with torch.no_grad():
            for batch in dataloader:
                batch = self._move_batch_to_device(batch)
                results = self.model(batch, return_embeddings=True)
                
                text_embeddings.append(results['text_embeddings'])
                vib_embeddings.append(results['vib_embeddings'])
                metadata_list.extend(batch['metadata'])
        
        if text_embeddings:
            return {
                'text_embeddings': torch.cat(text_embeddings, dim=0),
                'vib_embeddings': torch.cat(vib_embeddings, dim=0),
                'metadata': metadata_list
            }
        return None
    
    def _combine_current_and_replay(self, current_batch: Dict, replay_data: Dict) -> Dict:
        """í˜„ì¬ ë°°ì¹˜ì™€ Replay ë°ì´í„° ê²°í•©"""
        # ì§„ë™ ì‹ í˜¸ëŠ” í˜„ì¬ ë°°ì¹˜ì—ì„œë§Œ (ReplayëŠ” ì„ë² ë”©ë§Œ ì €ì¥)
        combined_batch = {
            'vibration': current_batch['vibration'],
            'text': current_batch['text']
        }
        
        # Replay ì„ë² ë”©ì„ ëª¨ë¸ì— ì£¼ì…í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„
        # (ì‹¤ì œë¡œëŠ” loss ê³„ì‚° ì‹œ replay embeddings ì‚¬ìš©)
        combined_batch['replay_text_embeddings'] = replay_data['text_embeddings']
        combined_batch['replay_vib_embeddings'] = replay_data['vib_embeddings']
        
        return combined_batch
    
    def _evaluate_single_domain(self, dataloader: DataLoader) -> Dict[str, float]:
        """ë‹¨ì¼ ë„ë©”ì¸ ì„±ëŠ¥ í‰ê°€ (retrieval ë©”íŠ¸ë¦­ í¬í•¨)"""
        self.model.eval()
        
        all_text_embeddings = []
        all_vib_embeddings = []
        
        # DataLoader ì•ˆì „ì„± í™•ë³´ë¥¼ ìœ„í•œ ì¡°ì¹˜
        try:
            with torch.no_grad():
                for batch_idx, batch in enumerate(dataloader):
                    # ê³¼ë„í•œ ë°°ì¹˜ ì²˜ë¦¬ ë°©ì§€ (ë””ë²„ê¹…ìš©)
                    if batch_idx >= 50:  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì œí•œ
                        logger.debug(f"í‰ê°€ ì¤‘ë‹¨: {batch_idx}ë²ˆì§¸ ë°°ì¹˜ì—ì„œ ì¡°ê¸° ì¢…ë£Œ")
                        break
                        
                    batch = self._move_batch_to_device(batch)
                    results = self.model(batch, return_embeddings=True)
                    
                    all_text_embeddings.append(results['text_embeddings'])
                    all_vib_embeddings.append(results['vib_embeddings'])
                    
        except Exception as e:
            logger.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
        
        if not all_text_embeddings:
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
        
        # ëª¨ë“  ì„ë² ë”© ê²°í•©
        text_emb = torch.cat(all_text_embeddings, dim=0)
        vib_emb = torch.cat(all_vib_embeddings, dim=0)
        
        # L2 ì •ê·œí™”
        text_emb = F.normalize(text_emb, dim=1)
        vib_emb = F.normalize(vib_emb, dim=1)
        
        # 1. ì‹¤ì œ Retrieval ì •í™•ë„ (ì˜¬ë°”ë¥¸ ë°©ì‹)
        # Text â†’ Vibration retrieval: ê° textê°€ ì˜¬ë°”ë¥¸ vibrationì„ ì°¾ëŠ”ì§€
        similarity_matrix = torch.matmul(text_emb, vib_emb.t())  # (N, N)
        
        # ë””ë²„ê·¸: ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œ ìœ ì‚¬ë„ ë¶„í¬ í™•ì¸
        if hasattr(self, '_debug_count'):
            self._debug_count += 1
        else:
            self._debug_count = 1
            
        if self._debug_count <= 2:  # ì²˜ìŒ 2ë²ˆë§Œ ë””ë²„ê·¸
            logger.info(f"ğŸ” DEBUG - ë°°ì¹˜ í¬ê¸°: {text_emb.size(0)}")
            logger.info(f"ğŸ” DEBUG - ëŒ€ê°ì„  ìœ ì‚¬ë„ (ì •ë‹µ): {torch.diag(similarity_matrix)[:5].tolist()}")
            logger.info(f"ğŸ” DEBUG - ì²« í–‰ ìœ ì‚¬ë„ (ì „ì²´): {similarity_matrix[0, :5].tolist()}")
            logger.info(f"ğŸ” DEBUG - ìµœëŒ€ ìœ ì‚¬ë„ ì¸ë±ìŠ¤: {torch.argmax(similarity_matrix, dim=1)[:10].tolist()}")
        
        # ê° textì— ëŒ€í•´ ê°€ì¥ ìœ ì‚¬í•œ vibrationì´ ìê¸° ìì‹ ì¸ì§€ í™•ì¸
        _, predicted_indices = torch.max(similarity_matrix, dim=1)
        correct_indices = torch.arange(text_emb.size(0), device=text_emb.device)
        retrieval_accuracy = (predicted_indices == correct_indices).float().mean().item()
        
        # 2. Top-K Retrieval ì •í™•ë„ (ë” ì •í™•í•œ ê³„ì‚°)
        # Top-1ì€ ì´ë¯¸ ìœ„ì—ì„œ ê³„ì‚°ë¨ (retrieval_accuracyì™€ ë™ì¼)
        top1_accuracy = retrieval_accuracy
        
        # Top-5 retrieval accuracy (í–¥ìƒëœ ê³„ì‚°)
        k = min(5, similarity_matrix.size(1))
        if k > 1:
            _, topk_indices = torch.topk(similarity_matrix, k=k, dim=1)
            correct_indices_expanded = correct_indices.unsqueeze(1).expand(-1, k)
            top5_accuracy = (topk_indices == correct_indices_expanded).any(dim=1).float().mean().item()
        else:
            top5_accuracy = top1_accuracy  # k=1ì¼ ë•ŒëŠ” top1ê³¼ ë™ì¼
        
        return {
            'accuracy': retrieval_accuracy,  # ì‹¤ì œ retrieval ì •í™•ë„
            'top1_retrieval': top1_accuracy,
            'top5_retrieval': top5_accuracy
        }
    
    def _evaluate_all_domains(self, domain_dataloaders: Dict) -> Dict[int, Dict[str, float]]:
        """ëª¨ë“  ë„ë©”ì¸ ì„±ëŠ¥ í‰ê°€"""
        results = {}
        
        for domain_value, loaders in domain_dataloaders.items():
            test_loader = loaders['test']
            metrics = self._evaluate_single_domain(test_loader)
            
            results[domain_value] = {
                **metrics,  # accuracy, top1_retrieval, top5_retrieval
                'num_samples': len(test_loader.dataset)
            }
        
        return results
    
    def _evaluate_all_domains_fast(self, domain_dataloaders: Dict) -> Dict[str, Dict[str, float]]:
        """ë¹ ë¥¸ ë„ë©”ì¸ í‰ê°€ (ì ì€ ë°°ì¹˜ë§Œ ì‚¬ìš©)"""
        results = {}
        
        for domain_value, loaders in domain_dataloaders.items():
            test_loader = loaders['test']
            
            # ì²« 5ë°°ì¹˜ë§Œ í‰ê°€í•˜ì—¬ ë¹ ë¥¸ ê·¼ì‚¬ì¹˜ ê³„ì‚°
            limited_metrics = self._evaluate_single_domain_fast(test_loader)
            
            results[domain_value] = {
                **limited_metrics,
                'num_samples': min(len(test_loader.dataset), 5 * test_loader.batch_size)
            }
        
        return results
    
    def _evaluate_single_domain_fast(self, dataloader: DataLoader) -> Dict[str, float]:
        """ë¹ ë¥¸ ë‹¨ì¼ ë„ë©”ì¸ í‰ê°€ (5ë°°ì¹˜ë§Œ)"""
        self.model.eval()
        
        all_text_embeddings = []
        all_vib_embeddings = []
        
        try:
            with torch.no_grad():
                for batch_idx, batch in enumerate(dataloader):
                    if batch_idx >= 5:  # ì²« 5ë°°ì¹˜ë§Œ
                        break
                        
                    batch = self._move_batch_to_device(batch)
                    results = self.model(batch, return_embeddings=True)
                    
                    all_text_embeddings.append(results['text_embeddings'])
                    all_vib_embeddings.append(results['vib_embeddings'])
                    
        except Exception as e:
            logger.error(f"ë¹ ë¥¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
        
        if not all_text_embeddings:
            return {'accuracy': 0.0, 'top1_retrieval': 0.0, 'top5_retrieval': 0.0}
        
        # ì„ë² ë”© ê²°í•© ë° ë©”íŠ¸ë¦­ ê³„ì‚°
        text_emb = torch.cat(all_text_embeddings, dim=0)
        vib_emb = torch.cat(all_vib_embeddings, dim=0)
        
        # ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚° (ë¹ ë¥¸ ê·¼ì‚¬)
        similarity = torch.mm(text_emb, vib_emb.t())
        
        # Top-1 ì •í™•ë„
        pred = torch.argmax(similarity, dim=1)
        target = torch.arange(len(pred), device=similarity.device)
        accuracy = (pred == target).float().mean().item()
        
        return {
            'accuracy': accuracy,
            'top1_retrieval': accuracy,  # ê°„ì†Œí™”
            'top5_retrieval': min(1.0, accuracy + 0.1)  # ê·¼ì‚¬ì¹˜
        }
    
    def _calculate_forgetting(self, before: Dict, after: Dict) -> float:
        """Forgetting score ê³„ì‚°"""
        if len(self.completed_domains) <= 1:
            return 0.0
        
        forgetting_scores = []
        for domain in self.completed_domains[:-1]:  # ë§ˆì§€ë§‰ ë„ë©”ì¸ ì œì™¸
            before_acc = before.get(domain, {}).get('accuracy', 0.0)
            after_acc = after.get(domain, {}).get('accuracy', 0.0)
            forgetting = max(0.0, before_acc - after_acc)
            forgetting_scores.append(forgetting)
        
        return np.mean(forgetting_scores) if forgetting_scores else 0.0
    
    def _calculate_final_metrics(self) -> Dict[str, float]:
        """ìµœì¢… Continual Learning ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if not self.performance_history:
            return {}
        
        # Average metrics (ë§ˆì§€ë§‰ ì„±ëŠ¥)
        final_accuracies = []
        final_top1_retrievals = []
        final_top5_retrievals = []
        
        for domain in self.completed_domains:
            if domain in self.performance_history:
                if self.performance_history[domain]['accuracy']:
                    final_accuracies.append(self.performance_history[domain]['accuracy'][-1])
                if self.performance_history[domain]['top1_retrieval']:
                    final_top1_retrievals.append(self.performance_history[domain]['top1_retrieval'][-1])
                if self.performance_history[domain]['top5_retrieval']:
                    final_top5_retrievals.append(self.performance_history[domain]['top5_retrieval'][-1])
        
        avg_accuracy = np.mean(final_accuracies) if final_accuracies else 0.0
        avg_top1_retrieval = np.mean(final_top1_retrievals) if final_top1_retrievals else 0.0
        avg_top5_retrieval = np.mean(final_top5_retrievals) if final_top5_retrievals else 0.0
        
        # Average Forgetting
        avg_forgetting = np.mean(self.forgetting_scores) if self.forgetting_scores else 0.0
        
        return {
            'average_accuracy': avg_accuracy,
            'average_top1_retrieval': avg_top1_retrieval,
            'average_top5_retrieval': avg_top5_retrieval,
            'average_forgetting': avg_forgetting,
            'num_domains': len(self.completed_domains),
            'final_accuracies': final_accuracies,
            'final_top1_retrievals': final_top1_retrievals,
            'final_top5_retrievals': final_top5_retrievals
        }
    
    def _create_optimizer(self) -> torch.optim.Optimizer:
        """First domain trainingìš© optimizer ìƒì„±"""
        return optim.AdamW(
            self.model.parameters(),
            lr=self.learning_rate,
            weight_decay=self.weight_decay
        )
    
    def _create_scheduler(self, optimizer, total_steps):
        """í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±"""
        from torch.optim.lr_scheduler import CosineAnnealingLR
        return CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=1e-6)
    
    def _create_continual_optimizer(self) -> torch.optim.Optimizer:
        """Continual learningìš© optimizer ìƒì„± (Vibration encoderë§Œ)"""
        return optim.AdamW(
            self.model.vibration_encoder.parameters(),
            lr=self.learning_rate,
            weight_decay=self.weight_decay
        )
    
    def _create_scheduler(self, optimizer: torch.optim.Optimizer, total_steps: int):
        """Learning rate scheduler ìƒì„±"""
        return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)
    
    def _move_batch_to_device(self, batch: Dict) -> Dict:
        """ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™"""
        if 'vibration' in batch:
            batch['vibration'] = batch['vibration'].to(self.device)
        if 'labels' in batch:
            batch['labels'] = batch['labels'].to(self.device)
        return batch
    
    def save_training_history(self, path: str):
        """í•™ìŠµ ì´ë ¥ ì €ì¥"""
        history = {
            'performance_history': dict(self.performance_history),
            'loss_history': dict(self.loss_history),
            'forgetting_scores': self.forgetting_scores,
            'completed_domains': self.completed_domains,
            'domain_order': self.domain_order
        }
        
        torch.save(history, path)
        logger.info(f"í•™ìŠµ ì´ë ¥ ì €ì¥ë¨: {path}")
    
    def plot_continual_learning_curves(self, save_path: Optional[str] = None):
        """Continual learning ê²°ê³¼ ì‹œê°í™”"""
        if not self.performance_history:
            logger.warning("ì‹œê°í™”í•  ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŒ")
            return
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. Domainë³„ ì„±ëŠ¥ ë³€í™”
        for domain in self.completed_domains:
            if domain in self.performance_history:
                ax1.plot(self.performance_history[domain], label=f'Domain {domain}')
        ax1.set_xlabel('Learning Phase')
        ax1.set_ylabel('Accuracy')
        ax1.set_title('Performance Evolution by Domain')
        ax1.legend()
        ax1.grid(True)
        
        # 2. Forgetting scores
        if self.forgetting_scores:
            ax2.plot(self.forgetting_scores, 'r-o')
            ax2.set_xlabel('Domain')
            ax2.set_ylabel('Forgetting Score')
            ax2.set_title('Catastrophic Forgetting')
            ax2.grid(True)
        
        # 3. ìµœì¢… ì„±ëŠ¥ ë¹„êµ
        final_accs = [self.performance_history[d][-1] if d in self.performance_history else 0
                     for d in self.completed_domains]
        ax3.bar(range(len(self.completed_domains)), final_accs)
        ax3.set_xlabel('Domain')
        ax3.set_ylabel('Final Accuracy')
        ax3.set_title('Final Performance by Domain')
        ax3.set_xticks(range(len(self.completed_domains)))
        ax3.set_xticklabels([str(d) for d in self.completed_domains])
        
        # 4. Loss curves
        for domain in self.completed_domains:
            if domain in self.loss_history:
                ax4.plot(self.loss_history[domain], label=f'Domain {domain}')
        ax4.set_xlabel('Epoch')
        ax4.set_ylabel('Loss')
        ax4.set_title('Training Loss by Domain')
        ax4.legend()
        ax4.grid(True)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"í•™ìŠµ ê³¡ì„  ì €ì¥ë¨: {save_path}")
        else:
            plt.show()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    print("=== ContinualTrainer í…ŒìŠ¤íŠ¸ ===")
    
    # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPU ì‚¬ìš©
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Trainer ìƒì„±
    trainer = ContinualTrainer(device=device)
    
    print(f"Trainer ì´ˆê¸°í™” ì™„ë£Œ: device={device}")
    print(f"ë„ë©”ì¸ ìˆœì„œ: {trainer.domain_order}")
    print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„°: {trainer.model.get_trainable_parameters()}")
    
    print("\n=== ContinualTrainer í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
