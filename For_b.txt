# B 씨를 위한 논문 작성 가이드: 3. Methodology & 4. Experimental Results

안녕하세요 B 씨, 코드 워크스페이스에 접근할 수 없으시니 아래 정보를 바탕으로 3.Methodology와 4.Experimental Results 챕터를 작성하시면 됩니다.

---

## 3. Methodology

### 3.1 전체 파이프라인 개요

TextVibCLIP 모델은 진동 신호와 텍스트 설명을 입력으로 받아 멀티모달 임베딩 공간에서 정렬 학습을 수행합니다.

**입력 → 인코더 → 공통 임베딩 → loss 계산 → inference 흐름:**

1. **입력 처리**: 진동 신호(2048 샘플)와 텍스트 설명을 각각의 인코더에 입력
2. **특징 추출**: 진동 인코더(CNN)와 텍스트 인코더(DistilBERT + LoRA)로 특징 추출
3. **공통 임베딩**: 각 모달리티의 특징을 공통 차원(256)으로 projection
4. **학습**: Triplet ranking loss와 auxiliary classification loss로 정렬 학습
5. **추론**: 새로운 진동 신호에 대해 가장 유사한 텍스트 설명을 검색

## 딥러닝 모델 환경 정보

아래 표는 본 연구에서 사용된 딥러닝 모델 학습 환경에 대한 상세 정보를 정리한 것입니다.

| 항목 | 사양 | 비고 |
|------|------|------|
| **운영체제** | Ubuntu 22.04 LTS (Linux 5.4.0-216-generic) | 64-bit 운영체제 |
| **CPU** | Intel(R) Xeon(R) Silver 4210R CPU @ 2.40GHz × 40 cores | 2 sockets, 20 cores per socket |
| **메모리** | 251 GB RAM | DDR4, NUMA 아키텍처 |
| **GPU** | NVIDIA Quadro RTX 5000 × 6개 | 각 16GB GDDR6 메모리 |
| **CUDA 버전** | 11.7 | NVIDIA 드라이버 535.230.02 |
| **Python 버전** | 3.8.10 | Anaconda 환경 (TVCLIP) |
| **딥러닝 프레임워크** | PyTorch 2.0.1 | CUDA 11.7 지원 |
| **자연어 처리** | Transformers 4.46.3 | Hugging Face 라이브러리 |
| **기계학습** | scikit-learn 1.3.2 | 데이터 전처리 및 평가용 |
| **수치 연산** | NumPy 1.24.4 | 배열 연산 및 데이터 처리 |

### 주요 라이브러리 버전 정보

- **PyTorch**: 2.0.1 (CUDA 11.7 지원 버전)
- **CUDA Toolkit**: 11.7
- **cuDNN**: PyTorch 2.0.1에 포함
- **NVIDIA 드라이버**: 535.230.02

### 하드웨어 구성 특성

- **멀티 GPU 설정**: 6개의 RTX 5000 GPU를 병렬로 사용
- **메모리 아키텍처**: NUMA (Non-Uniform Memory Access) 구조로 최적화된 메모리 접근
- **스토리지**: 고속 SSD 기반 데이터 저장소 사용

**1D-CNN 기반 아키텍처:**
- 입력: 2048 길이의 진동 신호 (단일 채널)
- 구조: 4-layer CNN (Conv1d) + Batch Normalization + ReLU + Dropout
- 채널: [64, 128, 256, 512] (점진적 증가)
- 커널 크기: [16, 32, 64, 32]
- 스트라이드: 2 (차원 축소)
- 출력: 256차원 임베딩 벡터
- 활성화 함수: ReLU
- 정규화: Batch Normalization
- 풀링: Adaptive Average Pooling (전역 평균)

### 3.3 텍스트 인코더 구조

**DistilBERT 기반 (LoRA 파인튜닝):**
- 백본: distilbert-base-uncased (pretrained)
- 입력: 베어링 상태 텍스트 설명 (최대 128 토큰)
- LoRA 설정:
  - 랭크(r): 32
  - 스케일링 파라미터(α): 64
  - 대상 모듈: q_lin, v_lin (어텐션 레이어)
  - 드롭아웃: 0.1
- 동결 전략: 첫 번째 도메인 학습 시 전체 파인튜닝, 이후 도메인에서는 백본 동결하고 LoRA만 업데이트

### 3.4 Contrastive Learning 설정

**Triplet Ranking Loss 기반:**
- 손실 함수: Triplet Loss (margin=0.4)
- 목표: 같은 클래스의 text-vibration 쌍은 가깝게, 다른 클래스는 멀게
- 학습 방식: 배치 내에서 anchor-positive-negative triplet 구성
- 마진 설정: 0.4 (같은 클래스 유사도와 다른 클래스 유사도 간 최소 차이)
- 보조 손실: Auxiliary classification (7개 클래스 분류 헤드, 가중치 1.0)

### 3.5 Asymmetric Adaptation 전략

**도메인별 학습 전략:**
- **첫 번째 도메인 (Foundation Learning)**:
  - 모든 파라미터 업데이트 (텍스트 인코더 완전 파인튜닝)
  - 에포크: 20회
  - 학습률: 1.5e-4 (파라미터 그룹별 멀티플라이어 적용)
  - Two-stage 학습: 초기 8에포크는 projection 레이어만 학습

- **이후 도메인들 (Adaptation Learning)**:
  - 텍스트 인코더 백본 동결 (LoRA만 업데이트)
  - 진동 인코더 위주로 적응
  - 에포크: 8회
  - 학습률: 3e-5 (안정적 적응)
  - 파라미터별 학습률 멀티플라이어:
    - 텍스트 인코더(LoRA): 1.0x
    - 프로젝션 레이어: 2.0x
    - 진동 인코더: 3.0x

### 3.6 Replay 메커니즘 구현

**대표적 샘플 저장 및 활용:**
- 저장 용량: 도메인당 800개 임베딩 저장
- 선택 기준: 'representative' 전략 (클래스별 균형 + 어려운 샘플 우선)
- 학습 시 사용: 매 배치마다 현재 도메인과 과거 도메인 데이터 1:1 비율로 혼합
- 부스팅 도메인: 어려운 도메인(1000, 1200, 1400 RPM)에 60% 추가 할당

---

## 4. Experimental Results

### 4.1 사용한 데이터셋

**UOS Bearing Dataset:**
- 출처: University of Ottawa 베어링 실험 데이터
- 크기: 각 RPM별로 약 1,000개 샘플씩 (총 6개 도메인 × 약 1,000개)
- 도메인 순서: 600 → 800 → 1000 → 1200 → 1400 → 1600 RPM (점진적 속도 증가)
- 시프트 타입: 회전 속도 변화 (Varying Speed)
- 분할 방식: 각 도메인별 train/validation/test = 60%/20%/20%
- 클래스: 7개 (정상, 볼 결함, 내륜 결함, 외륜 결함, 기계적 느슨함, 로터 불균형, 샤프트 misalignment)

### 4.2 학습 설정

**하이퍼파라미터:**
- 배치 크기: 16 (안정적 그래디언트 계산)
- 최적화기: AdamW (weight decay 3e-5)
- 학습률 스케줄러:
  - 첫 번째 도메인: Cosine annealing (eta_min=1e-6)
  - 이후 도메인: Step LR (step_size=3, gamma=0.8)
- 그래디언트 클리핑: 0.1 (최대 노름)
- 조기 종료: 첫 번째 도메인 patience=10, 이후 도메인 patience=4
- 최소 에포크: 첫 번째 도메인 8회, 이후 도메인 3회

### 4.3 비교 Baseline 모델들

**기존 베어링 진단 모델들과 비교:**
1. **Vibration-only CNN**: 진동 신호만 사용한 1D-CNN 분류기
2. **Text-only Transformer**: 텍스트 설명만 사용한 DistilBERT 분류기
3. **Early Fusion**: 진동과 텍스트를 단순 연결한 모델
4. **Late Fusion**: 두 모달리티를 독립적으로 학습 후 결합
5. **Standard CLIP**: 이미지-텍스트 CLIP을 진동에 적용한 버전

### 4.4 평가 지표

**분류 및 continual learning 성능 평가:**
- 분류 지표: Accuracy, F1-score, Precision, Recall
- Continual Learning 지표:
  - 평균 정확도 (전체 도메인 평균)
  - 망각도 (이전 도메인 성능 저하율)
  - 순방향 전이 (새 도메인 학습 효율)
  - 후방향 전이 (이전 도메인 성능 향상)
- 평가 방식: 각 도메인 학습 완료 후 모든 이전 도메인에 대해 테스트

---

이 정보로 3.Methodology와 4.Experimental Results 챕터를 작성하시면 됩니다. 실제 결과 수치(정확도, 손실값 등)는 나중에 제가 제공해드릴게요.
