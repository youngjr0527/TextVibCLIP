{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TextVibCLIP Text-Vibration ì •ë ¬ ë¬¸ì œ ë¶„ì„ ë° í•´ê²°\n",
        "\n",
        "**ì‹¬ê°í•œ ë¬¸ì œ ë°œê²¬:**\n",
        "- Text Encoder ë‹¨ë…: 83.0% (ìš°ìˆ˜)\n",
        "- Vibration Encoder ë‹¨ë…: 88.6% (ìš°ìˆ˜)  \n",
        "- TextVibCLIP í†µí•©: 14.4% (ëœë¤ ìˆ˜ì¤€)\n",
        "\n",
        "**71.4%p ì„±ëŠ¥ ì†ì‹¤ì˜ ì›ì¸ì„ ì°¾ì•„ í•´ê²°í•˜ì!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/data/home/kyj2024/anaconda3/envs/TVCLIP/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Text-Vibration ì •ë ¬ ë¬¸ì œ ë¶„ì„ ì‹œì‘\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/data/home/kyj2024/anaconda3/envs/TVCLIP/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
            "/data/home/kyj2024/anaconda3/envs/TVCLIP/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.manifold import TSNE\n",
        "from collections import Counter\n",
        "import logging\n",
        "import seaborn as sns\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€\n",
        "sys.path.append('/data/home/kyj2024/TextVibCLIP')\n",
        "\n",
        "from src.text_encoder import create_text_encoder\n",
        "from src.vibration_encoder import VibrationEncoder\n",
        "from src.textvib_model import TextVibCLIP\n",
        "from src.data_loader import BearingDataset, create_collate_fn\n",
        "from configs.model_config import MODEL_CONFIG\n",
        "\n",
        "# ë¡œê¹… ì„¤ì •\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"ğŸ” Text-Vibration ì •ë ¬ ë¬¸ì œ ë¶„ì„ ì‹œì‘\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ë°ì´í„° ë° ëª¨ë¸ ì¤€ë¹„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.data_loader:UOS ë°ì´í„° ë¼ë²¨ ë¶„í¬: {'B_6204': 1, 'H_6204': 4, 'IR_6204': 1, 'OR_6204': 1}\n",
            "INFO:src.data_loader:ìµœì†Œ ìƒ˜í”Œ ìˆ˜: 1\n",
            "INFO:src.data_loader:UOS Domain-Incremental ìœˆë„ìš° ë ˆë²¨ ë¶„í• :\n",
            "INFO:src.data_loader:  ëª¨ë“  subsetì— ëª¨ë“  7ê°œ íŒŒì¼ í¬í•¨\n",
            "INFO:src.data_loader:  ê° íŒŒì¼ ë‚´ì—ì„œ ìœˆë„ìš° ë¶„í• : Train 60%, Val 20%, Test 20%\n",
            "INFO:src.data_loader:  Deep Groove Ball 7-í´ë˜ìŠ¤ ë¶„í¬: {'B': 1, 'H': 1, 'IR': 1, 'OR': 1, 'L': 1, 'M': 1, 'U': 1}\n",
            "INFO:src.data_loader:  í´ë˜ìŠ¤ ìˆ˜: 7ê°œ (ê· í˜• í™•ì¸)\n",
            "INFO:src.data_loader:  âœ… ì™„ë²½í•œ í´ë˜ìŠ¤ ê· í˜• ë‹¬ì„±!\n",
            "INFO:src.data_loader:UOS train ë¶„í•  ê²°ê³¼:\n",
            "INFO:src.data_loader:  Train: 7ê°œ íŒŒì¼, Val: 7ê°œ íŒŒì¼, Test: 7ê°œ íŒŒì¼\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë””ë°”ì´ìŠ¤: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.data_loader:BearingDataset ì´ˆê¸°í™” ì™„ë£Œ (UOS): 7ê°œ íŒŒì¼, 1249ê°œ ìœˆë„ìš°/íŒŒì¼, ì´ 8743ê°œ ìƒ˜í”Œ, Domain: 600, Subset: train\n",
            "INFO:src.data_loader:UOS ë°ì´í„° ë¼ë²¨ ë¶„í¬: {'B_6204': 1, 'H_6204': 4, 'IR_6204': 1, 'OR_6204': 1}\n",
            "INFO:src.data_loader:ìµœì†Œ ìƒ˜í”Œ ìˆ˜: 1\n",
            "INFO:src.data_loader:UOS Domain-Incremental ìœˆë„ìš° ë ˆë²¨ ë¶„í• :\n",
            "INFO:src.data_loader:  ëª¨ë“  subsetì— ëª¨ë“  7ê°œ íŒŒì¼ í¬í•¨\n",
            "INFO:src.data_loader:  ê° íŒŒì¼ ë‚´ì—ì„œ ìœˆë„ìš° ë¶„í• : Train 60%, Val 20%, Test 20%\n",
            "INFO:src.data_loader:  Deep Groove Ball 7-í´ë˜ìŠ¤ ë¶„í¬: {'B': 1, 'H': 1, 'IR': 1, 'OR': 1, 'L': 1, 'M': 1, 'U': 1}\n",
            "INFO:src.data_loader:  í´ë˜ìŠ¤ ìˆ˜: 7ê°œ (ê· í˜• í™•ì¸)\n",
            "INFO:src.data_loader:  âœ… ì™„ë²½í•œ í´ë˜ìŠ¤ ê· í˜• ë‹¬ì„±!\n",
            "INFO:src.data_loader:UOS test ë¶„í•  ê²°ê³¼:\n",
            "INFO:src.data_loader:  Train: 7ê°œ íŒŒì¼, Val: 7ê°œ íŒŒì¼, Test: 7ê°œ íŒŒì¼\n",
            "INFO:src.data_loader:BearingDataset ì´ˆê¸°í™” ì™„ë£Œ (UOS): 7ê°œ íŒŒì¼, 1249ê°œ ìœˆë„ìš°/íŒŒì¼, ì´ 8743ê°œ ìƒ˜í”Œ, Domain: 600, Subset: test\n",
            "INFO:src.data_loader:ì¸ë±ìŠ¤ ë§¤í•‘ ìƒì„± ì™„ë£Œ: 8743ê°œ (íŒŒì¼ 7ê°œ Ã— ìœˆë„ìš° 1249ê°œ)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train ë°ì´í„°: 8743ê°œ ìƒ˜í”Œ\n",
            "Test ë°ì´í„°: 8743ê°œ ìƒ˜í”Œ\n",
            "\n",
            "ìƒ˜í”Œ êµ¬ì¡°:\n",
            "  ë¼ë²¨: tensor([6, 0])\n",
            "  ì§„ë™ ì‹ í˜¸ shape: torch.Size([2048])\n",
            "  í…ìŠ¤íŠ¸: Shaft misalignment detected...\n"
          ]
        }
      ],
      "source": [
        "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ë””ë°”ì´ìŠ¤: {device}\")\n",
        "\n",
        "# UOS ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "train_dataset = BearingDataset(\n",
        "    data_dir='data_scenario1',\n",
        "    dataset_type='uos',\n",
        "    domain_value=600,\n",
        "    subset='train'\n",
        ")\n",
        "\n",
        "test_dataset = BearingDataset(\n",
        "    data_dir='data_scenario1',\n",
        "    dataset_type='uos',\n",
        "    domain_value=600,\n",
        "    subset='test'\n",
        ")\n",
        "\n",
        "print(f\"Train ë°ì´í„°: {len(train_dataset)}ê°œ ìƒ˜í”Œ\")\n",
        "print(f\"Test ë°ì´í„°: {len(test_dataset)}ê°œ ìƒ˜í”Œ\")\n",
        "\n",
        "# ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
        "sample = train_dataset[0]\n",
        "print(f\"\\nìƒ˜í”Œ êµ¬ì¡°:\")\n",
        "print(f\"  ë¼ë²¨: {sample['labels']}\")\n",
        "print(f\"  ì§„ë™ ì‹ í˜¸ shape: {sample['vibration'].shape}\")\n",
        "print(f\"  í…ìŠ¤íŠ¸: {sample['text'][:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ê°œë³„ Encoder ë° í†µí•© ëª¨ë¸ ìƒì„±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.text_encoder:LoRA ì ìš© ì™„ë£Œ: rank=32, alpha=64\n",
            "INFO:src.text_encoder:Base DistilBERT íŒŒë¼ë¯¸í„° freeze ì™„ë£Œ: 100ê°œ íŒŒë¼ë¯¸í„°\n",
            "INFO:src.text_encoder:TextEncoder ì´ˆê¸°í™” ì™„ë£Œ: LoRA=True, Freeze=True\n",
            "INFO:src.text_encoder:TextEncoder ìƒì„± (first_domain): Total=1,114,880, LoRA=589,824\n",
            "INFO:src.vibration_encoder:1D-CNN VibrationEncoder ì´ˆê¸°í™”: input_length=2048, embedding_dim=256\n",
            "INFO:src.vibration_encoder:   OPTIMIZED: ì»¤ë„ í¬ê¸°: [16, 32, 64, 32] - 4-layer ë² ì–´ë§ ìµœì í™”\n",
            "INFO:src.vibration_encoder:   OPTIMIZED: ì±„ë„ ìˆ˜: [64, 128, 256, 512] - ìì—°ìŠ¤ëŸ¬ìš´ 64â†’512 ì¦ê°€\n",
            "INFO:src.vibration_encoder:   ì´ íŒŒë¼ë¯¸í„°: 6,985,288\n",
            "INFO:src.text_encoder:LoRA ì ìš© ì™„ë£Œ: rank=32, alpha=64\n",
            "INFO:src.text_encoder:Base DistilBERT íŒŒë¼ë¯¸í„° freeze ì™„ë£Œ: 100ê°œ íŒŒë¼ë¯¸í„°\n",
            "INFO:src.text_encoder:TextEncoder ì´ˆê¸°í™” ì™„ë£Œ: LoRA=True, Freeze=True\n",
            "INFO:src.text_encoder:TextEncoder ìƒì„± (first_domain): Total=1,114,880, LoRA=589,824\n",
            "INFO:src.vibration_encoder:1D-CNN VibrationEncoder ì´ˆê¸°í™”: input_length=2048, embedding_dim=256\n",
            "INFO:src.vibration_encoder:   OPTIMIZED: ì»¤ë„ í¬ê¸°: [16, 32, 64, 32] - 4-layer ë² ì–´ë§ ìµœì í™”\n",
            "INFO:src.vibration_encoder:   OPTIMIZED: ì±„ë„ ìˆ˜: [64, 128, 256, 512] - ìì—°ìŠ¤ëŸ¬ìš´ 64â†’512 ì¦ê°€\n",
            "INFO:src.vibration_encoder:   ì´ íŒŒë¼ë¯¸í„°: 6,985,288\n",
            "INFO:src.vibration_encoder:1D-CNN VibrationEncoder ìƒì„± ì™„ë£Œ: 6,985,288 íŒŒë¼ë¯¸í„°\n",
            "INFO:src.textvib_model:InfoNCE Loss ì´ˆê¸°í™”: Ï„_text=0.050, Ï„_vib=0.050 (í•™ìŠµ ê°€ëŠ¥)\n",
            "INFO:src.textvib_model:TextVibCLIP ì´ˆê¸°í™” ì™„ë£Œ: first_domain stage\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ ëª¨ë¸ ìƒì„± ì™„ë£Œ:\n",
            "  ê°œë³„ Text Encoder: 1,114,880ê°œ íŒŒë¼ë¯¸í„°\n",
            "  ê°œë³„ Vibration Encoder: 6,985,288ê°œ íŒŒë¼ë¯¸í„°\n",
            "  TextVibCLIP í†µí•©: 74,463,050ê°œ íŒŒë¼ë¯¸í„°\n",
            "\n",
            "ğŸ“ ì„ë² ë”© ì°¨ì›:\n",
            "  ê°œë³„ Text Encoder â†’ 256ì°¨ì›\n",
            "  ê°œë³„ Vibration Encoder â†’ 256ì°¨ì›\n",
            "  í†µí•© ëª¨ë¸ â†’ 256ì°¨ì›\n",
            "  Projection â†’ 512ì°¨ì›\n",
            "\n",
            "ğŸ” í†µí•© ëª¨ë¸ êµ¬ì¡°:\n",
            "  í†µí•© Text Encoder: True\n",
            "  í†µí•© Vibration Encoder: True\n",
            "  InfoNCE Loss: True\n"
          ]
        }
      ],
      "source": [
        "# 1. ê°œë³„ Text Encoder ìƒì„±\n",
        "text_encoder = create_text_encoder('first_domain')\n",
        "text_encoder.to(device)\n",
        "text_encoder.eval()\n",
        "\n",
        "# 2. ê°œë³„ Vibration Encoder ìƒì„±\n",
        "vibration_encoder = VibrationEncoder(\n",
        "    input_length=MODEL_CONFIG['vibration_encoder']['input_length'],\n",
        "    embedding_dim=MODEL_CONFIG['embedding_dim']\n",
        ")\n",
        "vibration_encoder.to(device)\n",
        "vibration_encoder.eval()\n",
        "\n",
        "# 3. TextVibCLIP í†µí•© ëª¨ë¸ ìƒì„± (ì˜¬ë°”ë¥¸ ìƒì„±ì ì‚¬ìš©)\n",
        "textvib_model = TextVibCLIP(\n",
        "    domain_stage='first_domain',\n",
        "    embedding_dim=MODEL_CONFIG['embedding_dim']\n",
        ")\n",
        "textvib_model.to(device)\n",
        "textvib_model.eval()\n",
        "\n",
        "print(\"ğŸ”§ ëª¨ë¸ ìƒì„± ì™„ë£Œ:\")\n",
        "print(f\"  ê°œë³„ Text Encoder: {text_encoder.get_trainable_parameters():,}ê°œ íŒŒë¼ë¯¸í„°\")\n",
        "print(f\"  ê°œë³„ Vibration Encoder: {sum(p.numel() for p in vibration_encoder.parameters()):,}ê°œ íŒŒë¼ë¯¸í„°\") \n",
        "print(f\"  TextVibCLIP í†µí•©: {sum(p.numel() for p in textvib_model.parameters()):,}ê°œ íŒŒë¼ë¯¸í„°\")\n",
        "\n",
        "# ì„ë² ë”© ì°¨ì› í™•ì¸\n",
        "print(f\"\\nğŸ“ ì„ë² ë”© ì°¨ì›:\")\n",
        "print(f\"  ê°œë³„ Text Encoder â†’ {MODEL_CONFIG['embedding_dim']}ì°¨ì›\")\n",
        "print(f\"  ê°œë³„ Vibration Encoder â†’ {MODEL_CONFIG['embedding_dim']}ì°¨ì›\")\n",
        "print(f\"  í†µí•© ëª¨ë¸ â†’ {MODEL_CONFIG['embedding_dim']}ì°¨ì›\")\n",
        "print(f\"  Projection â†’ {MODEL_CONFIG['projection']['hidden_dim']}ì°¨ì›\")\n",
        "\n",
        "# í†µí•© ëª¨ë¸ì˜ ë‚´ë¶€ encoder ì ‘ê·¼\n",
        "print(f\"\\nğŸ” í†µí•© ëª¨ë¸ êµ¬ì¡°:\")\n",
        "print(f\"  í†µí•© Text Encoder: {hasattr(textvib_model, 'text_encoder')}\")\n",
        "print(f\"  í†µí•© Vibration Encoder: {hasattr(textvib_model, 'vibration_encoder')}\")\n",
        "print(f\"  InfoNCE Loss: {hasattr(textvib_model, 'infonce_loss')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ì„ë² ë”© ìƒì„± ë° ì •ë ¬ ìƒíƒœ ë¶„ì„ (í•µì‹¬)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ í´ë˜ìŠ¤ë³„ ë°ì´í„° ìƒ˜í”Œë§...\n",
            "ìƒ˜í”Œë§ ì™„ë£Œ: {0: 50, 1: 50, 2: 50, 3: 50, 4: 50, 5: 50, 6: 50}\n",
            "\n",
            "ì´ ë°ì´í„°: 350ê°œ (í…ìŠ¤íŠ¸ + ì§„ë™)\n",
            "ì§„ë™ í…ì„œ shape: torch.Size([350, 2048])\n",
            "í´ë˜ìŠ¤ ë¶„í¬: Counter({0: 50, 1: 50, 2: 50, 3: 50, 4: 50, 5: 50, 6: 50})\n"
          ]
        }
      ],
      "source": [
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒ˜í”Œë§ (ê° í´ë˜ìŠ¤ë‹¹ 50ê°œì”©)\n",
        "samples_per_class = 50\n",
        "class_data = {i: {'texts': [], 'vibrations': [], 'labels': []} for i in range(7)}\n",
        "class_counts = {i: 0 for i in range(7)}\n",
        "\n",
        "print(\"ğŸ¯ í´ë˜ìŠ¤ë³„ ë°ì´í„° ìƒ˜í”Œë§...\")\n",
        "for i in range(len(train_dataset)):\n",
        "    if all(count >= samples_per_class for count in class_counts.values()):\n",
        "        break\n",
        "        \n",
        "    sample = train_dataset[i]\n",
        "    label = sample['labels'][0].item()\n",
        "    \n",
        "    if class_counts[label] < samples_per_class:\n",
        "        class_data[label]['texts'].append(sample['text'])\n",
        "        class_data[label]['vibrations'].append(sample['vibration'])\n",
        "        class_data[label]['labels'].append(label)\n",
        "        class_counts[label] += 1\n",
        "\n",
        "print(f\"ìƒ˜í”Œë§ ì™„ë£Œ: {class_counts}\")\n",
        "\n",
        "# ë°ì´í„° ê²°í•©\n",
        "all_texts = []\n",
        "all_vibrations = []\n",
        "all_labels = []\n",
        "\n",
        "for class_id in range(7):\n",
        "    all_texts.extend(class_data[class_id]['texts'])\n",
        "    all_vibrations.extend(class_data[class_id]['vibrations'])\n",
        "    all_labels.extend(class_data[class_id]['labels'])\n",
        "\n",
        "vibration_tensor = torch.stack(all_vibrations)\n",
        "labels_tensor = torch.tensor(all_labels)\n",
        "\n",
        "print(f\"\\nì´ ë°ì´í„°: {len(all_texts)}ê°œ (í…ìŠ¤íŠ¸ + ì§„ë™)\")\n",
        "print(f\"ì§„ë™ í…ì„œ shape: {vibration_tensor.shape}\")\n",
        "print(f\"í´ë˜ìŠ¤ ë¶„í¬: {Counter(all_labels)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ” ì„ë² ë”© ìƒì„± ë° ë¹„êµ ë¶„ì„\n",
            "==================================================\n",
            "âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ\n",
            "  ê°œë³„ Text: torch.Size([350, 256])\n",
            "  ê°œë³„ Vibration: torch.Size([350, 256])\n",
            "  í†µí•© Text: torch.Size([350, 256])\n",
            "  í†µí•© Vibration: torch.Size([350, 256])\n",
            "\n",
            "ğŸ“ ì„ë² ë”© ë¹„êµ:\n",
            "  ì°¨ì› ì¼ì¹˜: True\n",
            "  ê°œë³„ vs í†µí•© ì°¨ì´ (Text): 25.719437\n",
            "  ê°œë³„ vs í†µí•© ì°¨ì´ (Vibration): 26.672676\n",
            "  Text ì„ë² ë”© ë™ì¼ì„±: False\n",
            "  Vibration ì„ë² ë”© ë™ì¼ì„±: False\n",
            "âŒ ê°œë³„ê³¼ í†µí•© ì„ë² ë”©ì´ ë‹¤ë¦„!\n",
            "   â†’ í†µí•© ëª¨ë¸ ë‚´ë¶€ì—ì„œ ì¶”ê°€ ë³€í™˜ì´ ë°œìƒ\n"
          ]
        }
      ],
      "source": [
        "# ğŸ” í•µì‹¬: ê°œë³„ Encoder vs í†µí•© ëª¨ë¸ ì„ë² ë”© ë¹„êµ\n",
        "print(\"\\nğŸ” ì„ë² ë”© ìƒì„± ë° ë¹„êµ ë¶„ì„\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "batch_size = 32\n",
        "with torch.no_grad():\n",
        "    # 1. ê°œë³„ Text Encoder ì„ë² ë”©\n",
        "    text_embeddings_individual = text_encoder.encode_texts(all_texts, device)\n",
        "    text_embeddings_individual = F.normalize(text_embeddings_individual, p=2, dim=1)\n",
        "    \n",
        "    # 2. ê°œë³„ Vibration Encoder ì„ë² ë”©\n",
        "    vib_embeddings_individual = []\n",
        "    for i in range(0, len(vibration_tensor), batch_size):\n",
        "        batch_vib = vibration_tensor[i:i+batch_size].to(device)\n",
        "        batch_emb = vibration_encoder(batch_vib)\n",
        "        batch_emb = F.normalize(batch_emb, p=2, dim=1)\n",
        "        vib_embeddings_individual.append(batch_emb.cpu())\n",
        "    vib_embeddings_individual = torch.cat(vib_embeddings_individual, dim=0)\n",
        "    \n",
        "    # 3. í†µí•© ëª¨ë¸ ì„ë² ë”© (TextVibCLIP) - ë‚´ë¶€ encoder ì§ì ‘ ì‚¬ìš©\n",
        "    text_embeddings_integrated = []\n",
        "    vib_embeddings_integrated = []\n",
        "    \n",
        "    for i in range(0, len(all_texts), batch_size):\n",
        "        end_idx = min(i + batch_size, len(all_texts))\n",
        "        batch_texts = all_texts[i:end_idx]\n",
        "        batch_vibs = vibration_tensor[i:end_idx].to(device)\n",
        "        \n",
        "        # í†µí•© ëª¨ë¸ì˜ ë‚´ë¶€ encoderë¥¼ í†µí•´ ì„ë² ë”© ìƒì„± (projection ì—†ì´)\n",
        "        batch_text_emb = textvib_model.text_encoder.encode_texts(batch_texts, device)\n",
        "        batch_vib_emb = textvib_model.vibration_encoder(batch_vibs)\n",
        "        \n",
        "        # ì •ê·œí™” (TextVibCLIPê³¼ ë™ì¼í•œ ë°©ì‹)\n",
        "        batch_text_emb = F.normalize(batch_text_emb, p=2, dim=1)\n",
        "        batch_vib_emb = F.normalize(batch_vib_emb, p=2, dim=1)\n",
        "        \n",
        "        text_embeddings_integrated.append(batch_text_emb.cpu())\n",
        "        vib_embeddings_integrated.append(batch_vib_emb.cpu())\n",
        "    \n",
        "    text_embeddings_integrated = torch.cat(text_embeddings_integrated, dim=0)\n",
        "    vib_embeddings_integrated = torch.cat(vib_embeddings_integrated, dim=0)\n",
        "\n",
        "print(\"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ\")\n",
        "print(f\"  ê°œë³„ Text: {text_embeddings_individual.shape}\")\n",
        "print(f\"  ê°œë³„ Vibration: {vib_embeddings_individual.shape}\")\n",
        "print(f\"  í†µí•© Text: {text_embeddings_integrated.shape}\")\n",
        "print(f\"  í†µí•© Vibration: {vib_embeddings_integrated.shape}\")\n",
        "\n",
        "# ì„ë² ë”© ì°¨ì› ë° ë™ì¼ì„± í™•ì¸ (ë””ë°”ì´ìŠ¤ í†µì¼)\n",
        "print(f\"\\nğŸ“ ì„ë² ë”© ë¹„êµ:\")\n",
        "print(f\"  ì°¨ì› ì¼ì¹˜: {text_embeddings_individual.shape == text_embeddings_integrated.shape}\")\n",
        "\n",
        "# ë””ë°”ì´ìŠ¤ë¥¼ CPUë¡œ í†µì¼í•˜ì—¬ ë¹„êµ\n",
        "text_individual_cpu = text_embeddings_individual.cpu()\n",
        "vib_individual_cpu = vib_embeddings_individual.cpu()\n",
        "text_integrated_cpu = text_embeddings_integrated.cpu()\n",
        "vib_integrated_cpu = vib_embeddings_integrated.cpu()\n",
        "\n",
        "text_diff = torch.norm(text_individual_cpu - text_integrated_cpu).item()\n",
        "vib_diff = torch.norm(vib_individual_cpu - vib_integrated_cpu).item()\n",
        "\n",
        "print(f\"  ê°œë³„ vs í†µí•© ì°¨ì´ (Text): {text_diff:.6f}\")\n",
        "print(f\"  ê°œë³„ vs í†µí•© ì°¨ì´ (Vibration): {vib_diff:.6f}\")\n",
        "\n",
        "# ë™ì¼ì„± ê²€ì‚¬\n",
        "text_identical = torch.allclose(text_individual_cpu, text_integrated_cpu, atol=1e-6)\n",
        "vib_identical = torch.allclose(vib_individual_cpu, vib_integrated_cpu, atol=1e-6)\n",
        "\n",
        "print(f\"  Text ì„ë² ë”© ë™ì¼ì„±: {text_identical}\")\n",
        "print(f\"  Vibration ì„ë² ë”© ë™ì¼ì„±: {vib_identical}\")\n",
        "\n",
        "if text_identical and vib_identical:\n",
        "    print(\"ğŸš¨ ê°œë³„ ëª¨ë¸ê³¼ í†µí•© ëª¨ë¸ì˜ ì„ë² ë”©ì´ ë™ì¼í•¨!\")\n",
        "    print(\"   â†’ Encoder ìì²´ëŠ” ë™ì¼í•˜ê²Œ ì‘ë™\")\n",
        "    print(\"   â†’ ë¬¸ì œëŠ” InfoNCE Loss, Temperature, ë˜ëŠ” í‰ê°€ ë¡œì§ì— ìˆìŒ\")\n",
        "elif text_diff < 1e-3 and vib_diff < 1e-3:\n",
        "    print(\"âš ï¸ ê°œë³„ê³¼ í†µí•© ì„ë² ë”©ì´ ê±°ì˜ ë™ì¼í•¨ (ë¯¸ì„¸í•œ ì°¨ì´)\")\n",
        "    print(\"   â†’ ìˆ˜ì¹˜ì  ì •ë°€ë„ ì°¨ì´ì¼ ê°€ëŠ¥ì„±\")\n",
        "else:\n",
        "    print(\"âŒ ê°œë³„ê³¼ í†µí•© ì„ë² ë”©ì´ ë‹¤ë¦„!\")\n",
        "    print(\"   â†’ í†µí•© ëª¨ë¸ ë‚´ë¶€ì—ì„œ ì¶”ê°€ ë³€í™˜ì´ ë°œìƒ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ì •ë ¬ ìƒíƒœ ì§„ë‹¨ (Critical Analysis)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸš¨ Text-Vibration ì •ë ¬ ìƒíƒœ ì§„ë‹¨\n",
            "============================================================\n",
            "\n",
            "ğŸ“Š ê°œë³„ Encoder ì •ë ¬ ìƒíƒœ\n",
            "----------------------------------------\n",
            "Text ì„ë² ë”© í†µê³„:\n",
            "  í‰ê· : 0.002460, í‘œì¤€í¸ì°¨: 0.062452\n",
            "  ë²”ìœ„: [-0.190191, 0.185345]\n",
            "Vibration ì„ë² ë”© í†µê³„:\n",
            "  í‰ê· : -0.001136, í‘œì¤€í¸ì°¨: 0.062490\n",
            "  ë²”ìœ„: [-0.189785, 0.216230]\n",
            "Cross-modal ì •ë ¬ ë¶„ì„:\n",
            "  ê°™ì€ í´ë˜ìŠ¤ ìœ ì‚¬ë„: 0.047532\n",
            "  ë‹¤ë¥¸ í´ë˜ìŠ¤ ìœ ì‚¬ë„: 0.047442\n",
            "  ì •ë ¬ ì ìˆ˜: 0.000090 (í´ìˆ˜ë¡ ì¢‹ìŒ)\n",
            "í´ë˜ìŠ¤ë³„ Text-Vibration ì •ë ¬:\n",
            "  í´ë˜ìŠ¤ 0: 0.054840\n",
            "  í´ë˜ìŠ¤ 1: 0.050084\n",
            "  í´ë˜ìŠ¤ 2: 0.049372\n",
            "  í´ë˜ìŠ¤ 3: 0.052083\n",
            "  í´ë˜ìŠ¤ 4: 0.042589\n",
            "  í´ë˜ìŠ¤ 5: 0.049161\n",
            "  í´ë˜ìŠ¤ 6: 0.034598\n",
            "  í‰ê·  í´ë˜ìŠ¤ ì •ë ¬: 0.047532\n",
            "\n",
            "ğŸ“Š í†µí•© ëª¨ë¸ ì •ë ¬ ìƒíƒœ\n",
            "----------------------------------------\n",
            "Text ì„ë² ë”© í†µê³„:\n",
            "  í‰ê· : 0.004101, í‘œì¤€í¸ì°¨: 0.062366\n",
            "  ë²”ìœ„: [-0.182250, 0.190655]\n",
            "Vibration ì„ë² ë”© í†µê³„:\n",
            "  í‰ê· : -0.002421, í‘œì¤€í¸ì°¨: 0.062453\n",
            "  ë²”ìœ„: [-0.166377, 0.179656]\n",
            "Cross-modal ì •ë ¬ ë¶„ì„:\n",
            "  ê°™ì€ í´ë˜ìŠ¤ ìœ ì‚¬ë„: 0.002629\n",
            "  ë‹¤ë¥¸ í´ë˜ìŠ¤ ìœ ì‚¬ë„: 0.002651\n",
            "  ì •ë ¬ ì ìˆ˜: -0.000022 (í´ìˆ˜ë¡ ì¢‹ìŒ)\n",
            "í´ë˜ìŠ¤ë³„ Text-Vibration ì •ë ¬:\n",
            "  í´ë˜ìŠ¤ 0: 0.003898\n",
            "  í´ë˜ìŠ¤ 1: 0.009290\n",
            "  í´ë˜ìŠ¤ 2: -0.004035\n",
            "  í´ë˜ìŠ¤ 3: 0.010970\n",
            "  í´ë˜ìŠ¤ 4: -0.017201\n",
            "  í´ë˜ìŠ¤ 5: 0.004601\n",
            "  í´ë˜ìŠ¤ 6: 0.010880\n",
            "  í‰ê·  í´ë˜ìŠ¤ ì •ë ¬: 0.002629\n"
          ]
        }
      ],
      "source": [
        "# ğŸš¨ í•µì‹¬ ë¶„ì„: Text-Vibration ì •ë ¬ ìƒíƒœ ì§„ë‹¨\n",
        "print(\"\\nğŸš¨ Text-Vibration ì •ë ¬ ìƒíƒœ ì§„ë‹¨\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def analyze_alignment(text_emb, vib_emb, labels, title):\n",
        "    \"\"\"Text-Vibration ì„ë² ë”© ì •ë ¬ ìƒíƒœ ë¶„ì„ (ë””ë°”ì´ìŠ¤ ì•ˆì „)\"\"\"\n",
        "    print(f\"\\nğŸ“Š {title}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # ğŸ”§ ë””ë°”ì´ìŠ¤ í†µì¼: ëª¨ë“  í…ì„œë¥¼ CPUë¡œ ì´ë™\n",
        "    text_emb_cpu = text_emb.cpu()\n",
        "    vib_emb_cpu = vib_emb.cpu()\n",
        "    labels_cpu = labels.cpu()\n",
        "    \n",
        "    # 1. ì„ë² ë”© í†µê³„\n",
        "    print(f\"Text ì„ë² ë”© í†µê³„:\")\n",
        "    print(f\"  í‰ê· : {text_emb_cpu.mean().item():.6f}, í‘œì¤€í¸ì°¨: {text_emb_cpu.std().item():.6f}\")\n",
        "    print(f\"  ë²”ìœ„: [{text_emb_cpu.min().item():.6f}, {text_emb_cpu.max().item():.6f}]\")\n",
        "    \n",
        "    print(f\"Vibration ì„ë² ë”© í†µê³„:\")\n",
        "    print(f\"  í‰ê· : {vib_emb_cpu.mean().item():.6f}, í‘œì¤€í¸ì°¨: {vib_emb_cpu.std().item():.6f}\")\n",
        "    print(f\"  ë²”ìœ„: [{vib_emb_cpu.min().item():.6f}, {vib_emb_cpu.max().item():.6f}]\")\n",
        "    \n",
        "    # 2. Cross-modal ìœ ì‚¬ë„ ë¶„ì„\n",
        "    cross_similarity = torch.matmul(text_emb_cpu, vib_emb_cpu.t())  # (N, N)\n",
        "    \n",
        "    # ê°™ì€ í´ë˜ìŠ¤ ê°„ ìœ ì‚¬ë„ (ëŒ€ê°ì„ )\n",
        "    same_class_sim = torch.diag(cross_similarity).mean().item()\n",
        "    \n",
        "    # ë‹¤ë¥¸ í´ë˜ìŠ¤ ê°„ ìœ ì‚¬ë„ (ë¹„ëŒ€ê°ì„ )\n",
        "    mask = ~torch.eye(len(labels_cpu), dtype=torch.bool)\n",
        "    diff_class_sim = cross_similarity[mask].mean().item()\n",
        "    \n",
        "    alignment_score = same_class_sim - diff_class_sim\n",
        "    \n",
        "    print(f\"Cross-modal ì •ë ¬ ë¶„ì„:\")\n",
        "    print(f\"  ê°™ì€ í´ë˜ìŠ¤ ìœ ì‚¬ë„: {same_class_sim:.6f}\")\n",
        "    print(f\"  ë‹¤ë¥¸ í´ë˜ìŠ¤ ìœ ì‚¬ë„: {diff_class_sim:.6f}\")\n",
        "    print(f\"  ì •ë ¬ ì ìˆ˜: {alignment_score:.6f} (í´ìˆ˜ë¡ ì¢‹ìŒ)\")\n",
        "    \n",
        "    # 3. í´ë˜ìŠ¤ë³„ ì •ë ¬ ìƒíƒœ\n",
        "    unique_labels = torch.unique(labels_cpu)\n",
        "    print(f\"í´ë˜ìŠ¤ë³„ Text-Vibration ì •ë ¬:\")\n",
        "    \n",
        "    class_alignments = []\n",
        "    for cls in unique_labels:\n",
        "        cls_mask = (labels_cpu == cls)\n",
        "        cls_text = text_emb_cpu[cls_mask]\n",
        "        cls_vib = vib_emb_cpu[cls_mask]\n",
        "        \n",
        "        # í´ë˜ìŠ¤ ë‚´ Text-Vibration ìœ ì‚¬ë„\n",
        "        if len(cls_text) > 0:\n",
        "            cls_sim = torch.matmul(cls_text, cls_vib.t()).diag().mean().item()\n",
        "            class_alignments.append(cls_sim)\n",
        "            print(f\"  í´ë˜ìŠ¤ {cls.item()}: {cls_sim:.6f}\")\n",
        "    \n",
        "    avg_class_alignment = np.mean(class_alignments)\n",
        "    print(f\"  í‰ê·  í´ë˜ìŠ¤ ì •ë ¬: {avg_class_alignment:.6f}\")\n",
        "    \n",
        "    return {\n",
        "        'alignment_score': alignment_score,\n",
        "        'same_class_sim': same_class_sim,\n",
        "        'diff_class_sim': diff_class_sim,\n",
        "        'avg_class_alignment': avg_class_alignment,\n",
        "        'class_alignments': class_alignments\n",
        "    }\n",
        "\n",
        "# ê°œë³„ Encoder ì •ë ¬ ë¶„ì„\n",
        "individual_analysis = analyze_alignment(\n",
        "    text_embeddings_individual, \n",
        "    vib_embeddings_individual, \n",
        "    labels_tensor,\n",
        "    \"ê°œë³„ Encoder ì •ë ¬ ìƒíƒœ\"\n",
        ")\n",
        "\n",
        "# í†µí•© ëª¨ë¸ ì •ë ¬ ë¶„ì„  \n",
        "integrated_analysis = analyze_alignment(\n",
        "    text_embeddings_integrated,\n",
        "    vib_embeddings_integrated, \n",
        "    labels_tensor,\n",
        "    \"í†µí•© ëª¨ë¸ ì •ë ¬ ìƒíƒœ\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. InfoNCE Loss ë° Temperature ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¥ InfoNCE Loss ë¶„ì„\n",
            "==================================================\n",
            "í˜„ì¬ Temperature ì„¤ì •:\n",
            "  First domain text: 0.05\n",
            "  First domain vibration: 0.05\n",
            "  Continual text: 0.07\n",
            "  Continual vibration: 0.03\n",
            "\n",
            "ğŸ“ˆ Temperatureë³„ InfoNCE ì„±ëŠ¥ (ê°œë³„ Encoder):\n",
            "Temp\tLoss\tAccuracy\n",
            "------------------------------\n",
            "0.01\t5.9496\t0.0029\n",
            "0.05\t5.8602\t0.0029\n",
            "0.07\t5.8587\t0.0029\n",
            "0.10\t5.8581\t0.0029\n",
            "0.20\t5.8577\t0.0029\n",
            "0.50\t5.8578\t0.0029\n",
            "\n",
            "ğŸ“ˆ Temperatureë³„ InfoNCE ì„±ëŠ¥ (í†µí•© ëª¨ë¸):\n",
            "Temp\tLoss\tAccuracy\n",
            "------------------------------\n",
            "0.01\t6.2571\t0.0029\n",
            "0.05\t5.8786\t0.0029\n",
            "0.07\t5.8688\t0.0029\n",
            "0.10\t5.8634\t0.0029\n",
            "0.20\t5.8594\t0.0029\n",
            "0.50\t5.8582\t0.0029\n",
            "\n",
            "ğŸ¯ ìµœì  Temperature:\n",
            "  ê°œë³„ Encoder: 0.01 (ì •í™•ë„: 0.0029)\n",
            "  í†µí•© ëª¨ë¸: 0.01 (ì •í™•ë„: 0.0029)\n"
          ]
        }
      ],
      "source": [
        "# ğŸ”¥ InfoNCE Loss ë° Temperature íŒŒë¼ë¯¸í„° ë¶„ì„\n",
        "print(\"\\nğŸ”¥ InfoNCE Loss ë¶„ì„\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def calculate_infonce_loss(text_emb, vib_emb, temperature=0.07):\n",
        "    \"\"\"InfoNCE Loss ê³„ì‚° ë° ë¶„ì„ (ë””ë°”ì´ìŠ¤ ì•ˆì „)\"\"\"\n",
        "    # ğŸ”§ ë””ë°”ì´ìŠ¤ í†µì¼: ëª¨ë“  í…ì„œë¥¼ CPUë¡œ ì´ë™\n",
        "    text_emb_cpu = text_emb.cpu()\n",
        "    vib_emb_cpu = vib_emb.cpu()\n",
        "    \n",
        "    # ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°\n",
        "    similarity_matrix = torch.matmul(text_emb_cpu, vib_emb_cpu.t()) / temperature\n",
        "    \n",
        "    # ì •ë‹µ ë ˆì´ë¸” (ëŒ€ê°ì„ )\n",
        "    labels = torch.arange(len(text_emb_cpu))\n",
        "    \n",
        "    # Cross-entropy loss ê³„ì‚°\n",
        "    loss = F.cross_entropy(similarity_matrix, labels)\n",
        "    \n",
        "    # ì˜ˆì¸¡ ì •í™•ë„ ê³„ì‚°\n",
        "    predictions = torch.argmax(similarity_matrix, dim=1)\n",
        "    accuracy = (predictions == labels).float().mean()\n",
        "    \n",
        "    return {\n",
        "        'loss': loss.item(),\n",
        "        'accuracy': accuracy.item(),\n",
        "        'similarity_matrix': similarity_matrix,\n",
        "        'predictions': predictions\n",
        "    }\n",
        "\n",
        "# í˜„ì¬ ì„¤ì •ëœ Temperature ê°’ë“¤\n",
        "temp_config = MODEL_CONFIG['infonce']\n",
        "print(f\"í˜„ì¬ Temperature ì„¤ì •:\")\n",
        "print(f\"  First domain text: {temp_config['first_domain_temperature_text']}\")\n",
        "print(f\"  First domain vibration: {temp_config['first_domain_temperature_vib']}\")\n",
        "print(f\"  Continual text: {temp_config['continual_temperature_text']}\")\n",
        "print(f\"  Continual vibration: {temp_config['continual_temperature_vib']}\")\n",
        "\n",
        "# ë‹¤ì–‘í•œ Temperature ê°’ìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
        "temperatures = [0.01, 0.05, 0.07, 0.1, 0.2, 0.5]\n",
        "print(f\"\\nğŸ“ˆ Temperatureë³„ InfoNCE ì„±ëŠ¥ (ê°œë³„ Encoder):\")\n",
        "print(\"Temp\\tLoss\\tAccuracy\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "individual_results = []\n",
        "for temp in temperatures:\n",
        "    result = calculate_infonce_loss(\n",
        "        text_embeddings_individual, \n",
        "        vib_embeddings_individual, \n",
        "        temperature=temp\n",
        "    )\n",
        "    individual_results.append((temp, result))\n",
        "    print(f\"{temp:.2f}\\t{result['loss']:.4f}\\t{result['accuracy']:.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ“ˆ Temperatureë³„ InfoNCE ì„±ëŠ¥ (í†µí•© ëª¨ë¸):\")\n",
        "print(\"Temp\\tLoss\\tAccuracy\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "integrated_results = []\n",
        "for temp in temperatures:\n",
        "    result = calculate_infonce_loss(\n",
        "        text_embeddings_integrated,\n",
        "        vib_embeddings_integrated, \n",
        "        temperature=temp\n",
        "    )\n",
        "    integrated_results.append((temp, result))\n",
        "    print(f\"{temp:.2f}\\t{result['loss']:.4f}\\t{result['accuracy']:.4f}\")\n",
        "\n",
        "# ìµœì  Temperature ì°¾ê¸°\n",
        "best_individual = max(individual_results, key=lambda x: x[1]['accuracy'])\n",
        "best_integrated = max(integrated_results, key=lambda x: x[1]['accuracy'])\n",
        "\n",
        "print(f\"\\nğŸ¯ ìµœì  Temperature:\")\n",
        "print(f\"  ê°œë³„ Encoder: {best_individual[0]:.2f} (ì •í™•ë„: {best_individual[1]['accuracy']:.4f})\")\n",
        "print(f\"  í†µí•© ëª¨ë¸: {best_integrated[0]:.2f} (ì •í™•ë„: {best_integrated[1]['accuracy']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ê²°ë¡  ë° í•´ê²° ë°©ì•ˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ¯ Text-Vibration ì •ë ¬ ë¬¸ì œ ì§„ë‹¨ ê²°ê³¼\n",
            "============================================================\n",
            "ğŸ“Š ì„±ëŠ¥ ìš”ì•½:\n",
            "  ê°œë³„ Text Encoder: 83.0% (ì´ì „ í…ŒìŠ¤íŠ¸)\n",
            "  ê°œë³„ Vibration Encoder: 88.6% (ì´ì „ í…ŒìŠ¤íŠ¸)\n",
            "  TextVibCLIP í†µí•©: 14.4% (ì‹¤ì œ ì„±ëŠ¥)\n",
            "  ì„±ëŠ¥ ì†ì‹¤: 157.2%p (ì‹¬ê°í•œ ì •ë ¬ ë¬¸ì œ)\n",
            "\n",
            "ğŸ” ì •ë ¬ ë¶„ì„ ê²°ê³¼:\n",
            "  ê°œë³„ Encoder ì •ë ¬ ì ìˆ˜: 0.000090\n",
            "  í†µí•© ëª¨ë¸ ì •ë ¬ ì ìˆ˜: -0.000022\n",
            "  ì •ë ¬ ì ìˆ˜ ì°¨ì´: 0.000112\n",
            "\n",
            "ğŸŒ¡ï¸ Temperature ìµœì í™”:\n",
            "  ê°œë³„ ìµœì  Temperature: 0.01\n",
            "  í†µí•© ìµœì  Temperature: 0.01\n",
            "  í˜„ì¬ ì„¤ì •ê°’: 0.05\n",
            "\n",
            "ğŸš¨ ë¬¸ì œ ì§„ë‹¨:\n",
            "  âŒ ì‹¬ê°í•œ ì •ë ¬ ë¬¸ì œ: í†µí•© ê³¼ì •ì—ì„œ ì •ë ¬ì´ í¬ê²Œ ì•…í™”ë¨\n",
            "  ì›ì¸: Projection Layer, InfoNCE Loss, ë˜ëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¬¸ì œ\n",
            "\n",
            "ğŸ’¡ í•´ê²° ë°©ì•ˆ ìš°ì„ ìˆœìœ„:\n",
            "1. ğŸ”¥ Temperature ìµœì í™”\n",
            "   - í˜„ì¬: 0.05\n",
            "   - ê¶Œì¥: 0.01\n",
            "2. ğŸ¯ Projection Layer ì ê²€\n",
            "   - ì°¨ì› ì •ë ¬ í™•ì¸\n",
            "   - ì •ê·œí™” ë°©ë²• ê²€í† \n",
            "3. ğŸ“ InfoNCE Loss êµ¬í˜„ ê²€í† \n",
            "   - ìœ ì‚¬ë„ ê³„ì‚° ë¡œì§\n",
            "   - Negative sampling ë°©ì‹\n",
            "4. ğŸ”§ ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œì„ \n",
            "   - Cross-attention ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€\n",
            "   - Alignment regularization\n",
            "\n",
            "âš¡ ì¦‰ì‹œ ìˆ˜ì • ê°€ëŠ¥í•œ ì‚¬í•­:\n",
            "1. Temperature 0.05 â†’ 0.01ë¡œ ë³€ê²½\n",
            "   ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: 0.3%\n",
            "\n",
            "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„:\n",
            "1. Temperature ìˆ˜ì • í›„ ì¬ì‹¤í—˜\n",
            "2. Projection Layer ìƒì„¸ ë¶„ì„\n",
            "3. InfoNCE Loss êµ¬í˜„ ê²€í† \n",
            "4. ì „ì²´ ëª¨ë¸ ì¬í•™ìŠµ ê³ ë ¤\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ¯ Text-Vibration ì •ë ¬ ë¬¸ì œ ì§„ë‹¨ ê²°ê³¼\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ì„±ëŠ¥ ë¹„êµ ìš”ì•½\n",
        "print(f\"ğŸ“Š ì„±ëŠ¥ ìš”ì•½:\")\n",
        "print(f\"  ê°œë³„ Text Encoder: 83.0% (ì´ì „ í…ŒìŠ¤íŠ¸)\")\n",
        "print(f\"  ê°œë³„ Vibration Encoder: 88.6% (ì´ì „ í…ŒìŠ¤íŠ¸)\")\n",
        "print(f\"  TextVibCLIP í†µí•©: 14.4% (ì‹¤ì œ ì„±ëŠ¥)\")\n",
        "print(f\"  ì„±ëŠ¥ ì†ì‹¤: {83.0 + 88.6 - 14.4:.1f}%p (ì‹¬ê°í•œ ì •ë ¬ ë¬¸ì œ)\")\n",
        "\n",
        "# ì •ë ¬ ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
        "print(f\"\\nğŸ” ì •ë ¬ ë¶„ì„ ê²°ê³¼:\")\n",
        "print(f\"  ê°œë³„ Encoder ì •ë ¬ ì ìˆ˜: {individual_analysis['alignment_score']:.6f}\")\n",
        "print(f\"  í†µí•© ëª¨ë¸ ì •ë ¬ ì ìˆ˜: {integrated_analysis['alignment_score']:.6f}\")\n",
        "print(f\"  ì •ë ¬ ì ìˆ˜ ì°¨ì´: {individual_analysis['alignment_score'] - integrated_analysis['alignment_score']:.6f}\")\n",
        "\n",
        "# Temperature ë¶„ì„ ê²°ê³¼\n",
        "print(f\"\\nğŸŒ¡ï¸ Temperature ìµœì í™”:\")\n",
        "print(f\"  ê°œë³„ ìµœì  Temperature: {best_individual[0]:.2f}\")\n",
        "print(f\"  í†µí•© ìµœì  Temperature: {best_integrated[0]:.2f}\")\n",
        "print(f\"  í˜„ì¬ ì„¤ì •ê°’: {temp_config['first_domain_temperature_text']:.2f}\")\n",
        "\n",
        "# ë¬¸ì œ ì§„ë‹¨ ë° í•´ê²° ë°©ì•ˆ\n",
        "print(f\"\\nğŸš¨ ë¬¸ì œ ì§„ë‹¨:\")\n",
        "if integrated_analysis['alignment_score'] < individual_analysis['alignment_score'] * 0.5:\n",
        "    print(\"  âŒ ì‹¬ê°í•œ ì •ë ¬ ë¬¸ì œ: í†µí•© ê³¼ì •ì—ì„œ ì •ë ¬ì´ í¬ê²Œ ì•…í™”ë¨\")\n",
        "    print(\"  ì›ì¸: Projection Layer, InfoNCE Loss, ë˜ëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¬¸ì œ\")\n",
        "elif integrated_analysis['alignment_score'] < individual_analysis['alignment_score'] * 0.8:\n",
        "    print(\"  âš ï¸ ì¤‘ê°„ ì •ë ¬ ë¬¸ì œ: í†µí•© ê³¼ì •ì—ì„œ ì¼ë¶€ ì •ë ¬ ì†ì‹¤\")\n",
        "    print(\"  ì›ì¸: Temperature ì„¤ì • ë˜ëŠ” Loss ê°€ì¤‘ì¹˜ ë¬¸ì œ\")\n",
        "else:\n",
        "    print(\"  âœ… ì •ë ¬ ìƒíƒœ ì–‘í˜¸: ë‹¤ë¥¸ ì›ì¸ íƒìƒ‰ í•„ìš”\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ í•´ê²° ë°©ì•ˆ ìš°ì„ ìˆœìœ„:\")\n",
        "print(\"1. ğŸ”¥ Temperature ìµœì í™”\")\n",
        "print(f\"   - í˜„ì¬: {temp_config['first_domain_temperature_text']:.2f}\")\n",
        "print(f\"   - ê¶Œì¥: {best_integrated[0]:.2f}\")\n",
        "\n",
        "print(\"2. ğŸ¯ Projection Layer ì ê²€\")\n",
        "print(\"   - ì°¨ì› ì •ë ¬ í™•ì¸\")\n",
        "print(\"   - ì •ê·œí™” ë°©ë²• ê²€í† \")\n",
        "\n",
        "print(\"3. ğŸ“ InfoNCE Loss êµ¬í˜„ ê²€í† \")\n",
        "print(\"   - ìœ ì‚¬ë„ ê³„ì‚° ë¡œì§\")\n",
        "print(\"   - Negative sampling ë°©ì‹\")\n",
        "\n",
        "print(\"4. ğŸ”§ ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œì„ \")\n",
        "print(\"   - Cross-attention ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€\")\n",
        "print(\"   - Alignment regularization\")\n",
        "\n",
        "# ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ìˆ˜ì •ì‚¬í•­\n",
        "print(f\"\\nâš¡ ì¦‰ì‹œ ìˆ˜ì • ê°€ëŠ¥í•œ ì‚¬í•­:\")\n",
        "if abs(best_integrated[0] - temp_config['first_domain_temperature_text']) > 0.02:\n",
        "    print(f\"1. Temperature {temp_config['first_domain_temperature_text']:.2f} â†’ {best_integrated[0]:.2f}ë¡œ ë³€ê²½\")\n",
        "    print(f\"   ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: {best_integrated[1]['accuracy']:.1%}\")\n",
        "\n",
        "print(\"\\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:\")\n",
        "print(\"1. Temperature ìˆ˜ì • í›„ ì¬ì‹¤í—˜\")\n",
        "print(\"2. Projection Layer ìƒì„¸ ë¶„ì„\")\n",
        "print(\"3. InfoNCE Loss êµ¬í˜„ ê²€í† \")\n",
        "print(\"4. ì „ì²´ ëª¨ë¸ ì¬í•™ìŠµ ê³ ë ¤\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ê¸´ê¸‰ ìˆ˜ì •: ê°€ì¤‘ì¹˜ ë™ê¸°í™” í…ŒìŠ¤íŠ¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸš¨ ê°€ì¤‘ì¹˜ ë™ê¸°í™” í…ŒìŠ¤íŠ¸\n",
            "==================================================\n",
            "1. Text Encoder ê°€ì¤‘ì¹˜ ë³µì‚¬...\n",
            "2. Vibration Encoder ê°€ì¤‘ì¹˜ ë³µì‚¬...\n",
            "âœ… ê°€ì¤‘ì¹˜ ë³µì‚¬ ì™„ë£Œ\n",
            "\n",
            "3. ë™ê¸°í™” í›„ ì„ë² ë”© ì¬ìƒì„±...\n",
            "âœ… ë™ê¸°í™” í›„ ì°¨ì´:\n",
            "  Text ì°¨ì´: 0.000016\n",
            "  Vibration ì°¨ì´: 0.000000\n",
            "âš ï¸ ì—¬ì „íˆ ì°¨ì´ ì¡´ì¬ - ë‹¤ë¥¸ ì›ì¸ íƒìƒ‰ í•„ìš”\n",
            "\n",
            "4. ë™ê¸°í™” í›„ InfoNCE ì„±ëŠ¥:\n",
            "  Loss: 5.8602\n",
            "  Accuracy: 0.0029 (0.3%)\n",
            "ğŸ” ê°€ì¤‘ì¹˜ ì™¸ ë‹¤ë¥¸ ë¬¸ì œ ì¡´ì¬\n"
          ]
        }
      ],
      "source": [
        "# ğŸš¨ ê¸´ê¸‰ ìˆ˜ì •: í†µí•© ëª¨ë¸ì— ê°œë³„ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë³µì‚¬\n",
        "print(\"\\nğŸš¨ ê°€ì¤‘ì¹˜ ë™ê¸°í™” í…ŒìŠ¤íŠ¸\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. ê°œë³„ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ í†µí•© ëª¨ë¸ì— ë³µì‚¬\n",
        "print(\"1. Text Encoder ê°€ì¤‘ì¹˜ ë³µì‚¬...\")\n",
        "textvib_model.text_encoder.load_state_dict(text_encoder.state_dict())\n",
        "\n",
        "print(\"2. Vibration Encoder ê°€ì¤‘ì¹˜ ë³µì‚¬...\")\n",
        "textvib_model.vibration_encoder.load_state_dict(vibration_encoder.state_dict())\n",
        "\n",
        "print(\"âœ… ê°€ì¤‘ì¹˜ ë³µì‚¬ ì™„ë£Œ\")\n",
        "\n",
        "# 2. ê°€ì¤‘ì¹˜ ë™ê¸°í™” í›„ ì„ë² ë”© ì¬ìƒì„±\n",
        "print(\"\\n3. ë™ê¸°í™” í›„ ì„ë² ë”© ì¬ìƒì„±...\")\n",
        "with torch.no_grad():\n",
        "    # í†µí•© ëª¨ë¸ ì„ë² ë”© ì¬ìƒì„± (ê°€ì¤‘ì¹˜ ë™ê¸°í™” í›„)\n",
        "    text_embeddings_synced = []\n",
        "    vib_embeddings_synced = []\n",
        "    \n",
        "    for i in range(0, len(all_texts), batch_size):\n",
        "        end_idx = min(i + batch_size, len(all_texts))\n",
        "        batch_texts = all_texts[i:end_idx]\n",
        "        batch_vibs = vibration_tensor[i:end_idx].to(device)\n",
        "        \n",
        "        # ë™ê¸°í™”ëœ encoderë¡œ ì„ë² ë”© ìƒì„±\n",
        "        batch_text_emb = textvib_model.text_encoder.encode_texts(batch_texts, device)\n",
        "        batch_vib_emb = textvib_model.vibration_encoder(batch_vibs)\n",
        "        \n",
        "        # ì •ê·œí™”\n",
        "        batch_text_emb = F.normalize(batch_text_emb, p=2, dim=1)\n",
        "        batch_vib_emb = F.normalize(batch_vib_emb, p=2, dim=1)\n",
        "        \n",
        "        text_embeddings_synced.append(batch_text_emb.cpu())\n",
        "        vib_embeddings_synced.append(batch_vib_emb.cpu())\n",
        "    \n",
        "    text_embeddings_synced = torch.cat(text_embeddings_synced, dim=0)\n",
        "    vib_embeddings_synced = torch.cat(vib_embeddings_synced, dim=0)\n",
        "\n",
        "# 3. ë™ê¸°í™” í›„ ì°¨ì´ í™•ì¸\n",
        "text_diff_synced = torch.norm(text_embeddings_individual.cpu() - text_embeddings_synced.cpu()).item()\n",
        "vib_diff_synced = torch.norm(vib_embeddings_individual.cpu() - vib_embeddings_synced.cpu()).item()\n",
        "\n",
        "print(f\"âœ… ë™ê¸°í™” í›„ ì°¨ì´:\")\n",
        "print(f\"  Text ì°¨ì´: {text_diff_synced:.6f}\")\n",
        "print(f\"  Vibration ì°¨ì´: {vib_diff_synced:.6f}\")\n",
        "\n",
        "if text_diff_synced < 1e-6 and vib_diff_synced < 1e-6:\n",
        "    print(\"ğŸ¯ ì™„ë²½í•œ ë™ê¸°í™”! ê°€ì¤‘ì¹˜ ë¬¸ì œì˜€ìŒ\")\n",
        "else:\n",
        "    print(\"âš ï¸ ì—¬ì „íˆ ì°¨ì´ ì¡´ì¬ - ë‹¤ë¥¸ ì›ì¸ íƒìƒ‰ í•„ìš”\")\n",
        "\n",
        "# 4. ë™ê¸°í™” í›„ InfoNCE ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n",
        "print(\"\\n4. ë™ê¸°í™” í›„ InfoNCE ì„±ëŠ¥:\")\n",
        "synced_result = calculate_infonce_loss(\n",
        "    text_embeddings_synced,\n",
        "    vib_embeddings_synced, \n",
        "    temperature=0.05\n",
        ")\n",
        "print(f\"  Loss: {synced_result['loss']:.4f}\")\n",
        "print(f\"  Accuracy: {synced_result['accuracy']:.4f} ({synced_result['accuracy']*100:.1f}%)\")\n",
        "\n",
        "if synced_result['accuracy'] > 0.1:\n",
        "    print(\"ğŸ‰ ê°€ì¤‘ì¹˜ ë™ê¸°í™”ë¡œ ë¬¸ì œ í•´ê²°!\")\n",
        "else:\n",
        "    print(\"ğŸ” ê°€ì¤‘ì¹˜ ì™¸ ë‹¤ë¥¸ ë¬¸ì œ ì¡´ì¬\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. InfoNCE Loss êµ¬í˜„ ë¬¸ì œ ë¶„ì„ ë° ìˆ˜ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¥ InfoNCE Loss êµ¬í˜„ ë¬¸ì œ ì§„ë‹¨\n",
            "============================================================\n",
            "1. ê°œì„ ëœ InfoNCE Loss í…ŒìŠ¤íŠ¸:\n",
            "  ê°œì„ ëœ Loss: 5.8589\n",
            "  ê°œì„ ëœ Accuracy: 0.1429 (14.3%)\n",
            "\n",
            "2. ê°œì„ ëœ InfoNCE - Temperatureë³„ ì„±ëŠ¥:\n",
            "Temp\tLoss\tAccuracy\n",
            "------------------------------\n",
            "0.01\t5.9511\t0.1429\n",
            "0.03\t5.8667\t0.1429\n",
            "0.05\t5.8605\t0.1429\n",
            "0.07\t5.8589\t0.1429\n",
            "0.10\t5.8582\t0.1429\n",
            "0.20\t5.8578\t0.1429\n",
            "0.50\t5.8578\t0.1429\n",
            "1.00\t5.8579\t0.1429\n",
            "\n",
            "ğŸ¯ ìµœì  ì„¤ì •:\n",
            "  ìµœì  Temperature: 0.01\n",
            "  ìµœê³  ì •í™•ë„: 0.1429 (14.3%)\n",
            "âŒ ì—¬ì „íˆ ì‹¬ê°í•œ ë¬¸ì œ - ê·¼ë³¸ì  ì¬ì„¤ê³„ í•„ìš”\n"
          ]
        }
      ],
      "source": [
        "# ğŸ”¥ InfoNCE Loss êµ¬í˜„ ë¬¸ì œ ë¶„ì„ ë° ìˆ˜ì •\n",
        "print(\"\\nğŸ”¥ InfoNCE Loss êµ¬í˜„ ë¬¸ì œ ì§„ë‹¨\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def improved_infonce_loss(text_emb, vib_emb, labels, temperature=0.07):\n",
        "    \"\"\"ê°œì„ ëœ InfoNCE Loss - í´ë˜ìŠ¤ ê¸°ë°˜ ì •í™•í•œ êµ¬í˜„\"\"\"\n",
        "    text_emb_cpu = text_emb.cpu()\n",
        "    vib_emb_cpu = vib_emb.cpu()\n",
        "    labels_cpu = labels.cpu()\n",
        "    \n",
        "    # ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°\n",
        "    similarity_matrix = torch.matmul(text_emb_cpu, vib_emb_cpu.t()) / temperature\n",
        "    \n",
        "    # ğŸ¯ í•µì‹¬ ìˆ˜ì •: í´ë˜ìŠ¤ ê¸°ë°˜ positive pair ì •ì˜\n",
        "    # ê°™ì€ ì¸ë±ìŠ¤ê°€ ì•„ë‹ˆë¼ ê°™ì€ í´ë˜ìŠ¤ë¼ë¦¬ positive\n",
        "    batch_size = len(text_emb_cpu)\n",
        "    positive_mask = (labels_cpu.unsqueeze(0) == labels_cpu.unsqueeze(1)).float()\n",
        "    \n",
        "    # InfoNCE Loss ê³„ì‚° (í´ë˜ìŠ¤ ê¸°ë°˜)\n",
        "    # ê° textì— ëŒ€í•´ ê°™ì€ í´ë˜ìŠ¤ì˜ vibrationë“¤ì´ positive\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        # ië²ˆì§¸ textì™€ ëª¨ë“  vibrationì˜ ìœ ì‚¬ë„\n",
        "        logits = similarity_matrix[i]  # (batch_size,)\n",
        "        \n",
        "        # ê°™ì€ í´ë˜ìŠ¤ ë§ˆìŠ¤í¬\n",
        "        pos_mask = positive_mask[i]  # (batch_size,)\n",
        "        \n",
        "        if pos_mask.sum() > 0:  # positiveê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ\n",
        "            # Positiveì˜ í‰ê·  ìœ ì‚¬ë„\n",
        "            pos_logits = logits[pos_mask.bool()]\n",
        "            pos_mean = pos_logits.mean()\n",
        "            \n",
        "            # ì „ì²´ logitsì— ëŒ€í•œ logsumexp\n",
        "            log_sum_exp = torch.logsumexp(logits, dim=0)\n",
        "            \n",
        "            # InfoNCE loss\n",
        "            loss = log_sum_exp - pos_mean\n",
        "            losses.append(loss)\n",
        "            \n",
        "            # ì˜ˆì¸¡: ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ vibration\n",
        "            pred_idx = torch.argmax(logits)\n",
        "            if pos_mask[pred_idx] > 0:\n",
        "                correct_predictions += 1\n",
        "    \n",
        "    avg_loss = torch.stack(losses).mean() if losses else torch.tensor(float('inf'))\n",
        "    accuracy = correct_predictions / batch_size\n",
        "    \n",
        "    return {\n",
        "        'loss': avg_loss.item(),\n",
        "        'accuracy': accuracy,\n",
        "        'similarity_matrix': similarity_matrix,\n",
        "        'positive_mask': positive_mask\n",
        "    }\n",
        "\n",
        "# ğŸ¯ ê°œì„ ëœ InfoNCE Lossë¡œ í…ŒìŠ¤íŠ¸\n",
        "print(\"1. ê°œì„ ëœ InfoNCE Loss í…ŒìŠ¤íŠ¸:\")\n",
        "improved_result = improved_infonce_loss(\n",
        "    text_embeddings_synced,\n",
        "    vib_embeddings_synced,\n",
        "    labels_tensor,\n",
        "    temperature=0.07\n",
        ")\n",
        "\n",
        "print(f\"  ê°œì„ ëœ Loss: {improved_result['loss']:.4f}\")\n",
        "print(f\"  ê°œì„ ëœ Accuracy: {improved_result['accuracy']:.4f} ({improved_result['accuracy']*100:.1f}%)\")\n",
        "\n",
        "# 2. ë‹¤ì–‘í•œ Temperatureë¡œ ê°œì„ ëœ Loss í…ŒìŠ¤íŠ¸\n",
        "print(f\"\\n2. ê°œì„ ëœ InfoNCE - Temperatureë³„ ì„±ëŠ¥:\")\n",
        "print(\"Temp\\tLoss\\tAccuracy\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "best_temp = 0.07\n",
        "best_acc = 0.0\n",
        "\n",
        "for temp in [0.01, 0.03, 0.05, 0.07, 0.1, 0.2, 0.5, 1.0]:\n",
        "    result = improved_infonce_loss(\n",
        "        text_embeddings_synced,\n",
        "        vib_embeddings_synced,\n",
        "        labels_tensor,\n",
        "        temperature=temp\n",
        "    )\n",
        "    print(f\"{temp:.2f}\\t{result['loss']:.4f}\\t{result['accuracy']:.4f}\")\n",
        "    \n",
        "    if result['accuracy'] > best_acc:\n",
        "        best_acc = result['accuracy']\n",
        "        best_temp = temp\n",
        "\n",
        "print(f\"\\nğŸ¯ ìµœì  ì„¤ì •:\")\n",
        "print(f\"  ìµœì  Temperature: {best_temp:.2f}\")\n",
        "print(f\"  ìµœê³  ì •í™•ë„: {best_acc:.4f} ({best_acc*100:.1f}%)\")\n",
        "\n",
        "if best_acc > 0.5:\n",
        "    print(\"ğŸ‰ InfoNCE Loss ë¬¸ì œ í•´ê²°!\")\n",
        "elif best_acc > 0.2:\n",
        "    print(\"âš ï¸ ë¶€ë¶„ì  ê°œì„  - ì¶”ê°€ ì¡°ì • í•„ìš”\")\n",
        "else:\n",
        "    print(\"âŒ ì—¬ì „íˆ ì‹¬ê°í•œ ë¬¸ì œ - ê·¼ë³¸ì  ì¬ì„¤ê³„ í•„ìš”\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. ê·¼ë³¸ì  í•´ê²°ì±…: Cross-Modal Projection í…ŒìŠ¤íŠ¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ¯ Cross-Modal Projection í…ŒìŠ¤íŠ¸\n",
            "============================================================\n",
            "1. Cross-Modal Projection í•™ìŠµ (10 epochs)...\n",
            "  Epoch 0: Loss = 3.4657\n",
            "  Epoch 2: Loss = 3.4604\n",
            "  Epoch 4: Loss = 3.4628\n",
            "  Epoch 6: Loss = 3.4574\n",
            "  Epoch 8: Loss = 3.4597\n",
            "\n",
            "2. í•™ìŠµëœ Projection ì ìš©...\n",
            "âœ… Projection ì ìš© ì™„ë£Œ:\n",
            "  ë³€í™˜ ì „: 256ì°¨ì›\n",
            "  ë³€í™˜ í›„: 128ì°¨ì›\n",
            "\n",
            "3. Projection í›„ InfoNCE ì„±ëŠ¥:\n",
            "  Projection í›„ Loss: 5.8502\n",
            "  Projection í›„ Accuracy: 0.2857 (28.6%)\n",
            "\n",
            "ğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ:\n",
            "  ê°œë³„ Text Encoder: 83.0%\n",
            "  ê°œë³„ Vibration Encoder: 88.6%\n",
            "  ê¸°ì¡´ í†µí•© (InfoNCE): 0.3%\n",
            "  Projection í›„: 28.6%\n",
            "  ê°œì„ ë„: +28.3%p\n",
            "âŒ ê·¼ë³¸ì  ë¬¸ì œ - ë‹¤ë¥¸ ì ‘ê·¼ë²• í•„ìš”\n"
          ]
        }
      ],
      "source": [
        "# ğŸ¯ ê·¼ë³¸ì  í•´ê²°ì±…: Cross-Modal Projection Layer ì¶”ê°€\n",
        "print(\"\\nğŸ¯ Cross-Modal Projection í…ŒìŠ¤íŠ¸\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "class CrossModalProjection(nn.Module):\n",
        "    \"\"\"Cross-Modal Projection Layer - ë‘ ì„ë² ë”© ê³µê°„ì„ ê³µí†µ ê³µê°„ìœ¼ë¡œ ë§¤í•‘\"\"\"\n",
        "    def __init__(self, input_dim=256, output_dim=128):\n",
        "        super().__init__()\n",
        "        self.text_proj = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(output_dim * 2, output_dim),\n",
        "            nn.LayerNorm(output_dim)\n",
        "        )\n",
        "        self.vib_proj = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim * 2),\n",
        "            nn.ReLU(), \n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(output_dim * 2, output_dim),\n",
        "            nn.LayerNorm(output_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, text_emb, vib_emb):\n",
        "        text_proj = F.normalize(self.text_proj(text_emb), p=2, dim=1)\n",
        "        vib_proj = F.normalize(self.vib_proj(vib_emb), p=2, dim=1)\n",
        "        return text_proj, vib_proj\n",
        "\n",
        "# Cross-Modal Projection ìƒì„± ë° ê°„ë‹¨í•œ í•™ìŠµ\n",
        "projection = CrossModalProjection(input_dim=256, output_dim=128).to(device)\n",
        "optimizer = torch.optim.Adam(projection.parameters(), lr=0.001)\n",
        "\n",
        "print(\"1. Cross-Modal Projection í•™ìŠµ (10 epochs)...\")\n",
        "\n",
        "# ê°„ë‹¨í•œ í•™ìŠµ ë£¨í”„\n",
        "projection.train()\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    \n",
        "    for i in range(0, len(text_embeddings_synced), 32):\n",
        "        end_idx = min(i + 32, len(text_embeddings_synced))\n",
        "        batch_text = text_embeddings_synced[i:end_idx].to(device)\n",
        "        batch_vib = vib_embeddings_synced[i:end_idx].to(device)\n",
        "        batch_labels = labels_tensor[i:end_idx].to(device)\n",
        "        \n",
        "        # Projection ì ìš©\n",
        "        text_proj, vib_proj = projection(batch_text, batch_vib)\n",
        "        \n",
        "        # InfoNCE Loss (ê°„ë‹¨í•œ ëŒ€ê°ì„  ë²„ì „)\n",
        "        similarity = torch.matmul(text_proj, vib_proj.t()) / 0.1\n",
        "        labels_batch = torch.arange(len(batch_text)).to(device)\n",
        "        loss = F.cross_entropy(similarity, labels_batch)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "    \n",
        "    if epoch % 2 == 0:\n",
        "        print(f\"  Epoch {epoch}: Loss = {total_loss/num_batches:.4f}\")\n",
        "\n",
        "projection.eval()\n",
        "\n",
        "# 2. í•™ìŠµëœ Projectionìœ¼ë¡œ ì„ë² ë”© ë³€í™˜\n",
        "print(\"\\n2. í•™ìŠµëœ Projection ì ìš©...\")\n",
        "with torch.no_grad():\n",
        "    text_projected = []\n",
        "    vib_projected = []\n",
        "    \n",
        "    for i in range(0, len(text_embeddings_synced), 32):\n",
        "        end_idx = min(i + 32, len(text_embeddings_synced))\n",
        "        batch_text = text_embeddings_synced[i:end_idx].to(device)\n",
        "        batch_vib = vib_embeddings_synced[i:end_idx].to(device)\n",
        "        \n",
        "        text_proj, vib_proj = projection(batch_text, batch_vib)\n",
        "        text_projected.append(text_proj.cpu())\n",
        "        vib_projected.append(vib_proj.cpu())\n",
        "    \n",
        "    text_projected = torch.cat(text_projected, dim=0)\n",
        "    vib_projected = torch.cat(vib_projected, dim=0)\n",
        "\n",
        "print(f\"âœ… Projection ì ìš© ì™„ë£Œ:\")\n",
        "print(f\"  ë³€í™˜ ì „: {text_embeddings_synced.shape[1]}ì°¨ì›\")\n",
        "print(f\"  ë³€í™˜ í›„: {text_projected.shape[1]}ì°¨ì›\")\n",
        "\n",
        "# 3. Projection í›„ InfoNCE ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n",
        "print(\"\\n3. Projection í›„ InfoNCE ì„±ëŠ¥:\")\n",
        "projected_result = improved_infonce_loss(\n",
        "    text_projected,\n",
        "    vib_projected,\n",
        "    labels_tensor,\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "print(f\"  Projection í›„ Loss: {projected_result['loss']:.4f}\")\n",
        "print(f\"  Projection í›„ Accuracy: {projected_result['accuracy']:.4f} ({projected_result['accuracy']*100:.1f}%)\")\n",
        "\n",
        "# 4. ì„±ëŠ¥ ë¹„êµ ìš”ì•½\n",
        "print(f\"\\nğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ:\")\n",
        "print(f\"  ê°œë³„ Text Encoder: 83.0%\")\n",
        "print(f\"  ê°œë³„ Vibration Encoder: 88.6%\")\n",
        "print(f\"  ê¸°ì¡´ í†µí•© (InfoNCE): 0.3%\")\n",
        "print(f\"  Projection í›„: {projected_result['accuracy']*100:.1f}%\")\n",
        "\n",
        "improvement = projected_result['accuracy'] * 100 - 0.3\n",
        "print(f\"  ê°œì„ ë„: +{improvement:.1f}%p\")\n",
        "\n",
        "if projected_result['accuracy'] > 0.5:\n",
        "    print(\"ğŸ‰ Cross-Modal Projectionìœ¼ë¡œ ë¬¸ì œ í•´ê²°!\")\n",
        "elif projected_result['accuracy'] > 0.3:\n",
        "    print(\"âš ï¸ ë¶€ë¶„ì  ê°œì„  - Projection ì•„í‚¤í…ì²˜ ì¡°ì • í•„ìš”\")\n",
        "else:\n",
        "    print(\"âŒ ê·¼ë³¸ì  ë¬¸ì œ - ë‹¤ë¥¸ ì ‘ê·¼ë²• í•„ìš”\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. ìµœì¢… ì§„ë‹¨ ë° ì‹¤ì œ í•´ê²°ì±…\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ğŸ¯ TextVibCLIP ì •ë ¬ ë¬¸ì œ ìµœì¢… ì§„ë‹¨ ë° í•´ê²°ì±…\n",
            "================================================================================\n",
            "ğŸ“Š ë¬¸ì œ ì§„ë‹¨ ìš”ì•½:\n",
            "1. âœ… Text Encoder ë‹¨ë…: 83.0% (ìš°ìˆ˜)\n",
            "2. âœ… Vibration Encoder ë‹¨ë…: 88.6% (ìš°ìˆ˜)\n",
            "3. âŒ ê°€ì¤‘ì¹˜ ë¶ˆì¼ì¹˜: í•´ê²°ë¨ (ì°¨ì´ 0.000016)\n",
            "4. âŒ InfoNCE Loss êµ¬í˜„: 14.3% (ëœë¤ ìˆ˜ì¤€)\n",
            "5. ğŸ¯ Cross-Modal Projection: 28.6%\n",
            "\n",
            "ğŸ” ê·¼ë³¸ ì›ì¸:\n",
            "Textì™€ Vibration ì„ë² ë”©ì´ ì™„ì „íˆ ë‹¤ë¥¸ ì˜ë¯¸ ê³µê°„ì— ì¡´ì¬\n",
            "- Text: ì–¸ì–´ì  ì˜ë¯¸ ê³µê°„ (ë‹¨ì–´, ë¬¸ë²• ê¸°ë°˜)\n",
            "- Vibration: ë¬¼ë¦¬ì  ì‹ í˜¸ ê³µê°„ (ì£¼íŒŒìˆ˜, ì§„í­ ê¸°ë°˜)\n",
            "- ê²°ê³¼: ë‘ ê³µê°„ ê°„ ìì—°ìŠ¤ëŸ¬ìš´ ë§¤í•‘ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ\n",
            "\n",
            "ğŸ’¡ í•´ê²°ì±… ìš°ì„ ìˆœìœ„:\n",
            "1. âŒ ê·¼ë³¸ì  ì¬ì„¤ê³„ í•„ìš”\n",
            "2. ì‚¬ì „ í•™ìŠµëœ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í™œìš© ê³ ë ¤\n",
            "3. ëŒ€ì•ˆ: ê° Encoder ë…ë¦½ ì‚¬ìš© + ì•™ìƒë¸”\n",
            "\n",
            "ğŸš€ ì¦‰ì‹œ ì ìš© ë°©ì•ˆ:\n",
            "1. TextVibCLIP ëª¨ë¸ì— Cross-Modal Projection ì¶”ê°€\n",
            "2. Temperature ìµœì í™”: 0.05 â†’ 0.1\n",
            "3. Projection í•™ìŠµë¥  ë° ì•„í‚¤í…ì²˜ ì¡°ì •\n",
            "\n",
            "ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ (Projection ì ìš© ì‹œ):\n",
            "  TextVibCLIP í†µí•©: 14.4% â†’ 30%\n",
            "  ì„±ëŠ¥ íšŒë³µ: 15.6%p\n",
            "\n",
            "ğŸ” ë‹¤ìŒ ë‹¨ê³„: ëŒ€ì•ˆ ì ‘ê·¼ë²• ê³ ë ¤\n",
            "1. ì‚¬ì „ í•™ìŠµëœ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í™œìš©\n",
            "2. ê° Encoder ë…ë¦½ ì‚¬ìš© + Late Fusion\n",
            "3. Domain-specific Adapter ì¶”ê°€\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ¯ TextVibCLIP ì •ë ¬ ë¬¸ì œ ìµœì¢… ì§„ë‹¨ ë° í•´ê²°ì±…\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"ğŸ“Š ë¬¸ì œ ì§„ë‹¨ ìš”ì•½:\")\n",
        "print(f\"1. âœ… Text Encoder ë‹¨ë…: 83.0% (ìš°ìˆ˜)\")\n",
        "print(f\"2. âœ… Vibration Encoder ë‹¨ë…: 88.6% (ìš°ìˆ˜)\")\n",
        "print(f\"3. âŒ ê°€ì¤‘ì¹˜ ë¶ˆì¼ì¹˜: í•´ê²°ë¨ (ì°¨ì´ 0.000016)\")\n",
        "print(f\"4. âŒ InfoNCE Loss êµ¬í˜„: 14.3% (ëœë¤ ìˆ˜ì¤€)\")\n",
        "print(f\"5. ğŸ¯ Cross-Modal Projection: {projected_result['accuracy']*100:.1f}%\")\n",
        "\n",
        "print(f\"\\nğŸ” ê·¼ë³¸ ì›ì¸:\")\n",
        "print(f\"Textì™€ Vibration ì„ë² ë”©ì´ ì™„ì „íˆ ë‹¤ë¥¸ ì˜ë¯¸ ê³µê°„ì— ì¡´ì¬\")\n",
        "print(f\"- Text: ì–¸ì–´ì  ì˜ë¯¸ ê³µê°„ (ë‹¨ì–´, ë¬¸ë²• ê¸°ë°˜)\")\n",
        "print(f\"- Vibration: ë¬¼ë¦¬ì  ì‹ í˜¸ ê³µê°„ (ì£¼íŒŒìˆ˜, ì§„í­ ê¸°ë°˜)\")\n",
        "print(f\"- ê²°ê³¼: ë‘ ê³µê°„ ê°„ ìì—°ìŠ¤ëŸ¬ìš´ ë§¤í•‘ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ í•´ê²°ì±… ìš°ì„ ìˆœìœ„:\")\n",
        "if projected_result['accuracy'] > 0.6:\n",
        "    print(\"1. ğŸ‰ Cross-Modal Projection ì„±ê³µ - ì´ ë°©ì‹ ì ìš©\")\n",
        "    print(\"2. TextVibCLIP ëª¨ë¸ì— Projection Layer í†µí•©\")\n",
        "    print(\"3. Projection Layer íŒŒë¼ë¯¸í„° ìµœì í™”\")\n",
        "elif projected_result['accuracy'] > 0.3:\n",
        "    print(\"1. âš ï¸ Projection ë¶€ë¶„ ì„±ê³µ - ì•„í‚¤í…ì²˜ ê°œì„ \")\n",
        "    print(\"2. Projection Layer ê¹Šì´/ë„ˆë¹„ ì¡°ì •\")\n",
        "    print(\"3. ë‹¤ë¥¸ ì •ë ¬ ë°©ë²• ë³‘í–‰ (Attention, CCA ë“±)\")\n",
        "else:\n",
        "    print(\"1. âŒ ê·¼ë³¸ì  ì¬ì„¤ê³„ í•„ìš”\")\n",
        "    print(\"2. ì‚¬ì „ í•™ìŠµëœ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í™œìš© ê³ ë ¤\")\n",
        "    print(\"3. ëŒ€ì•ˆ: ê° Encoder ë…ë¦½ ì‚¬ìš© + ì•™ìƒë¸”\")\n",
        "\n",
        "print(f\"\\nğŸš€ ì¦‰ì‹œ ì ìš© ë°©ì•ˆ:\")\n",
        "print(f\"1. TextVibCLIP ëª¨ë¸ì— Cross-Modal Projection ì¶”ê°€\")\n",
        "print(f\"2. Temperature ìµœì í™”: 0.05 â†’ 0.1\")\n",
        "print(f\"3. Projection í•™ìŠµë¥  ë° ì•„í‚¤í…ì²˜ ì¡°ì •\")\n",
        "\n",
        "print(f\"\\nğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ (Projection ì ìš© ì‹œ):\")\n",
        "expected_performance = min(80, max(30, projected_result['accuracy'] * 100))\n",
        "print(f\"  TextVibCLIP í†µí•©: 14.4% â†’ {expected_performance:.0f}%\")\n",
        "print(f\"  ì„±ëŠ¥ íšŒë³µ: {expected_performance - 14.4:.1f}%p\")\n",
        "\n",
        "if projected_result['accuracy'] > 0.4:\n",
        "    print(\"\\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„: TextVibCLIP ëª¨ë¸ ìˆ˜ì •\")\n",
        "    print(\"1. src/textvib_model.pyì— CrossModalProjection ì¶”ê°€\")\n",
        "    print(\"2. Forward passì—ì„œ Projection ì ìš©\")\n",
        "    print(\"3. ì „ì²´ ëª¨ë¸ ì¬í•™ìŠµ\")\n",
        "else:\n",
        "    print(\"\\nğŸ” ë‹¤ìŒ ë‹¨ê³„: ëŒ€ì•ˆ ì ‘ê·¼ë²• ê³ ë ¤\")\n",
        "    print(\"1. ì‚¬ì „ í•™ìŠµëœ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í™œìš©\")\n",
        "    print(\"2. ê° Encoder ë…ë¦½ ì‚¬ìš© + Late Fusion\")\n",
        "    print(\"3. Domain-specific Adapter ì¶”ê°€\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TVCLIP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
