#!/usr/bin/env python3
"""
TextVibCLIP ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ í†µí•© ì‹¤í—˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
1. ì‹œë‚˜ë¦¬ì˜¤ 1 (UOS) + ì‹œë‚˜ë¦¬ì˜¤ 2 (CWRU) ìë™ ì‹¤í–‰
2. ì‹œë‚˜ë¦¬ì˜¤ë³„/ë„ë©”ì¸ë³„ ì„±ëŠ¥ ì§€í‘œ CSV ì €ì¥
3. ì¢…í•© ê²°ê³¼ ìš”ì•½ ë° ë¹„êµ ë¶„ì„
4. ì‹¤í—˜ ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

Usage:
    python run_all_scenarios.py --output_dir results_comparison
    python run_all_scenarios.py --quick_test --epochs 10
"""

import argparse
import logging
import os
import torch
import time
import json
from datetime import datetime
from typing import Dict, List, Any
import numpy as np
import warnings

# Torchvision beta warning ë¹„í™œì„±í™”
try:
    import torchvision
    torchvision.disable_beta_transforms_warning()
except:
    pass

# ê¸°íƒ€ warning ì–µì œ
warnings.filterwarnings("ignore", category=UserWarning, module="torchvision")

# pandas import (CSV ì €ì¥ìš©)
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    print("âš ï¸ pandasê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CSV ì €ì¥ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
    print("   ì„¤ì¹˜: pip install pandas")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
import sys
from pathlib import Path
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

from src.continual_trainer import ContinualTrainer
from src.data_loader import BearingDataset, create_domain_dataloaders
from src.textvib_model import create_textvib_model
from src.utils import set_seed
from src.visualization import create_visualizer
from configs.model_config import TRAINING_CONFIG, DATA_CONFIG, CWRU_DATA_CONFIG

# ë¡œê¹… ì„¤ì •
def setup_logging(log_dir: str) -> logging.Logger:
    """í†µí•© ì‹¤í—˜ìš© ë¡œê¹… ì„¤ì •"""
    os.makedirs(log_dir, exist_ok=True)
    
    log_filename = f"all_scenarios_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    log_path = os.path.join(log_dir, log_filename)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_path),
            logging.StreamHandler()
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"í†µí•© ì‹¤í—˜ ë¡œê¹… ì‹œì‘: {log_path}")
    return logger


class ScenarioConfig:
    """ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„¤ì • ê´€ë¦¬"""
    
    UOS_CONFIG = {
        'name': 'UOS_Scenario1_VaryingSpeed',
        'data_dir': 'data_scenario1',
        'dataset_type': 'uos',
        'domain_order': [600, 800, 1000, 1200, 1400, 1600],
        'domain_names': ['600RPM', '800RPM', '1000RPM', '1200RPM', '1400RPM', '1600RPM'],
        'shift_type': 'Varying Speed',
        'first_domain_epochs': 30,  # ë°ì´í„° ë§ìŒ
        'remaining_epochs': 20,
        'batch_size': 32,
        'replay_buffer_size': 1000,
        'patience': 5
    }
    
    CWRU_CONFIG = {
        'name': 'CWRU_Scenario2_VaryingLoad',
        'data_dir': 'data_scenario2',
        'dataset_type': 'cwru',
        'domain_order': [0, 1, 2, 3],
        'domain_names': ['0HP', '1HP', '2HP', '3HP'],
        'shift_type': 'Varying Load',
        'first_domain_epochs': 80,  # ë°ì´í„° ì ìŒ
        'remaining_epochs': 50,
        'batch_size': 8,
        'replay_buffer_size': 200,
        'patience': 15
    }


class ExperimentResults:
    """ì‹¤í—˜ ê²°ê³¼ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.scenario_results = {}
        self.detailed_results = []
        self.summary_results = []
    
    def add_scenario_result(self, scenario_name: str, results: Dict):
        """ì‹œë‚˜ë¦¬ì˜¤ ê²°ê³¼ ì¶”ê°€"""
        self.scenario_results[scenario_name] = results
        
        # ìƒì„¸ ê²°ê³¼ ì¶”ê°€ (ë„ë©”ì¸ë³„)
        for domain_idx, domain_name in enumerate(results['domain_names']):
            if domain_idx < len(results['final_accuracies']):
                self.detailed_results.append({
                    'Scenario': scenario_name,
                    'Domain_Index': domain_idx + 1,
                    'Domain_Name': domain_name,
                    'Shift_Type': results['shift_type'],
                    'Accuracy': results['final_accuracies'][domain_idx],
                    'Top1_Retrieval': results.get('final_top1_retrievals', [0] * len(results['domain_names']))[domain_idx],
                    'Top5_Retrieval': results.get('final_top5_retrievals', [0] * len(results['domain_names']))[domain_idx],
                    'Samples_Per_Domain': results.get('samples_per_domain', 0),
                    'Total_Training_Time': results.get('total_time', 0)
                })
        
        # ìš”ì•½ ê²°ê³¼ ì¶”ê°€ (ì‹œë‚˜ë¦¬ì˜¤ë³„)
        self.summary_results.append({
            'Scenario': scenario_name,
            'Shift_Type': results['shift_type'],
            'Num_Domains': len(results['domain_names']),
            'Avg_Accuracy': results.get('average_accuracy', 0),
            'Avg_Forgetting': results.get('average_forgetting', 0),
            'Avg_Top1_Retrieval': np.mean(results.get('final_top1_retrievals', [0])),
            'Avg_Top5_Retrieval': np.mean(results.get('final_top5_retrievals', [0])),
            'Total_Samples': results.get('total_samples', 0),
            'Total_Time_Minutes': results.get('total_time', 0) / 60,
            'First_Domain_Epochs': results.get('first_domain_epochs', 0),
            'Remaining_Epochs': results.get('remaining_epochs', 0),
            'Batch_Size': results.get('batch_size', 0)
        })
    
    def save_to_csv(self, output_dir: str):
        """ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if not PANDAS_AVAILABLE:
            # pandasê°€ ì—†ìœ¼ë©´ JSONìœ¼ë¡œ ì €ì¥
            detailed_path = os.path.join(output_dir, f'detailed_results_{timestamp}.json')
            summary_path = os.path.join(output_dir, f'summary_results_{timestamp}.json')
            
            with open(detailed_path, 'w') as f:
                json.dump(self.detailed_results, f, indent=2)
            with open(summary_path, 'w') as f:
                json.dump(self.summary_results, f, indent=2)
            
            return detailed_path, summary_path, None
        
        # 1. ìƒì„¸ ê²°ê³¼ (ë„ë©”ì¸ë³„)
        detailed_df = pd.DataFrame(self.detailed_results)
        detailed_path = os.path.join(output_dir, f'detailed_results_{timestamp}.csv')
        detailed_df.to_csv(detailed_path, index=False)
        
        # 2. ìš”ì•½ ê²°ê³¼ (ì‹œë‚˜ë¦¬ì˜¤ë³„)
        summary_df = pd.DataFrame(self.summary_results)
        summary_path = os.path.join(output_dir, f'summary_results_{timestamp}.csv')
        summary_df.to_csv(summary_path, index=False)
        
        # 3. ë¹„êµ ê²°ê³¼ (í”¼ë²— í…Œì´ë¸”)
        pivot_path = None
        if len(self.detailed_results) > 0:
            try:
                pivot_df = detailed_df.pivot_table(
                    index=['Domain_Index', 'Domain_Name'],
                    columns='Scenario',
                    values=['Accuracy', 'Top1_Retrieval', 'Top5_Retrieval'],
                    aggfunc='first'
                )
                pivot_path = os.path.join(output_dir, f'comparison_results_{timestamp}.csv')
                pivot_df.to_csv(pivot_path)
            except Exception as e:
                print(f"âš ï¸ í”¼ë²— í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
        
        return detailed_path, summary_path, pivot_path


def run_single_scenario(config: Dict, logger: logging.Logger, device: torch.device) -> Dict:
    """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
    logger.info(f"ğŸš€ {config['name']} ì‹œì‘!")
    logger.info(f"   Domain Shift: {config['shift_type']}")
    logger.info(f"   Domains: {' â†’ '.join(config['domain_names'])}")
    
    start_time = time.time()
    
    try:
        # Trainer ìƒì„±
        trainer = ContinualTrainer(
            device=device,
            save_dir=f"checkpoints/{config['name']}",
            use_amp=True,
            max_grad_norm=1.0
        )
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
        trainer.batch_size = config['batch_size']
        trainer.learning_rate = 1e-4
        trainer.replay_buffer.buffer_size_per_domain = config['replay_buffer_size']
        
        # ë°ì´í„°ì…‹ ì •ë³´ ìˆ˜ì§‘
        sample_dataset = BearingDataset(
            data_dir=config['data_dir'],
            dataset_type=config['dataset_type'],
            domain_value=config['domain_order'][0],
            subset='train'
        )
        samples_per_domain = len(sample_dataset)
        total_samples = samples_per_domain * len(config['domain_order'])
        
        logger.info(f"   ë°ì´í„°: {samples_per_domain:,} ìƒ˜í”Œ/ë„ë©”ì¸, ì´ {total_samples:,} ìƒ˜í”Œ")
        
        # First Domain Training
        logger.info("ğŸ“š First Domain Training...")
        from src.data_loader import create_first_domain_dataloader
        
        first_loader = create_first_domain_dataloader(
            data_dir=config['data_dir'],
            domain_order=config['domain_order'],
            dataset_type=config['dataset_type'],
            subset='train',
            batch_size=config['batch_size']
        )
        
        first_results = trainer.train_first_domain(
            first_domain_dataloader=first_loader,
            num_epochs=config['first_domain_epochs']
        )
        
        # Remaining Domains Training
        logger.info("ğŸ”„ Remaining Domains Training...")
        trainer.num_epochs = config['remaining_epochs']
        
        # ë„ë©”ì¸ë³„ ë°ì´í„°ë¡œë” ìƒì„±
        from src.data_loader import create_domain_dataloaders
        domain_loaders = create_domain_dataloaders(
            data_dir=config['data_dir'],
            domain_order=config['domain_order'],
            dataset_type=config['dataset_type'],
            batch_size=config['batch_size']
        )
        
        remaining_results = trainer.train_remaining_domains(domain_loaders)
        
        # ê²°ê³¼ ì •ë¦¬
        final_metrics = remaining_results['final_metrics']
        total_time = time.time() - start_time
        
        results = {
            'domain_names': config['domain_names'],
            'shift_type': config['shift_type'],
            'final_accuracies': final_metrics['final_accuracies'],
            'final_top1_retrievals': final_metrics.get('final_top1_retrievals', []),
            'final_top5_retrievals': final_metrics.get('final_top5_retrievals', []),
            'average_accuracy': final_metrics['average_accuracy'],
            'average_forgetting': final_metrics['average_forgetting'],
            'samples_per_domain': samples_per_domain,
            'total_samples': total_samples,
            'total_time': total_time,
            'first_domain_epochs': config['first_domain_epochs'],
            'remaining_epochs': config['remaining_epochs'],
            'batch_size': config['batch_size']
        }
        
        logger.info(f"âœ… {config['name']} ì™„ë£Œ!")
        logger.info(f"   í‰ê·  ì •í™•ë„: {final_metrics['average_accuracy']:.4f}")
        logger.info(f"   í‰ê·  ë§ê°ë„: {final_metrics['average_forgetting']:.4f}")
        logger.info(f"   ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
        
        # ë„ë©”ì¸ë³„ ì„ë² ë”© ìˆ˜ì§‘ (ì‹œê°í™”ìš©)
        logger.info("ğŸ“Š ì‹œê°í™”ìš© ì„ë² ë”© ìˆ˜ì§‘ ì¤‘...")
        domain_embeddings = {}
        
        for domain in config['domain_order']:
            test_dataset = BearingDataset(
                data_dir=config['data_dir'],
                dataset_type=config['dataset_type'],
                domain_value=domain,
                subset='test'
            )
            
            if len(test_dataset) > 0:
                # ìƒ˜í”Œë§ (ì‹œê°í™”ìš©ìœ¼ë¡œ ì ë‹¹í•œ ìˆ˜ë§Œ)
                max_viz_samples = min(100, len(test_dataset))
                indices = torch.randperm(len(test_dataset))[:max_viz_samples]
                
                text_embeddings = []
                vib_embeddings = []
                metadata_list = []
                
                trainer.model.eval()
                with torch.no_grad():
                    for idx in indices:
                        sample = test_dataset[idx]
                        batch = {
                            'vibration': sample['vibration'].unsqueeze(0).to(device),
                            'text': [sample['text']]
                        }
                        
                        model_results = trainer.model(batch, return_embeddings=True)
                        text_embeddings.append(model_results['text_embeddings'])
                        vib_embeddings.append(model_results['vib_embeddings'])
                        metadata_list.append(sample['metadata'])
                
                if text_embeddings:
                    domain_embeddings[domain] = {
                        'text_embeddings': torch.cat(text_embeddings, dim=0),
                        'vib_embeddings': torch.cat(vib_embeddings, dim=0),
                        'metadata': metadata_list
                    }
        
        results['domain_embeddings'] = domain_embeddings
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ {config['name']} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        logger.exception("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        return None


def print_final_summary(results: ExperimentResults, logger: logging.Logger):
    """ìµœì¢… ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    logger.info("\n" + "="*80)
    logger.info("ğŸ‰ ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í—˜ ì™„ë£Œ!")
    logger.info("="*80)
    
    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ìš”ì•½
    for summary in results.summary_results:
        logger.info(f"\nğŸ“Š {summary['Scenario']}:")
        logger.info(f"   Shift Type: {summary['Shift_Type']}")
        logger.info(f"   Domains: {summary['Num_Domains']}ê°œ")
        logger.info(f"   Avg Accuracy: {summary['Avg_Accuracy']:.4f}")
        logger.info(f"   Avg Forgetting: {summary['Avg_Forgetting']:.4f}")
        logger.info(f"   Total Time: {summary['Total_Time_Minutes']:.1f}ë¶„")
        logger.info(f"   Total Samples: {summary['Total_Samples']:,}ê°œ")
    
    # ë¹„êµ ë¶„ì„
    if len(results.summary_results) >= 2:
        uos_result = results.summary_results[0]
        cwru_result = results.summary_results[1]
        
        logger.info(f"\nğŸ” ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ:")
        logger.info(f"   ì •í™•ë„ ì°¨ì´: {abs(uos_result['Avg_Accuracy'] - cwru_result['Avg_Accuracy']):.4f}")
        logger.info(f"   ë§ê°ë„ ì°¨ì´: {abs(uos_result['Avg_Forgetting'] - cwru_result['Avg_Forgetting']):.4f}")
        logger.info(f"   ë°ì´í„° ê·œëª¨ ë¹„ìœ¨: {uos_result['Total_Samples'] / cwru_result['Total_Samples']:.1f}:1")
    
    logger.info("="*80)


def parse_arguments():
    """ëª…ë ¹ì¤„ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='TextVibCLIP ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ í†µí•© ì‹¤í—˜')
    
    parser.add_argument('--output_dir', type=str, default='results_comparison',
                       help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--quick_test', action='store_true',
                       help='ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì—í¬í¬ ìˆ˜ ê°ì†Œ)')
    parser.add_argument('--epochs', type=int, default=None,
                       help='ì—í¬í¬ ìˆ˜ (quick_test ëª¨ë“œìš©)')
    parser.add_argument('--device', type=str, default='auto',
                       choices=['auto', 'cpu', 'cuda'], help='í•™ìŠµ ë””ë°”ì´ìŠ¤')
    parser.add_argument('--seed', type=int, default=42,
                       help='ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œê°’')
    parser.add_argument('--skip_uos', action='store_true',
                       help='UOS ì‹œë‚˜ë¦¬ì˜¤ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--skip_cwru', action='store_true',
                       help='CWRU ì‹œë‚˜ë¦¬ì˜¤ ê±´ë„ˆë›°ê¸°')
    
    return parser.parse_args()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    args = parse_arguments()
    
    # ì¬í˜„ì„± ì„¤ì •
    set_seed(args.seed)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)
    
    # ë¡œê¹… ì„¤ì •
    logger = setup_logging(args.output_dir)
    logger.info("ğŸ¯ TextVibCLIP ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ í†µí•© ì‹¤í—˜ ì‹œì‘!")
    logger.info(f"ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {args.output_dir}")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)
    
    logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {device}")
    if device.type == 'cuda':
        logger.info(f"   GPU: {torch.cuda.get_device_name()}")
    
    # ì‹¤í—˜ ê²°ê³¼ ê´€ë¦¬ì
    results = ExperimentResults()
    
    # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •
    scenarios = []
    if not args.skip_uos:
        scenarios.append(ScenarioConfig.UOS_CONFIG)
    if not args.skip_cwru:
        scenarios.append(ScenarioConfig.CWRU_CONFIG)
    
    if not scenarios:
        logger.error("âŒ ì‹¤í–‰í•  ì‹œë‚˜ë¦¬ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # Quick test ëª¨ë“œ ì„¤ì •
    if args.quick_test:
        test_epochs = args.epochs if args.epochs else 5
        logger.info(f"âš¡ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì—í¬í¬ ìˆ˜ë¥¼ {test_epochs}ë¡œ ì¶•ì†Œ")
        for scenario in scenarios:
            scenario['first_domain_epochs'] = test_epochs
            scenario['remaining_epochs'] = test_epochs // 2
    
    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‹¤í–‰
    total_start_time = time.time()
    
    for i, scenario in enumerate(scenarios, 1):
        logger.info(f"\n{'='*60}")
        logger.info(f"ì‹œë‚˜ë¦¬ì˜¤ {i}/{len(scenarios)}: {scenario['name']}")
        logger.info(f"{'='*60}")
        
        scenario_result = run_single_scenario(scenario, logger, device)
        
        if scenario_result:
            results.add_scenario_result(scenario['name'], scenario_result)
        else:
            logger.error(f"âŒ {scenario['name']} ì‹¤í–‰ ì‹¤íŒ¨!")
    
    # ê²°ê³¼ ì €ì¥
    logger.info("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    try:
        detailed_path, summary_path, comparison_path = results.save_to_csv(args.output_dir)
        logger.info(f"âœ… ìƒì„¸ ê²°ê³¼: {detailed_path}")
        logger.info(f"âœ… ìš”ì•½ ê²°ê³¼: {summary_path}")
        logger.info(f"âœ… ë¹„êµ ê²°ê³¼: {comparison_path}")
    except Exception as e:
        logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    # ê³ ê¸‰ ì‹œê°í™” ìƒì„±
    logger.info("\nğŸ¨ ë…¼ë¬¸ìš© ì‹œê°í™” ìƒì„± ì¤‘...")
    try:
        visualizer = create_visualizer(args.output_dir)
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ê²°ê³¼ ì •ë¦¬
        scenario_summary = {}
        domain_embeddings = {}
        
        for scenario_result in results.scenario_results.values():
            if 'domain_embeddings' in scenario_result:
                scenario_name = scenario_result.get('shift_type', 'Unknown')
                scenario_summary[scenario_name] = scenario_result
                domain_embeddings[scenario_name] = scenario_result['domain_embeddings']
        
        # ë…¼ë¬¸ìš© Figure ìƒì„±
        if scenario_summary and domain_embeddings:
            figure_paths = visualizer.create_paper_figures(
                scenario_summary, 
                domain_embeddings,
                output_prefix="TextVibCLIP"
            )
            
            logger.info(f"âœ… ë…¼ë¬¸ìš© Figure {len(figure_paths)}ê°œ ìƒì„± ì™„ë£Œ!")
            for path in figure_paths:
                logger.info(f"   ğŸ“Š {Path(path).name}")
        else:
            logger.warning("âš ï¸ ì‹œê°í™”ìš© ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            
    except Exception as e:
        logger.error(f"âŒ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {str(e)}")
        logger.exception("ìƒì„¸ ì˜¤ë¥˜:")
    
    # ìµœì¢… ìš”ì•½
    total_time = time.time() - total_start_time
    logger.info(f"\nâ±ï¸ ì „ì²´ ì‹¤í—˜ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
    
    print_final_summary(results, logger)
    
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    logger.info("ğŸ‰ ëª¨ë“  ì‹¤í—˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")


if __name__ == "__main__":
    main()
