#!/usr/bin/env python3
"""
TextVibCLIP ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
Triplet ranking loss ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¡œ ì†Œê·œëª¨ ë°ì´í„°ì— ìµœì í™”

Usage:
    python run_scenarios.py --quick_test --epochs 10
    python run_scenarios.py --skip_uos  # CWRUë§Œ
    python run_scenarios.py --skip_cwru # UOSë§Œ
"""

import argparse
import logging
import os
import torch
import torch.nn.functional as F
import time
import json
import numpy as np
import random
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple

# ğŸ¯ ì¬í˜„ì„± ë³´ì¥ì„ ìœ„í•œ ì‹œë“œ ê³ ì • (ì¤‘ë³µ ì œê±°)
def set_random_seeds(seed: int = 42):
    """ëª¨ë“  ëœë¤ ì‹œë“œ ê³ ì •"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # ë©€í‹° GPU í™˜ê²½
    np.random.seed(seed)
    random.seed(seed)
    
    # ì¶”ê°€ì ì¸ ì¬í˜„ì„± ë³´ì¥
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    print(f"ğŸ¯ Random seeds fixed to {seed} for reproducibility")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
import sys
from pathlib import Path
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

from src.continual_trainer import ContinualTrainer
from src.data_loader import create_domain_dataloaders
from src.data_cache import create_cached_domain_dataloaders, create_cached_first_domain_dataloader, clear_all_caches
from src.utils import set_seed
from src.visualization import create_visualizer
from configs.model_config import TRAINING_CONFIG, DATA_CONFIG, CWRU_DATA_CONFIG


def setup_logging(log_dir: str) -> Tuple[logging.Logger, str]:
    """ë¡œê¹… ì„¤ì •"""
    experiment_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    experiment_dir = os.path.join(log_dir, f"{experiment_timestamp}")
    os.makedirs(experiment_dir, exist_ok=True)
    
    log_filename = f"textvibclip_{experiment_timestamp}.log"
    log_path = os.path.join(experiment_dir, log_filename)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_path),
            logging.StreamHandler()
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"TextVibCLIP ì‹¤í—˜ ì‹œì‘: {log_path}")
    logger.info(f"ì‹¤í—˜ ê²°ê³¼ í´ë”: {experiment_dir}")
    
    return logger, experiment_dir


class ScenarioConfig:
    """ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„¤ì •"""
    
    UOS_CONFIG = {
        'name': 'UOS_Scenario1_VaryingSpeed',
        'data_dir': 'data_scenario1',
        'dataset_type': 'uos',
        'domain_order': [600, 800, 1000, 1200, 1400, 1600],
        'domain_names': ['600RPM', '800RPM', '1000RPM', '1200RPM', '1400RPM', '1600RPM'],
        'shift_type': 'Varying Speed',
        'first_domain_epochs': 20,  # 15 â†’ 20 (ë” ì•ˆì •ì ì¸ ê¸°ì´ˆ í•™ìŠµ)
        'remaining_epochs': 8,      # 6 â†’ 8 (ê· í˜•ì¡íŒ ì ì‘ í•™ìŠµ)
        'batch_size': 16,           # 8 â†’ 16 (ë” ì•ˆì •ì ì¸ ê·¸ë˜ë””ì–¸íŠ¸)
        'replay_buffer_size': 800,  # 1000 â†’ 800 (ìµœì í™”ëœ ë©”ëª¨ë¦¬ ì‚¬ìš©)
        'patience': 10              # 8 â†’ 10 (ë” ì—¬ìœ ìˆëŠ” ì¡°ê¸° ì¢…ë£Œ)
    }
    
    CWRU_CONFIG = {
        'name': 'CWRU_Scenario2_VaryingLoad',
        'data_dir': 'data_scenario2',
        'dataset_type': 'cwru',
        'domain_order': [0, 1, 2, 3],
        'domain_names': ['0HP', '1HP', '2HP', '3HP'],
        'shift_type': 'Varying Load',
        'first_domain_epochs': 15,
        'remaining_epochs': 6,
        'batch_size': 4,            #  (ê·¹ì†Œ ë°ì´í„° ëŒ€ì‘)
        'replay_buffer_size': 100,   
        'patience': 5
    }


def run_single_scenario(config: Dict, logger: logging.Logger, device: torch.device, args, experiment_dir: str) -> Dict:
    """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
    logger.info(f"ğŸš€ {config['name']} ì‹œì‘!")
    logger.info(f"   ì•„í‚¤í…ì²˜: Ranking-based (Triplet Loss)")
    logger.info(f"   Domains: {' â†’ '.join(config['domain_names'])}")
    
    start_time = time.time()
    
    try:
        # Trainer ìƒì„± (ì‹¤í—˜ë³„ ë…ë¦½ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬)
        # ì¬í˜„ì„± ë³´ì¥: ê° ì‹¤í—˜ì´ ë…ë¦½ì ì¸ ì²´í¬í¬ì¸íŠ¸ ì‚¬ìš©
        checkpoint_dir = os.path.join(experiment_dir, 'checkpoints', config['name'])
        
        # Replay-free ì‹¤í—˜ì¸ ê²½ìš° ì™„ì „íˆ ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì‹œì‘
        if 'ReplayFree' in config['name']:
            logger.info("ğŸ”„ Replay-free ì‹¤í—˜: ëª¨ë¸ ì™„ì „ ì´ˆê¸°í™”")
            # ê¸°ì¡´ ëª¨ë¸ì´ ìˆë‹¤ë©´ ì™„ì „íˆ ì œê±°í•˜ê³  ìƒˆë¡œ ìƒì„±
            trainer = ContinualTrainer(
                model=None,  # Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì™„ì „íˆ ìƒˆë¡œìš´ ëª¨ë¸ ìƒì„±
                device=device,
                save_dir=checkpoint_dir,
                domain_order=config['domain_order'],
                data_dir=config['data_dir'],
                dataset_type=config['dataset_type'],
                results_save_dir=None
            )
        else:
            trainer = ContinualTrainer(
                device=device,
                save_dir=checkpoint_dir,
                domain_order=config['domain_order'],
                data_dir=config['data_dir'],
                dataset_type=config['dataset_type'],
                results_save_dir=None
            )
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
        trainer.batch_size = config['batch_size']
        trainer.replay_buffer.buffer_size_per_domain = config['replay_buffer_size']
        
        # First Domain Training
        logger.info("ğŸ“š First Domain Training...")
        
        first_loader = create_cached_first_domain_dataloader(
            data_dir=config['data_dir'],
            domain_order=config['domain_order'],
            dataset_type=config['dataset_type'],
            subset='train',
            batch_size=config['batch_size']
        )
        
        first_results = trainer.train_first_domain(
            first_domain_dataloader=first_loader,
            num_epochs=config['first_domain_epochs']
        )
        
        # Remaining Domains Training
        logger.info("ğŸ”„ Remaining Domains Training...")
        
        domain_loaders = create_cached_domain_dataloaders(
            data_dir=config['data_dir'],
            domain_order=config['domain_order'],
            dataset_type=config['dataset_type'],
            batch_size=config['batch_size']
        )
        
        # ë‚¨ë„ë©”ì¸ ì—í­/ì„¤ì • ê°•ì œ ë°˜ì˜ (ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •ê³¼ trainer ë‚´ë¶€ íŠ¹ìˆ˜ì„¤ì • ë¶ˆì¼ì¹˜ í•´ì†Œ)
        try:
            from configs.model_config import CWRU_SPECIFIC_CONFIG, CONTINUAL_CONFIG
            if config['dataset_type'] == 'cwru':
                CWRU_SPECIFIC_CONFIG['num_epochs'] = max(1, int(config.get('remaining_epochs', 3)))
            else:
                CONTINUAL_CONFIG['num_epochs'] = max(1, int(config.get('remaining_epochs', 3)))
        except Exception:
            pass

        remaining_results = trainer.train_remaining_domains(domain_loaders)

        # ğŸ” ì‹œê°í™”: ê° ë„ë©”ì¸ì˜ test ì„ë² ë”© ìˆ˜ì§‘ í›„ PNG ì €ì¥
        try:
            # Replay-free ì‹¤í—˜ì¸ ê²½ìš° ì‹œê°í™”ë„ replay_free ë””ë ‰í† ë¦¬ì— ì €ì¥
            viz_dir = experiment_dir
            if 'ReplayFree' in config['name']:
                replay_free_dir = os.path.join(experiment_dir, 'replay_free')
                os.makedirs(replay_free_dir, exist_ok=True)
                viz_dir = replay_free_dir
            
            visualizer = create_visualizer(viz_dir)
            for domain_value in config['domain_order']:
                if domain_value not in domain_loaders:
                    continue
                test_loader = domain_loaders[domain_value]['test']
                emb = trainer._collect_domain_embeddings(test_loader)
                if not emb:
                    continue

                text_emb = emb.get('text_embeddings')
                vib_emb = emb.get('vib_embeddings')
                metadata_list = emb.get('metadata', [])

                # ë¼ë²¨/ë² ì–´ë§íƒ€ì… ì¶”ì¶œ
                labels = [m.get('bearing_condition', 'H') for m in metadata_list]
                # CWRUëŠ” ë² ì–´ë§ íƒ€ì… ë¼ë²¨ì„ ê³ ì • í‘œì‹œ(í˜¼ë™ ë°©ì§€)
                if config['dataset_type'] == 'cwru':
                    bearing_types = ['CWRU'] * len(metadata_list)
                else:
                    bearing_types = [m.get('bearing_type', '6204') for m in metadata_list]

                domain_name = f"{domain_value}HP" if config['dataset_type'] == 'cwru' else f"{domain_value}RPM"

                # ì •í•© ì‹œê°í™”: UOS/CWRU ê³µí†µ - í‰ê°€ ê¸°ì¤€ê³¼ ë™ì¼í•˜ê²Œ í…ìŠ¤íŠ¸ í”„ë¡œí† íƒ€ì… ì‚¬ìš©(UOSëŠ” 7í´ë˜ìŠ¤)
                if vib_emb is not None and labels:
                    try:
                        if config['dataset_type'] == 'cwru':
                            prompt_bank = {
                                0: ["healthy bearing","normal bearing with no fault","bearing vibration without defect"],
                                1: ["bearing with ball fault","ball defect in bearing","ball damage on bearing"],
                                2: ["bearing inner race fault","inner ring defect in bearing","inner race damage of bearing"],
                                3: ["bearing outer race fault","outer ring defect in bearing","outer race damage of bearing"]
                            }
                            class_ids = [0,1,2,3]
                            label_map = {'H': 0, 'B': 1, 'IR': 2, 'OR': 3}
                        else:
                            # UOS 7í´ë˜ìŠ¤ í”„ë¡¬í”„íŠ¸ (ê°„ê²° ë²„ì „)
                            prompt_bank = {
                                0: ["healthy bearing"],          # H_H
                                1: ["bearing with ball fault"],  # H_B
                                2: ["inner race fault"],         # H_IR
                                3: ["outer race fault"],         # H_OR
                                4: ["mechanical looseness"],     # L_H
                                5: ["rotor unbalance"],          # U_H
                                6: ["shaft misalignment"]        # M_H
                            }
                            class_ids = [0,1,2,3,4,5,6]
                            label_map = {'H_H':0,'H_B':1,'H_IR':2,'H_OR':3,'L_H':4,'U_H':5,'M_H':6}

                        # í´ë˜ìŠ¤ í”„ë¡œí† íƒ€ì… ì„ë² ë”© ê³„ì‚°
                        class_protos = []
                        for cls_id in class_ids:
                            texts = prompt_bank[cls_id]
                            raw = trainer.model.text_encoder.encode_texts(texts, device)
                            proj = F.normalize(trainer.model.text_projection(raw), p=2, dim=1)
                            proto = F.normalize(proj.mean(dim=0, keepdim=True), p=2, dim=1)
                            class_protos.append(proto)
                        proto_mat = torch.cat(class_protos, dim=0)

                        # UOS ë¼ë²¨ ë¬¸ìì—´ êµ¬ì„±
                        if config['dataset_type'] == 'uos':
                            # ê¸°ì¡´ labelsëŠ” 'bearing_condition'ë§Œì¼ ìˆ˜ ìˆìŒ â†’ metadataë¡œ ì¡°í•© ë¼ë²¨ ìƒì„±
                            rc = [m.get('rotating_component','H') for m in metadata_list]
                            bc = [m.get('bearing_condition','H') for m in metadata_list]
                            labels = [f"{r}_{b}" for r,b in zip(rc, bc)]

                        idx = torch.tensor([label_map.get(l, 0) for l in labels], device=proto_mat.device)
                        # ê° ìƒ˜í”Œ ë¼ë²¨ì— í•´ë‹¹í•˜ëŠ” í”„ë¡œí† íƒ€ì…ì„ í…ìŠ¤íŠ¸ ì„ë² ë”©ìœ¼ë¡œ ì‚¬ìš©
                        text_emb = proto_mat.index_select(0, idx)
                    except Exception as _e:
                        logger.warning(f"CWRU í”„ë¡œí† íƒ€ì… ê¸°ë°˜ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {_e}")

                # Per-domain encoder alignment t-SNE
                visualizer.create_encoder_alignment_plot(
                    text_embeddings=text_emb,
                    vib_embeddings=vib_emb,
                    labels=labels,
                    bearing_types=bearing_types,
                    domain_name=domain_name,
                    save_name="encoder_alignment"
                )

                # Similarity diagnostics (per-domain)
                if config['dataset_type'] == 'cwru':
                    try:
                        # í‰ê°€ í”„ë¡¬í”„íŠ¸ í”„ë¡œí† íƒ€ì…ì„ ì¬ì‚¬ìš©
                        prompt_bank = {
                            0: [
                                "healthy bearing",
                                "normal bearing with no fault",
                                "bearing vibration without defect"
                            ],
                            1: [
                                "bearing with ball fault",
                                "ball defect in bearing",
                                "ball damage on bearing"
                            ],
                            2: [
                                "bearing inner race fault",
                                "inner ring defect in bearing",
                                "inner race damage of bearing"
                            ],
                            3: [
                                "bearing outer race fault",
                                "outer ring defect in bearing",
                                "outer race damage of bearing"
                            ]
                        }
                        class_protos = []
                        for cls_id in [0, 1, 2, 3]:
                            texts = prompt_bank[cls_id]
                            raw = trainer.model.text_encoder.encode_texts(texts, device)
                            proj = F.normalize(trainer.model.text_projection(raw), p=2, dim=1)
                            proto = F.normalize(proj.mean(dim=0, keepdim=True), p=2, dim=1)
                            class_protos.append(proto)
                        proto_mat = torch.cat(class_protos, dim=0)

                        pass
                    except Exception as _e:
                        logger.warning(f"ì‹œê°í™” ì‹¤íŒ¨: {_e}")
        except Exception as viz_err:
            logger.warning(f"ì‹œê°í™” ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {viz_err}")
        
        #  ì¶”ê°€ ì‹œê°í™” ìƒì„±
        try:
            logger.info("ğŸ“Š  ì‹œê°í™” ìƒì„± ì¤‘...")
            
            # Continual Learning Performance Curve
            visualizer.create_continual_learning_curve(
                domain_names=config['domain_names'],
                accuracies=remaining_results['final_metrics']['final_accuracies'],
                scenario_name=config['name']
            )
            
            # Forgetting Analysis Heatmap (ì‹¤ì œ performance_history ì‚¬ìš©)
            # Heatmap[i, j] = ië²ˆì§¸ í•™ìŠµ ë‹¨ê³„ í›„, jë²ˆì§¸ test domain ì •í™•ë„
            # ìœ„ìª½ ì‚¼ê°í˜•ë§Œ ê°’ ìˆìŒ (j <= i, ì´ë¯¸ í•™ìŠµí•œ ë„ë©”ì¸ë§Œ)
            n_domains = len(config['domain_names'])
            accuracy_matrix = np.full((n_domains, n_domains), np.nan)
            
            # trainer.performance_historyì—ì„œ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ
            for i in range(n_domains):
                # ië²ˆì§¸ í•™ìŠµ ë‹¨ê³„ (0~ië²ˆì§¸ ë„ë©”ì¸ê¹Œì§€ í•™ìŠµ ì™„ë£Œ)
                for j in range(n_domains):
                    # jë²ˆì§¸ test domain
                    if j <= i:  # ì´ë¯¸ í•™ìŠµí•œ ë„ë©”ì¸ë§Œ (ìœ„ìª½ ì‚¼ê°í˜•)
                        test_domain = config['domain_order'][j]
                        if test_domain in trainer.performance_history:
                            history = trainer.performance_history[test_domain]['accuracy']
                            # jë²ˆì§¸ ë„ë©”ì¸ì€ jë²ˆì§¸ ë‹¨ê³„ë¶€í„° í‰ê°€ë¨
                            # ië²ˆì§¸ ë‹¨ê³„ì—ì„œì˜ ì¸ë±ìŠ¤ = i - j
                            history_idx = i - j
                            if len(history) > history_idx:
                                accuracy_matrix[i, j] = history[history_idx]

            visualizer.create_forgetting_heatmap(
                domain_names=config['domain_names'],
                accuracy_matrix=accuracy_matrix,
                scenario_name=config['name']
            )
            
            logger.info("âœ…  ì‹œê°í™” ìƒì„± ì™„ë£Œ!")
        except Exception as paper_viz_err:
            logger.warning(f" ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {paper_viz_err}")
        
        # Replay-free ì‹¤í—˜ì¸ ê²½ìš° ë³„ë„ ë””ë ‰í† ë¦¬ì— ì €ì¥
        if 'ReplayFree' in config['name']:
            replay_free_dir = os.path.join(experiment_dir, 'replay_free')
            os.makedirs(replay_free_dir, exist_ok=True)
            
            # ì‹¤í—˜ ì„¤ì • ì €ì¥ (replay_free ë””ë ‰í† ë¦¬)
            config_path = save_experiment_config(config, trainer, replay_free_dir, device)
            logger.info(f"ğŸ“ ì‹¤í—˜ ì„¤ì • ì €ì¥ (replay-free): {config_path}")
            
            # ê²°ê³¼ë¥¼ replay_free ë””ë ‰í† ë¦¬ì— ì €ì¥í•˜ë„ë¡ ì„¤ì •
            experiment_dir = replay_free_dir
        else:
            # ì‹¤í—˜ ì„¤ì • ì €ì¥ (ê¸°ë³¸ ë””ë ‰í† ë¦¬)
            config_path = save_experiment_config(config, trainer, experiment_dir, device)
            logger.info(f"ğŸ“ ì‹¤í—˜ ì„¤ì • ì €ì¥: {config_path}")
        
        # ê²°ê³¼ ì •ë¦¬ (Heatmap ë°ì´í„° í¬í•¨)
        final_metrics = remaining_results['final_metrics']
        total_time = time.time() - start_time
        
        # ğŸ¯ Forgetting Heatmap ë°ì´í„° ì¶”ì¶œ (JSON ì €ì¥ìš©)
        n_domains = len(config['domain_names'])
        heatmap_matrix = []
        stage_averages = []
        
        for i in range(n_domains):
            row = []
            for j in range(n_domains):
                if j <= i:  # í•™ìŠµí•œ ë„ë©”ì¸ë§Œ
                    test_domain = config['domain_order'][j]
                    if test_domain in trainer.performance_history:
                        history = trainer.performance_history[test_domain]['accuracy']
                        history_idx = i - j
                        if len(history) > history_idx:
                            row.append(round(history[history_idx] * 100, 2))  # í¼ì„¼íŠ¸
                        else:
                            row.append(None)
                    else:
                        row.append(None)
                else:
                    row.append(None)  # ì•„ì§ í•™ìŠµ ì•ˆí•¨
            
            # ê° í–‰ì˜ í‰ê·  ê³„ì‚°
            valid_values = [v for v in row if v is not None]
            if valid_values:
                stage_avg = round(sum(valid_values) / len(valid_values), 2)
            else:
                stage_avg = None
            
            heatmap_matrix.append(row)
            stage_averages.append(stage_avg)
        
        results = {
            'domain_names': config['domain_names'],
            'shift_type': config['shift_type'],
            # ğŸ¯ ì£¼ìš” ê²°ê³¼: Stageë³„ í‰ê·  (Heatmap ê° í–‰ í‰ê· )
            'stage_accuracies': stage_averages,  # ì´ê²Œ í•µì‹¬!
            'average_accuracy': final_metrics['average_accuracy'],
            'average_forgetting': final_metrics['average_forgetting'],
            # ğŸ¯ Forgetting Heatmap ì „ì²´ ë°ì´í„°
            'forgetting_matrix': heatmap_matrix,
            # ì°¸ê³ ìš© (ë…¼ë¬¸ì—ëŠ” ì‚¬ìš© ì•ˆí•¨)
            'final_top1_retrievals': final_metrics.get('final_top1_retrievals', []),
            'final_top5_retrievals': final_metrics.get('final_top5_retrievals', []),
            'total_time': total_time,
            'first_domain_epochs': config['first_domain_epochs'],
            'remaining_epochs': config['remaining_epochs'],
            'batch_size': config['batch_size']
        }
        
        logger.info(f"âœ… {config['name']} ì™„ë£Œ!")
        logger.info(f"   í‰ê·  ì •í™•ë„: {final_metrics['average_accuracy']:.4f}")
        logger.info(f"   í‰ê·  ë§ê°ë„: {final_metrics['average_forgetting']:.4f}")
        logger.info(f"   ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ {config['name']} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        logger.exception("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        return None


def save_experiment_config(config: Dict, trainer, output_dir: str, device: torch.device) -> str:
    """Save experiment configuration to txt file"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    config_path = os.path.join(output_dir, f'experiment_config_{timestamp}.txt')
    
    with open(config_path, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("TextVibCLIP Experiment Configuration\n")
        f.write("=" * 80 + "\n")
        f.write(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Scenario: {config['name']}\n")
        f.write(f"Dataset: {config['dataset_type'].upper()}\n")
        f.write(f"Domain Order: {' â†’ '.join(config['domain_names'])}\n")
        f.write(f"Shift Type: {config['shift_type']}\n")
        f.write(f"Device: {device}\n\n")
        
        # Scenario Configuration
        f.write("-" * 50 + "\n")
        f.write("Scenario Configuration\n")
        f.write("-" * 50 + "\n")
        for key, value in config.items():
            if key not in ['name', 'data_dir', 'dataset_type', 'domain_order', 'domain_names', 'shift_type']:
                f.write(f"{key}: {value}\n")
        f.write("\n")
        
        # Model Architecture
        f.write("-" * 50 + "\n")
        f.write("Model Architecture\n")
        f.write("-" * 50 + "\n")
        try:
            from configs.model_config import MODEL_CONFIG
            f.write(f"embedding_dim: {MODEL_CONFIG['embedding_dim']}\n")
            f.write(f"text_dim: {MODEL_CONFIG['text_dim']}\n")
            f.write(f"vibration_input_dim: {MODEL_CONFIG['vibration_input_dim']}\n")
            f.write(f"vibration_input_length: {MODEL_CONFIG['vibration_encoder']['input_length']}\n")
            f.write(f"vibration_kernel_sizes: {MODEL_CONFIG['vibration_encoder']['kernel_sizes']}\n")
            f.write(f"vibration_channels: {MODEL_CONFIG['vibration_encoder']['channels']}\n")
            f.write(f"vibration_stride: {MODEL_CONFIG['vibration_encoder']['stride']}\n")
            f.write(f"dropout: {MODEL_CONFIG['vibration_encoder']['dropout']}\n")
            f.write(f"activation: {MODEL_CONFIG['vibration_encoder']['activation']}\n")
            f.write(f"normalization: {MODEL_CONFIG['vibration_encoder']['normalization']}\n")
            f.write(f"pooling: {MODEL_CONFIG['vibration_encoder']['pooling']}\n")
            
            # Text Encoder Configuration
            f.write(f"\ntext_encoder_model: {MODEL_CONFIG['text_encoder']['model_name']}\n")
            f.write(f"lora_rank: {MODEL_CONFIG['text_encoder']['lora_config']['r']}\n")
            f.write(f"lora_alpha: {MODEL_CONFIG['text_encoder']['lora_config']['lora_alpha']}\n")
            f.write(f"lora_target_modules: {MODEL_CONFIG['text_encoder']['lora_config']['target_modules']}\n")
            f.write(f"lora_dropout: {MODEL_CONFIG['text_encoder']['lora_config']['lora_dropout']}\n")
            
            # Projection Layers
            f.write(f"\nprojection_hidden_dim: {MODEL_CONFIG['projection']['hidden_dim']}\n")
            f.write(f"projection_output_dim: {MODEL_CONFIG['projection']['output_dim']}\n")
            f.write(f"projection_dropout: {MODEL_CONFIG['projection']['dropout']}\n")
            
            # Ranking Loss
            f.write(f"\nranking_margin: {MODEL_CONFIG['ranking_loss']['margin']}\n")
            f.write(f"ranking_loss_type: {MODEL_CONFIG['ranking_loss']['loss_type']}\n")
            
            # Auxiliary Classification
            f.write(f"\naux_classification_enabled: {MODEL_CONFIG['aux_classification']['enabled']}\n")
            f.write(f"aux_num_classes: {MODEL_CONFIG['aux_classification']['num_classes']}\n")
            f.write(f"aux_loss_weight: {MODEL_CONFIG['aux_classification']['loss_weight']}\n")
            f.write(f"aux_dropout: {MODEL_CONFIG['aux_classification']['dropout']}\n")
        except Exception as e:
            f.write(f"Model config loading failed: {e}\n")
        f.write("\n")
        
        # Training Configuration
        f.write("-" * 50 + "\n")
        f.write("Training Configuration\n")
        f.write("-" * 50 + "\n")
        try:
            from configs.model_config import FIRST_DOMAIN_CONFIG, CONTINUAL_CONFIG, CWRU_SPECIFIC_CONFIG, CWRU_FIRST_DOMAIN_CONFIG
            
            if config['dataset_type'] == 'cwru':
                f.write("CWRU-specific configuration:\n")
                f.write(f"  first_domain_epochs: {CWRU_FIRST_DOMAIN_CONFIG['num_epochs']}\n")
                f.write(f"  first_domain_lr: {CWRU_FIRST_DOMAIN_CONFIG['learning_rate']}\n")
                f.write(f"  first_domain_weight_decay: {CWRU_FIRST_DOMAIN_CONFIG['weight_decay']}\n")
                f.write(f"  first_domain_aux_weight: {CWRU_FIRST_DOMAIN_CONFIG['aux_weight']}\n")
                f.write(f"  first_domain_patience: {CWRU_FIRST_DOMAIN_CONFIG['patience']}\n")
                f.write(f"  remaining_epochs: {CWRU_SPECIFIC_CONFIG['num_epochs']}\n")
                f.write(f"  remaining_lr: {CWRU_SPECIFIC_CONFIG['learning_rate']}\n")
                f.write(f"  remaining_weight_decay: {CWRU_SPECIFIC_CONFIG['weight_decay']}\n")
                f.write(f"  remaining_aux_weight: {CWRU_SPECIFIC_CONFIG['aux_weight']}\n")
                f.write(f"  remaining_patience: {CWRU_SPECIFIC_CONFIG['patience']}\n")
            else:
                f.write("UOS standard configuration:\n")
                f.write(f"  first_domain_epochs: {FIRST_DOMAIN_CONFIG['num_epochs']}\n")
                f.write(f"  first_domain_lr: {FIRST_DOMAIN_CONFIG['learning_rate']}\n")
                f.write(f"  first_domain_weight_decay: {FIRST_DOMAIN_CONFIG['weight_decay']}\n")
                f.write(f"  first_domain_aux_weight: {FIRST_DOMAIN_CONFIG['aux_weight']}\n")
                f.write(f"  first_domain_patience: {FIRST_DOMAIN_CONFIG['patience']}\n")
                f.write(f"  first_domain_min_epochs: {FIRST_DOMAIN_CONFIG['min_epoch']}\n")
                f.write(f"  remaining_epochs: {CONTINUAL_CONFIG['num_epochs']}\n")
                f.write(f"  remaining_lr: {CONTINUAL_CONFIG['learning_rate']}\n")
                f.write(f"  remaining_weight_decay: {CONTINUAL_CONFIG['weight_decay']}\n")
                f.write(f"  remaining_aux_weight: {CONTINUAL_CONFIG['aux_weight']}\n")
                f.write(f"  remaining_patience: {CONTINUAL_CONFIG['patience']}\n")
                f.write(f"  remaining_min_epochs: {CONTINUAL_CONFIG['min_epoch']}\n")
        except Exception as e:
            f.write(f"Training config loading failed: {e}\n")
        f.write("\n")
        
        # Replay Buffer Configuration
        f.write("-" * 50 + "\n")
        f.write("Replay Buffer Configuration\n")
        f.write("-" * 50 + "\n")
        f.write(f"buffer_size_per_domain: {trainer.replay_buffer.buffer_size_per_domain}\n")
        f.write(f"embedding_dim: {trainer.replay_buffer.embedding_dim}\n")
        f.write(f"sampling_strategy: {trainer.replay_buffer.sampling_strategy}\n")
        try:
            from configs.model_config import CONTINUAL_CONFIG
            f.write(f"replay_ratio: {CONTINUAL_CONFIG.get('replay_ratio', 'N/A')}\n")
            f.write(f"replay_every_n: {CONTINUAL_CONFIG.get('replay_every_n', 'N/A')}\n")
            f.write(f"replay_selection: {CONTINUAL_CONFIG.get('replay_selection', 'N/A')}\n")
        except Exception:
            pass
        f.write("\n")
        
        # Data Configuration
        f.write("-" * 50 + "\n")
        f.write("Data Configuration\n")
        f.write("-" * 50 + "\n")
        try:
            from configs.model_config import DATA_CONFIG, CWRU_DATA_CONFIG
            data_config = CWRU_DATA_CONFIG if config['dataset_type'] == 'cwru' else DATA_CONFIG
            f.write(f"window_size: {data_config['window_size']}\n")
            f.write(f"overlap_ratio: {data_config['overlap_ratio']}\n")
            f.write(f"signal_normalization: {data_config['signal_normalization']}\n")
            f.write(f"validation_split: {data_config['validation_split']}\n")
            f.write(f"test_split: {data_config['test_split']}\n")
            f.write(f"max_text_length: {data_config['max_text_length']}\n")
        except Exception as e:
            f.write(f"Data config loading failed: {e}\n")
        f.write("\n")
        
        # Reproducibility Configuration
        f.write("-" * 50 + "\n")
        f.write("Reproducibility Configuration\n")
        f.write("-" * 50 + "\n")
        f.write(f"pytorch_seed: {torch.initial_seed()}\n")
        f.write(f"numpy_seed: {np.random.get_state()[1][0] if hasattr(np.random, 'get_state') else 'N/A'}\n")
        f.write(f"random_seed: {random.getstate()[1][0] if hasattr(random, 'getstate') else 'N/A'}\n")
        f.write(f"cuda_seed: {torch.cuda.initial_seed() if torch.cuda.is_available() else 'N/A'}\n")
        f.write(f"cudnn_deterministic: {torch.backends.cudnn.deterministic}\n")
        f.write(f"cudnn_benchmark: {torch.backends.cudnn.benchmark}\n")
        f.write("\n")
        
        # Checkpoint Information
        f.write("-" * 50 + "\n")
        f.write("Checkpoint Information\n")
        f.write("-" * 50 + "\n")
        f.write(f"save_dir: {trainer.save_dir}\n")
        f.write(f"max_grad_norm: {trainer.max_grad_norm}\n")
        f.write("\n")
        
        # System Information
        f.write("-" * 50 + "\n")
        f.write("System Information\n")
        f.write("-" * 50 + "\n")
        f.write(f"python_version: {sys.version}\n")
        f.write(f"pytorch_version: {torch.__version__}\n")
        f.write(f"cuda_available: {torch.cuda.is_available()}\n")
        if torch.cuda.is_available():
            f.write(f"cuda_version: {torch.version.cuda}\n")
            f.write(f"gpu_count: {torch.cuda.device_count()}\n")
            f.write(f"current_gpu: {torch.cuda.current_device()}\n")
            f.write(f"gpu_name: {torch.cuda.get_device_name()}\n")
        f.write("\n")
        
        f.write("=" * 80 + "\n")
        f.write("Configuration saved successfully\n")
        f.write("=" * 80 + "\n")
    
    return config_path


def save_results(results: Dict, output_dir: str) -> str:
    """ê²°ê³¼ ì €ì¥"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_path = os.path.join(output_dir, f'results_{timestamp}.json')
    
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    return results_path


def parse_arguments():
    """ëª…ë ¹ì¤„ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='TextVibCLIP ì‹¤í—˜')
    
    parser.add_argument('--output_dir', type=str, default='results',
                       help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--quick_test', action='store_true',
                       help='ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ')
    parser.add_argument('--epochs', type=int, default=None,
                       help='ì—í¬í¬ ìˆ˜')
    parser.add_argument('--device', type=str, default='auto',
                       choices=['auto', 'cpu', 'cuda'])
    parser.add_argument('--seed', type=int, default=42)
    parser.add_argument('--skip_uos', action='store_true')
    parser.add_argument('--skip_cwru', action='store_true')
    parser.add_argument('--clear_cache', action='store_true')
    
    return parser.parse_args()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    args = parse_arguments()
    
    # ì¬í˜„ì„± ì„¤ì • (ì¤‘ë³µ ì œê±° - set_random_seeds ì‚¬ìš©)
    set_random_seeds(args.seed)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)
    
    # ë¡œê¹… ì„¤ì •
    logger, experiment_dir = setup_logging(args.output_dir)
    
    # ìºì‹œ ê´€ë¦¬
    if args.clear_cache:
        logger.info("ğŸ—‘ï¸ ìºì‹œ ì‚­ì œ ì¤‘...")
        clear_all_caches()
    
    logger.info("ğŸ¯ TextVibCLIP ì‹¤í—˜ ì‹œì‘!")
    logger.info("   ì•„í‚¤í…ì²˜: Ranking-based (Triplet Loss)")
    logger.info("   íŠ¹ì§•: ì†Œê·œëª¨ ë°ì´í„° ìµœì í™”, ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ ì§€ì›")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)
    
    logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {device}")
    
    # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •
    scenarios = []
    if not args.skip_uos:
        scenarios.append(ScenarioConfig.UOS_CONFIG)
    if not args.skip_cwru:
        scenarios.append(ScenarioConfig.CWRU_CONFIG)
    
    if not scenarios:
        logger.error("âŒ ì‹¤í–‰í•  ì‹œë‚˜ë¦¬ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # ì—í¬í¬ ì„¤ì •
    if args.quick_test:
        test_epochs = args.epochs if args.epochs else 10
        logger.info(f"âš¡ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì—í¬í¬ {test_epochs}")
        for scenario in scenarios:
            scenario['first_domain_epochs'] = test_epochs
            scenario['remaining_epochs'] = max(test_epochs // 2, 3)
    elif args.epochs:
        for scenario in scenarios:
            scenario['first_domain_epochs'] = args.epochs
            scenario['remaining_epochs'] = max(args.epochs // 2, 3)
    
    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‹¤í–‰ (ê¸°ì¡´ + replay-free ablation study)
    all_results = {}
    total_start_time = time.time()
    
    for i, scenario in enumerate(scenarios, 1):
        # 1. ê¸°ì¡´ ì‹¤í—˜ (replay buffer ì‚¬ìš©)
        logger.info(f"\n{'='*60}")
        logger.info(f"ì‹œë‚˜ë¦¬ì˜¤ {i*2-1}/{len(scenarios)*2}: {scenario['name']} (with replay buffer)")
        logger.info(f"{'='*60}")
        
        scenario_result = run_single_scenario(scenario, logger, device, args, experiment_dir)
        
        if scenario_result:
            all_results[scenario['name']] = scenario_result
        else:
            logger.error(f"âŒ {scenario['name']} ì‹¤í–‰ ì‹¤íŒ¨!")
        
        # 2. Replay-free ablation study
        logger.info(f"\n{'='*60}")
        logger.info(f"ì‹œë‚˜ë¦¬ì˜¤ {i*2}/{len(scenarios)*2}: {scenario['name']} (replay-free)")
        logger.info(f"{'='*60}")
        
        # Replay-free ì„¤ì •ìœ¼ë¡œ ì‹œë‚˜ë¦¬ì˜¤ ë³µì‚¬ ë° ìˆ˜ì •
        replay_free_scenario = scenario.copy()
        replay_free_scenario['name'] = scenario['name'] + '_ReplayFree'
        replay_free_scenario['replay_buffer_size'] = 0  # Replay buffer ë¹„í™œì„±í™”
        
        replay_free_result = run_single_scenario(replay_free_scenario, logger, device, args, experiment_dir)
        
        if replay_free_result:
            all_results[replay_free_scenario['name']] = replay_free_result
        else:
            logger.error(f"âŒ {replay_free_scenario['name']} ì‹¤í–‰ ì‹¤íŒ¨!")
    
    # ê²°ê³¼ ì €ì¥
    if all_results:
        results_path = save_results(all_results, experiment_dir)
        logger.info(f"âœ… ê²°ê³¼ ì €ì¥: {results_path}")
    
    # ìµœì¢… ìš”ì•½
    total_time = time.time() - total_start_time
    logger.info(f"\nâ±ï¸ ì „ì²´ ì‹¤í—˜ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
    
    # ì„±ëŠ¥ ìš”ì•½
    logger.info(f"\nğŸ“Š TextVibCLIP ì„±ëŠ¥ ìš”ì•½:")
    for scenario_name, result in all_results.items():
        avg_acc = result.get('average_accuracy', 0.0)
        avg_forget = result.get('average_forgetting', 0.0)
        logger.info(f"   {scenario_name}: í‰ê·  ì •í™•ë„ {avg_acc:.4f}, ë§ê°ë„ {avg_forget:.4f}")
    
    logger.info("ğŸ‰ TextVibCLIP ì‹¤í—˜ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
