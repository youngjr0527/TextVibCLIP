================================================================================
                    TextVibCLIP 성능 문제 분석 보고서
================================================================================

작성일: 2025년 9월 17일
분석 대상: UOS 데이터셋 기반 TextVibCLIP 모델
초기 성능: 14.4% (랜덤 수준)
최종 성능: 28.6% (Cross-Modal Projection 적용 후)

================================================================================
1. 문제 개요
================================================================================

TextVibCLIP 모델이 개별 Encoder의 우수한 성능에도 불구하고 통합 시 극도로 낮은 
성능을 보이는 문제를 분석했습니다.

초기 성능:
- Text Encoder 단독: 83.0% (우수)
- Vibration Encoder 단독: 88.6% (우수)
- TextVibCLIP 통합: 14.4% (랜덤 수준)
- 성능 손실: 71.4%p (심각한 문제)

================================================================================
2. 분석 방법론
================================================================================

세 가지 단계적 분석을 수행했습니다:

2.1 Text Encoder 단독 분석 (test_text_encoder.ipynb)
- 텍스트 다양성 분석
- 클래스별 분류 성능 측정
- 임베딩 품질 평가

2.2 Vibration Encoder 단독 분석 (test_vibration_encoder.ipynb)
- 진동 신호 분류 성능 측정
- 클래스별 혼동 행렬 분석
- 내부 유사도 평가

2.3 Text-Vibration 정렬 문제 분석 (test_alignment_issue.ipynb)
- 개별 vs 통합 임베딩 비교
- 가중치 동기화 테스트
- InfoNCE Loss 구현 검증
- Cross-Modal Projection 효과 분석

================================================================================
3. 주요 발견사항
================================================================================

3.1 텍스트 다양성 부족 문제 (해결됨)
--------------------------------------------
초기 문제:
- 모든 클래스가 "deep groove ball bearing operating at 600 rpm with..." 형식
- 클래스 간 유사도: 96%+ (거의 구분 불가)
- Text Encoder 성능: 15% (랜덤 수준)

해결책:
- 산업 표준 베어링 진단 용어 적용
- 클래스별 고유 키워드 강화
- 예시: H(정상) → "No defects detected", IR(내륜) → "Inner race spalling"

결과:
- Text Encoder 성능: 15% → 83.0% (5.5배 향상)
- 클래스 구분도: 0.0018 → 0.0142 (8배 향상)

3.2 Vibration Encoder 우수 성능 확인
--------------------------------------------
성능 결과:
- 분류 정확도: 88.6% (랜덤 14.3% 대비 6.2배)
- 클래스별 성능:
  * H(정상): 100.0% (완벽)
  * OR(외륜): 100.0% (완벽)
  * B(볼결함): 98.0% (우수)
  * U(불균형): 95.0% (우수)
  * L(느슨함): 91.0% (우수)
  * M(정렬불량): 70.0% (보통)
  * IR(내륜): 66.0% (보통)

특징:
- 내부 유사도: 99%+ (매우 높은 클래스 일관성)
- 1D-CNN 아키텍처: 2048 → 256 차원 변환 성공
- 총 파라미터: 6,985,288개

3.3 Text-Vibration 정렬 문제 (핵심 원인)
--------------------------------------------
가중치 불일치 문제:
- 개별 모델과 통합 모델의 임베딩 차이: 25+ (매우 큼)
- 원인: 서로 다른 초기화로 인한 가중치 불일치
- 해결: 가중치 동기화로 차이 0.000016으로 감소

InfoNCE Loss 구현 문제:
- 가중치 동기화 후에도 성능: 0.3% (여전히 실패)
- 모든 Temperature에서 동일한 결과 (14.3% = 랜덤)
- 원인: 임베딩 공간 불일치

임베딩 공간 불일치 (근본 원인):
- Text 임베딩: 언어적 의미 공간 (단어, 문법 기반)
- Vibration 임베딩: 물리적 신호 공간 (주파수, 진폭 기반)
- 문제: 두 공간 간 자연스러운 매핑이 존재하지 않음

================================================================================
4. 해결책 및 결과
================================================================================

4.1 텍스트 다양성 개선 (완료)
--------------------------------------------
적용 방법:
- 산업 표준 베어링 진단 용어 사용
- 클래스별 고유 키워드 강화
- 공통 단어 제거

결과:
- Text Encoder: 15% → 83.0% (68%p 향상)

4.2 가중치 동기화 (완료)
--------------------------------------------
적용 방법:
- 개별 모델 가중치를 통합 모델에 복사
- 임베딩 차이 확인 및 검증

결과:
- 임베딩 차이: 25+ → 0.000016 (99.999% 개선)

4.3 Cross-Modal Projection (부분 성공)
--------------------------------------------
적용 방법:
- Text/Vibration 전용 Projection Layer 추가
- 256차원 → 128차원 공통 공간 매핑
- InfoNCE Loss로 정렬 학습

결과:
- 통합 성능: 0.3% → 28.6% (+28.3%p)
- 여전히 개별 성능(83-88%)에 미치지 못함

4.4 TextVibCLIP 모델 개선 (적용됨)
--------------------------------------------
적용 사항:
- Cross-Modal Projection Layer 추가
- Temperature 최적화: 0.05 → 0.2
- Forward pass에서 Projection 적용

예상 결과:
- UOS 성능: 14.4% → 30-50% (2-3배 향상)

================================================================================
5. 근본 원인 분석
================================================================================

5.1 임베딩 공간 불일치 (핵심 문제)
--------------------------------------------
CLIP 모델의 한계:
- CLIP: 이미지-텍스트는 시각적으로 연결됨
- TextVibCLIP: 진동-텍스트는 물리적 연결이 약함

구체적 문제:
- Text Encoder: DistilBERT 기반 언어 모델
- Vibration Encoder: 1D-CNN 기반 신호 처리 모델
- 두 모델이 생성하는 임베딩 공간이 완전히 다름

증거:
- Cross-Modal 정렬 점수: 개별 0.000090 vs 통합 -0.000022 (음수!)
- InfoNCE 정확도: 모든 Temperature에서 14.3% (랜덤과 동일)

5.2 InfoNCE Loss 한계
--------------------------------------------
문제점:
- 대각선 매칭 방식: 같은 인덱스끼리만 positive pair
- 클래스 기반 매칭으로 개선해도 14.3% (변화 없음)
- Temperature 조정 무효: 0.01-1.0 범위에서 동일한 결과

결론:
- InfoNCE Loss 자체가 이 문제의 해결책이 아님
- 임베딩 공간 정렬이 선행되어야 함

================================================================================
6. 성능 개선 결과
================================================================================

6.1 단계별 성능 변화
--------------------------------------------
1단계 - 텍스트 다양성 개선:
   UOS 성능: 14.4% → 예상 40-50% (Text Encoder 83.0% 달성)

2단계 - 가중치 동기화:
   임베딩 차이: 25+ → 0.000016 (기술적 해결)

3단계 - Cross-Modal Projection:
   통합 성능: 0.3% → 28.6% (실질적 개선)

4단계 - 모델 아키텍처 개선:
   예상 성능: 30-50% (Temperature 0.2 + Projection Layer)

6.2 클래스별 성능 분석
--------------------------------------------
Text Encoder (83.0%):
- 최고: OR(외륜) 100%, U(불균형) 100%
- 최저: M(정렬불량) 65%, IR(내륜) 67%

Vibration Encoder (88.6%):
- 최고: H(정상) 100%, OR(외륜) 100%
- 최저: IR(내륜) 66%, M(정렬불량) 70%

공통 문제 클래스:
- IR vs L: 내륜 결함과 느슨함 혼동
- M vs H: 정렬불량과 정상 혼동

================================================================================
7. 향후 개선 방향
================================================================================

7.1 즉시 적용 가능한 개선
--------------------------------------------
1. Temperature 최적화 (완료)
   - 0.05 → 0.2 (4배 증가)

2. Cross-Modal Projection 추가 (완료)
   - TextVibCLIP 모델에 통합
   - 256차원 → 256차원 공간 변환

3. 텍스트 생성 로직 개선 (완료)
   - 산업 표준 용어 적용

7.2 추가 개선 방향
--------------------------------------------
1. Projection 아키텍처 강화:
   - 더 깊은 네트워크 (3-4층)
   - Attention 메커니즘 추가
   - Residual Connection 적용

2. 학습 전략 개선:
   - Auxiliary Classification Loss 추가
   - Curriculum Learning 적용
   - Data Augmentation 강화

3. 대안 접근법:
   - Late Fusion: 각 Encoder 독립 사용 + 결과 결합
   - Ensemble: 여러 모델의 예측 평균
   - Pre-trained Multi-modal Model 활용

================================================================================
8. 실험 검증 결과
================================================================================

8.1 개별 Encoder 검증
--------------------------------------------
✅ Text Encoder: 83.0% (우수)
- 산업 표준 용어 적용 성공
- 클래스별 고유 키워드 효과적
- 랜덤 대비 5.8배 향상

✅ Vibration Encoder: 88.6% (우수)
- 1D-CNN 아키텍처 효과적
- 진동 신호 특성 잘 포착
- 랜덤 대비 6.2배 향상

8.2 통합 문제 검증
--------------------------------------------
❌ 가중치 불일치: 해결됨
- 임베딩 차이: 25+ → 0.000016

❌ InfoNCE Loss: 실패
- 모든 설정에서 14.3% (랜덤)

⚠️ Cross-Modal Projection: 부분 성공
- 0.3% → 28.6% (+28.3%p)
- 여전히 목표치(60-80%) 미달

================================================================================
9. 결론 및 권고사항
================================================================================

9.1 핵심 발견
--------------------------------------------
1. 텍스트 다양성 부족이 초기 성능 저하의 주요 원인이었음
2. 개별 Encoder는 모두 우수한 성능을 보임 (80%+)
3. 임베딩 공간 불일치가 통합 성능 저하의 근본 원인
4. Cross-Modal Projection이 유일한 효과적 해결책

9.2 최종 권고사항
--------------------------------------------
즉시 적용:
1. ✅ 수정된 TextVibCLIP 모델로 전체 실험 재실행
   - Cross-Modal Projection Layer 포함
   - Temperature 0.2 적용
   - 예상 성능: 30-50%

단기 개선:
2. Projection 아키텍처 강화
   - 3-4층 깊은 네트워크
   - Attention 메커니즘 추가
   - 목표 성능: 50-70%

장기 개선:
3. 대안 접근법 고려
   - Late Fusion 방식
   - Ensemble 방법
   - Pre-trained 모델 활용

9.3 기술적 교훈
--------------------------------------------
1. 멀티모달 모델에서 임베딩 공간 정렬의 중요성
2. 개별 성능이 좋다고 통합 성능이 보장되지 않음
3. Cross-Modal Projection의 필요성과 효과
4. 도메인별 특성을 고려한 텍스트 생성의 중요성

================================================================================
10. 상세 실험 데이터
================================================================================

10.1 Text Encoder 분석 결과
--------------------------------------------
전체 성능: 83.0% (5.8배 향상)
클래스별 성능:
- H(정상): 86.0%
- B(볼결함): 84.0%
- IR(내륜): 67.0%
- OR(외륜): 100.0%
- L(느슨함): 79.0%
- U(불균형): 100.0%
- M(정렬불량): 65.0%

텍스트 품질:
- 클래스 구분도: 0.0142
- 내부 유사도: 96-97%
- 개선된 키워드 사용 확인

10.2 Vibration Encoder 분석 결과
--------------------------------------------
전체 성능: 88.6% (6.2배 향상)
클래스별 성능:
- H(정상): 100.0% (완벽)
- B(볼결함): 98.0% (우수)
- IR(내륜): 66.0% (보통, L과 혼동)
- OR(외륜): 100.0% (완벽)
- L(느슨함): 91.0% (우수)
- U(불균형): 95.0% (우수)
- M(정렬불량): 70.0% (보통, H와 혼동)

아키텍처:
- 커널 크기: [16, 32, 64, 32]
- 채널 수: [64, 128, 256, 512]
- 총 파라미터: 6,985,288개

10.3 정렬 문제 분석 결과
--------------------------------------------
가중치 동기화:
- Text 차이: 25.719437 → 0.000016
- Vibration 차이: 26.672676 → 0.000000
- 결과: 가중치 문제 해결됨

정렬 점수:
- 개별 Encoder: 0.000090 (미약한 양수)
- 통합 모델: -0.000022 (음수, 완전 실패)
- 차이: 112% 악화

InfoNCE Loss 성능:
- 모든 Temperature: 14.3% (랜덤과 동일)
- 클래스 기반 개선: 효과 없음
- 결론: InfoNCE만으로는 해결 불가

Cross-Modal Projection 효과:
- 학습 전: 0.3%
- 학습 후: 28.6% (+28.3%p)
- 차원 변환: 256 → 128
- 결론: 유일한 효과적 해결책

================================================================================
11. 기술적 세부사항
================================================================================

11.1 모델 아키텍처
--------------------------------------------
Text Encoder:
- Base: DistilBERT
- LoRA: rank=32, alpha=64
- 파라미터: 1,114,880개
- 출력: 256차원

Vibration Encoder:
- Base: 1D-CNN
- 구조: 4-layer [16,32,64,32] kernels
- 채널: [64,128,256,512]
- 파라미터: 6,985,288개
- 출력: 256차원

TextVibCLIP (수정 후):
- Text Projection: 256→256차원 변환
- Vibration Projection: 256→256차원 변환
- InfoNCE Temperature: 0.2
- 총 파라미터: 74,463,050개

11.2 데이터 특성
--------------------------------------------
UOS 데이터셋:
- 7개 클래스 (H,B,IR,OR,L,U,M)
- 윈도우 크기: 2048 샘플
- 샘플 수: 8,743개 (train/test 각각)
- 클래스 균형: 완벽한 균형

진동 신호:
- 정규화: Z-score
- 범위: [-1.56, 1.78]
- 통계: mean=-0.0004, std=1.0121

텍스트:
- 평균 길이: 3.8 단어
- 범위: 3-6 단어
- 산업 표준 용어 사용

================================================================================
12. 최종 평가
================================================================================

12.1 성공 요소
--------------------------------------------
✅ 텍스트 다양성 문제 해결: 68%p 향상
✅ 개별 Encoder 우수 성능: 80%+ 달성
✅ 가중치 동기화 문제 해결: 99.999% 개선
✅ Cross-Modal Projection 효과 확인: 28.3%p 향상

12.2 미해결 문제
--------------------------------------------
⚠️ 임베딩 공간 불일치: 부분적 해결 (28.6%)
⚠️ InfoNCE Loss 한계: 근본적 한계 확인
⚠️ 통합 성능 격차: 개별 80%+ vs 통합 28.6%

12.3 최종 결론
--------------------------------------------
TextVibCLIP의 성능 문제는 다음과 같은 복합적 원인에 의한 것이었습니다:

1. 텍스트 다양성 부족 (68%p 손실) - 해결됨
2. 가중치 불일치 (기술적 문제) - 해결됨  
3. 임베딩 공간 불일치 (근본적 문제) - 부분 해결됨

Cross-Modal Projection을 통해 상당한 개선을 달성했으나, 
개별 Encoder 수준의 성능을 달성하기 위해서는 추가적인 
아키텍처 개선이 필요합니다.

현재 수정된 모델로 30-50% 성능을 달성할 것으로 예상되며,
이는 초기 14.4% 대비 2-3배 향상된 결과입니다.

