#!/usr/bin/env python3
"""
1D-CNN ë¹„êµêµ° ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
TextVibCLIPì˜ í…ìŠ¤íŠ¸ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„ì„ ìœ„í•œ ë¹„êµêµ° ì‹¤í—˜

Usage:
    python run_1dcnn_scenarios.py --quick_test --epochs 10
"""

import argparse
import logging
import os
import torch
import torch.nn.functional as F
import time
import json
import numpy as np
import random
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple

# ğŸ¯ ì¬í˜„ì„± ë³´ì¥ì„ ìœ„í•œ ì‹œë“œ ê³ ì •
def set_random_seeds(seed: int = 42):
    """ëª¨ë“  ëœë¤ ì‹œë“œ ê³ ì •"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    print(f"ğŸ¯ Random seeds fixed to {seed} for reproducibility")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
import sys
from pathlib import Path
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

from src.onedcnn_trainer import OneDCNNTrainer
from src.data_loader import create_domain_dataloaders
from src.data_cache import create_cached_domain_dataloaders, create_cached_first_domain_dataloader, clear_all_caches
from src.utils import set_seed
from src.visualization import create_visualizer
from configs.model_config import TRAINING_CONFIG, DATA_CONFIG


def setup_logging(log_dir: str) -> Tuple[logging.Logger, str]:
    """ë¡œê¹… ì„¤ì •"""
    experiment_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    experiment_dir = os.path.join(log_dir, f"{experiment_timestamp}")
    os.makedirs(experiment_dir, exist_ok=True)
    
    log_filename = f"onedcnn_{experiment_timestamp}.log"
    log_path = os.path.join(experiment_dir, log_filename)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_path),
            logging.StreamHandler()
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"1D-CNN ë¹„êµêµ° ì‹¤í—˜ ì‹œì‘: {log_path}")
    logger.info(f"ì‹¤í—˜ ê²°ê³¼ í´ë”: {experiment_dir}")
    
    return logger, experiment_dir


class ScenarioConfig:
    """ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„¤ì •"""
    
    UOS_CONFIG = {
        'name': 'UOS_1DCNN_Baseline',
        'data_dir': 'data_scenario1',
        'dataset_type': 'uos',
        'domain_order': [600, 800, 1000, 1200, 1400, 1600],
        'domain_names': ['600RPM', '800RPM', '1000RPM', '1200RPM', '1400RPM', '1600RPM'],
        'shift_type': 'Varying Speed',
        'first_domain_epochs': 20,
        'remaining_epochs': 8,
        'batch_size': 16,
        'replay_buffer_size': 0,  # Vanilla 1D-CNN: replay buffer ì‚¬ìš© ì•ˆ í•¨
        'patience': 10
    }


def run_single_scenario(config: Dict, logger: logging.Logger, device: torch.device, args, experiment_dir: str) -> Dict:
    """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
    logger.info(f"ğŸš€ {config['name']} ì‹œì‘!")
    logger.info(f"   ì•„í‚¤í…ì²˜: 1D-CNN Classifier (TextVibCLIP ë¹„êµêµ°)")
    logger.info(f"   Domains: {' â†’ '.join(config['domain_names'])}")
    
    start_time = time.time()
    
    try:
        # Trainer ìƒì„±
        checkpoint_dir = os.path.join(experiment_dir, 'checkpoints', config['name'])
        
        trainer = OneDCNNTrainer(
            model=None,
            device=device,
            save_dir=checkpoint_dir,
            domain_order=config['domain_order'],
            data_dir=config['data_dir'],
            dataset_type=config['dataset_type'],
            results_save_dir=None
        )
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
        trainer.batch_size = config['batch_size']
        trainer.replay_buffer.buffer_size_per_domain = config['replay_buffer_size']
        
        # First Domain Training
        logger.info("ğŸ“š First Domain Training...")
        
        first_loader = create_cached_first_domain_dataloader(
            data_dir=config['data_dir'],
            domain_order=config['domain_order'],
            dataset_type=config['dataset_type'],
            subset='train',
            batch_size=config['batch_size']
        )
        
        first_results = trainer.train_first_domain(
            first_domain_dataloader=first_loader,
            num_epochs=config['first_domain_epochs']
        )
        
        # Remaining Domains Training
        logger.info("ğŸ”„ Remaining Domains Training...")
        
        domain_loaders = create_cached_domain_dataloaders(
            data_dir=config['data_dir'],
            domain_order=config['domain_order'],
            dataset_type=config['dataset_type'],
            batch_size=config['batch_size']
        )
        
        # ë‚¨ë„ë©”ì¸ ì—í­/ì„¤ì • ê°•ì œ ë°˜ì˜
        try:
            from configs.model_config import CONTINUAL_CONFIG
            CONTINUAL_CONFIG['num_epochs'] = max(1, int(config.get('remaining_epochs', 3)))
        except Exception:
            pass
        
        remaining_results = trainer.train_remaining_domains(domain_loaders)
        
        # ì‹œê°í™” ìƒì„±
        try:
            logger.info("ğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")
            visualizer = create_visualizer(experiment_dir)
            
            # Continual Learning Performance Curve
            visualizer.create_continual_learning_curve(
                domain_names=config['domain_names'],
                accuracies=remaining_results['final_metrics']['final_accuracies'],
                scenario_name=config['name']
            )
            
            # Forgetting Analysis Heatmap
            n_domains = len(config['domain_names'])
            accuracy_matrix = np.full((n_domains, n_domains), np.nan)
            
            for i in range(n_domains):
                for j in range(n_domains):
                    if j <= i:
                        test_domain = config['domain_order'][j]
                        if test_domain in trainer.performance_history:
                            history = trainer.performance_history[test_domain]['accuracy']
                            history_idx = i - j
                            if len(history) > history_idx:
                                accuracy_matrix[i, j] = history[history_idx]
            
            visualizer.create_forgetting_heatmap(
                domain_names=config['domain_names'],
                accuracy_matrix=accuracy_matrix,
                scenario_name=config['name']
            )
            
            logger.info("âœ… ì‹œê°í™” ìƒì„± ì™„ë£Œ!")
        except Exception as viz_err:
            logger.warning(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {viz_err}")
        
        # ì‹¤í—˜ ì„¤ì • ì €ì¥
        config_path = save_experiment_config(config, trainer, experiment_dir, device)
        logger.info(f"ğŸ“ ì‹¤í—˜ ì„¤ì • ì €ì¥: {config_path}")
        
        # ê²°ê³¼ ì •ë¦¬
        final_metrics = remaining_results['final_metrics']
        total_time = time.time() - start_time
        
        # Forgetting Heatmap ë°ì´í„° ì¶”ì¶œ
        n_domains = len(config['domain_names'])
        heatmap_matrix = []
        stage_averages = []
        
        for i in range(n_domains):
            row = []
            for j in range(n_domains):
                if j <= i:
                    test_domain = config['domain_order'][j]
                    if test_domain in trainer.performance_history:
                        history = trainer.performance_history[test_domain]['accuracy']
                        history_idx = i - j
                        if len(history) > history_idx:
                            row.append(round(history[history_idx] * 100, 2))
                        else:
                            row.append(None)
                    else:
                        row.append(None)
                else:
                    row.append(None)
            
            valid_values = [v for v in row if v is not None]
            if valid_values:
                stage_avg = round(sum(valid_values) / len(valid_values), 2)
            else:
                stage_avg = None
            
            heatmap_matrix.append(row)
            stage_averages.append(stage_avg)
        
        results = {
            'domain_names': config['domain_names'],
            'shift_type': config['shift_type'],
            'stage_accuracies': stage_averages,
            'average_accuracy': final_metrics['average_accuracy'],
            'average_forgetting': final_metrics['average_forgetting'],
            'forgetting_matrix': heatmap_matrix,
            'total_time': total_time,
            'first_domain_epochs': config['first_domain_epochs'],
            'remaining_epochs': config['remaining_epochs'],
            'batch_size': config['batch_size']
        }
        
        logger.info(f"âœ… {config['name']} ì™„ë£Œ!")
        logger.info(f"   í‰ê·  ì •í™•ë„: {final_metrics['average_accuracy']:.4f}")
        logger.info(f"   í‰ê·  ë§ê°ë„: {final_metrics['average_forgetting']:.4f}")
        logger.info(f"   ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ {config['name']} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        logger.exception("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        return None


def save_experiment_config(config: Dict, trainer, output_dir: str, device: torch.device) -> str:
    """ì‹¤í—˜ ì„¤ì •ì„ txt íŒŒì¼ë¡œ ì €ì¥"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    config_path = os.path.join(output_dir, f'experiment_config_{timestamp}.txt')
    
    with open(config_path, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("1D-CNN Baseline Experiment Configuration\n")
        f.write("=" * 80 + "\n")
        f.write(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Scenario: {config['name']}\n")
        f.write(f"Dataset: {config['dataset_type'].upper()}\n")
        f.write(f"Domain Order: {' â†’ '.join(config['domain_names'])}\n")
        f.write(f"Shift Type: {config['shift_type']}\n")
        f.write(f"Device: {device}\n\n")
        
        # Scenario Configuration
        f.write("-" * 50 + "\n")
        f.write("Scenario Configuration\n")
        f.write("-" * 50 + "\n")
        for key, value in config.items():
            if key not in ['name', 'data_dir', 'dataset_type', 'domain_order', 'domain_names', 'shift_type']:
                f.write(f"{key}: {value}\n")
        f.write("\n")
        
        # Model Architecture
        f.write("-" * 50 + "\n")
        f.write("Model Architecture\n")
        f.write("-" * 50 + "\n")
        f.write("Architecture: 1D-CNN Classifier (TextVibCLIP ë¹„êµêµ°)\n")
        f.write("Input: Vibration signal only (no text modality)\n")
        f.write("Output: Classification logits (7 classes for UOS)\n")
        try:
            from configs.model_config import MODEL_CONFIG
            f.write(f"embedding_dim: {MODEL_CONFIG['embedding_dim']}\n")
            f.write(f"vibration_input_length: {MODEL_CONFIG['vibration_encoder']['input_length']}\n")
            f.write(f"vibration_kernel_sizes: {MODEL_CONFIG['vibration_encoder']['kernel_sizes']}\n")
            f.write(f"vibration_channels: {MODEL_CONFIG['vibration_encoder']['channels']}\n")
        except Exception as e:
            f.write(f"Model config loading failed: {e}\n")
        f.write("\n")
        
        # Training Configuration
        f.write("-" * 50 + "\n")
        f.write("Training Configuration\n")
        f.write("-" * 50 + "\n")
        try:
            from configs.model_config import FIRST_DOMAIN_CONFIG, CONTINUAL_CONFIG
            f.write("First Domain:\n")
            f.write(f"  epochs: {FIRST_DOMAIN_CONFIG['num_epochs']}\n")
            f.write(f"  learning_rate: {FIRST_DOMAIN_CONFIG['learning_rate']}\n")
            f.write(f"  weight_decay: {FIRST_DOMAIN_CONFIG['weight_decay']}\n")
            f.write("Remaining Domains:\n")
            f.write(f"  epochs: {CONTINUAL_CONFIG['num_epochs']}\n")
            f.write(f"  learning_rate: {CONTINUAL_CONFIG['learning_rate']}\n")
            f.write(f"  weight_decay: {CONTINUAL_CONFIG['weight_decay']}\n")
        except Exception as e:
            f.write(f"Training config loading failed: {e}\n")
        f.write("\n")
        
        # Replay Buffer Configuration
        f.write("-" * 50 + "\n")
        f.write("Replay Buffer Configuration\n")
        f.write("-" * 50 + "\n")
        f.write(f"buffer_size_per_domain: {trainer.replay_buffer.buffer_size_per_domain}\n")
        f.write(f"sampling_strategy: {trainer.replay_buffer.sampling_strategy}\n")
        f.write("\n")
        
        # Reproducibility Configuration
        f.write("-" * 50 + "\n")
        f.write("Reproducibility Configuration\n")
        f.write("-" * 50 + "\n")
        f.write(f"pytorch_seed: {torch.initial_seed()}\n")
        f.write(f"cudnn_deterministic: {torch.backends.cudnn.deterministic}\n")
        f.write(f"cudnn_benchmark: {torch.backends.cudnn.benchmark}\n")
        f.write("\n")
        
        # System Information
        f.write("-" * 50 + "\n")
        f.write("System Information\n")
        f.write("-" * 50 + "\n")
        f.write(f"python_version: {sys.version}\n")
        f.write(f"pytorch_version: {torch.__version__}\n")
        f.write(f"cuda_available: {torch.cuda.is_available()}\n")
        if torch.cuda.is_available():
            f.write(f"cuda_version: {torch.version.cuda}\n")
            f.write(f"gpu_name: {torch.cuda.get_device_name()}\n")
        f.write("\n")
        
        f.write("=" * 80 + "\n")
        f.write("Configuration saved successfully\n")
        f.write("=" * 80 + "\n")
    
    return config_path


def save_results(results: Dict, output_dir: str) -> str:
    """ê²°ê³¼ ì €ì¥"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_path = os.path.join(output_dir, f'results_{timestamp}.json')
    
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    return results_path


def parse_arguments():
    """ëª…ë ¹ì¤„ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='1D-CNN ë¹„êµêµ° ì‹¤í—˜')
    
    parser.add_argument('--output_dir', type=str, default='results',
                       help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--quick_test', action='store_true',
                       help='ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ')
    parser.add_argument('--epochs', type=int, default=None,
                       help='ì—í¬í¬ ìˆ˜')
    parser.add_argument('--device', type=str, default='auto',
                       choices=['auto', 'cpu', 'cuda'])
    parser.add_argument('--seed', type=int, default=42)
    parser.add_argument('--clear_cache', action='store_true')
    
    return parser.parse_args()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    args = parse_arguments()
    
    # ì¬í˜„ì„± ì„¤ì •
    set_random_seeds(args.seed)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)
    
    # ë¡œê¹… ì„¤ì •
    logger, experiment_dir = setup_logging(args.output_dir)
    
    # ìºì‹œ ê´€ë¦¬
    if args.clear_cache:
        logger.info("ğŸ—‘ï¸ ìºì‹œ ì‚­ì œ ì¤‘...")
        clear_all_caches()
    
    logger.info("ğŸ¯ 1D-CNN ë¹„êµêµ° ì‹¤í—˜ ì‹œì‘!")
    logger.info("   ì•„í‚¤í…ì²˜: 1D-CNN Classifier (TextVibCLIP ë¹„êµêµ°)")
    logger.info("   ëª©ì : í…ìŠ¤íŠ¸ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)
    
    logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {device}")
    
    # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •
    scenarios = [ScenarioConfig.UOS_CONFIG]
    
    # ì—í¬í¬ ì„¤ì •
    if args.quick_test:
        test_epochs = args.epochs if args.epochs else 10
        logger.info(f"âš¡ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì—í¬í¬ {test_epochs}")
        for scenario in scenarios:
            scenario['first_domain_epochs'] = test_epochs
            scenario['remaining_epochs'] = max(test_epochs // 2, 3)
    elif args.epochs:
        for scenario in scenarios:
            scenario['first_domain_epochs'] = args.epochs
            scenario['remaining_epochs'] = max(args.epochs // 2, 3)
    
    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‹¤í–‰
    all_results = {}
    total_start_time = time.time()
    
    for i, scenario in enumerate(scenarios, 1):
        logger.info(f"\n{'='*60}")
        logger.info(f"ì‹œë‚˜ë¦¬ì˜¤ {i}/{len(scenarios)}: {scenario['name']}")
        logger.info(f"{'='*60}")
        
        scenario_result = run_single_scenario(scenario, logger, device, args, experiment_dir)
        
        if scenario_result:
            all_results[scenario['name']] = scenario_result
        else:
            logger.error(f"âŒ {scenario['name']} ì‹¤í–‰ ì‹¤íŒ¨!")
    
    # ê²°ê³¼ ì €ì¥
    if all_results:
        results_path = save_results(all_results, experiment_dir)
        logger.info(f"âœ… ê²°ê³¼ ì €ì¥: {results_path}")
    
    # ìµœì¢… ìš”ì•½
    total_time = time.time() - total_start_time
    logger.info(f"\nâ±ï¸ ì „ì²´ ì‹¤í—˜ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
    
    # ì„±ëŠ¥ ìš”ì•½
    logger.info(f"\nğŸ“Š 1D-CNN ë¹„êµêµ° ì„±ëŠ¥ ìš”ì•½:")
    for scenario_name, result in all_results.items():
        avg_acc = result.get('average_accuracy', 0.0)
        avg_forget = result.get('average_forgetting', 0.0)
        logger.info(f"   {scenario_name}: í‰ê·  ì •í™•ë„ {avg_acc:.4f}, ë§ê°ë„ {avg_forget:.4f}")
    
    logger.info("ğŸ‰ 1D-CNN ë¹„êµêµ° ì‹¤í—˜ ì™„ë£Œ!")


if __name__ == "__main__":
    main()

