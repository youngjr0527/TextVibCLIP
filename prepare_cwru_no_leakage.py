#!/usr/bin/env python3
"""
CWRU ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸ (íŒŒì¼ ë‚´ 3ë¶„í•  ë²„ì „)

í•µì‹¬ ì•„ì´ë””ì–´:
- ë„ë©”ì¸(load)Ã—í´ë˜ìŠ¤(H/B/IR/OR)ë§ˆë‹¤ ëŒ€í‘œ ì›ë³¸ íŒŒì¼ 1ê°œë¥¼ ì„ íƒ
- ë™ì¼ íŒŒì¼ì˜ ì›ì‹œ ì‹ í˜¸ë¥¼ 0â€“60/60â€“80/80â€“100%ë¡œ 3ë¶„í• í•˜ì—¬
  train/val/test ì „ìš© .mat íŒŒì¼ë¡œ ê°ê° ì €ì¥(ì„œë¡œ ë¹„ì¤‘ë³µ â†’ ìœˆë„ìš° ëˆ„ìˆ˜ ì—†ìŒ)
- ì´ë ‡ê²Œ ìƒì„±ëœ data_scenario2/Load_{hp}hp í•˜ìœ„ì˜ _train/_val/_test íŒŒì¼ë§Œ ì‚¬ìš©
"""

import os
import shutil
import glob
import re
from collections import defaultdict, Counter
import numpy as np
from scipy.io import loadmat, savemat


def _read_signal_from_mat(filepath: str) -> np.ndarray:
    """CWRU .matì—ì„œ 1D ì§„ë™ ì‹ í˜¸ë¥¼ ì½ì–´ ë°˜í™˜.
    ìš°ì„ ìˆœìœ„ í‚¤: 'DE_time' â†’ 'X' â†’ 'signal' â†’ ê·¸ ì™¸ 1D ë°°ì—´ ìë™ íƒìƒ‰
    """
    data = loadmat(filepath)
    for key in ['DE_time', 'X', 'signal']:
        if key in data:
            arr = np.array(data[key]).squeeze()
            if arr.ndim == 1:
                return arr.astype(np.float32)
    for k, v in data.items():
        if k.startswith('__'):
            continue
        arr = np.array(v).squeeze()
        if arr.ndim == 1 and arr.size > 1000:
            return arr.astype(np.float32)
    raise ValueError(f"ì§€ì›ë˜ëŠ” 1D ì‹ í˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {os.path.basename(filepath)}")


def _write_signal_to_mat(filepath: str, signal: np.ndarray):
    """ì‹ í˜¸ë¥¼ 'DE_time' í‚¤ë¡œ ì €ì¥."""
    savemat(filepath, {'DE_time': signal.astype(np.float32)})


def _split_indices(n: int, ratios: tuple) -> tuple:
    a, b, c = ratios
    assert abs(a + b + c - 1.0) < 1e-6
    i1 = int(n * a)
    i2 = int(n * (a + b))
    return i1, i2


def _select_bearings_for_splits(all_files: dict, load: str, fault_type: str) -> dict:
    """
    ê° í´ë˜ìŠ¤ë³„ë¡œ train/val/testìš© íŒŒì¼ ì„ íƒ
    
    ì „ëµ:
    - H: 1ê°œ ë² ì–´ë§ë§Œ ì¡´ì¬ â†’ ì‹œê°„ìˆœ 3ë¶„í•  (ê¸°ì¡´ ìœ ì§€)
    - B/IR/OR: Loadë³„ ìˆœí™˜ í• ë‹¹ (ê°™ì€ fault size, ë‹¤ë¥¸ loadì˜ ë² ì–´ë§)
      * Load 0: ë² ì–´ë§[0] train, ë² ì–´ë§[1] val, ë² ì–´ë§[2] test
      * Load 1: ë² ì–´ë§[1] train, ë² ì–´ë§[2] val, ë² ì–´ë§[3] test
      * Load 2: ë² ì–´ë§[2] train, ë² ì–´ë§[3] val, ë² ì–´ë§[0] test
      * Load 3: ë² ì–´ë§[3] train, ë² ì–´ë§[0] val, ë² ì–´ë§[1] test
    
    Returns:
        {'train': filepath, 'val': filepath, 'test': filepath} 
        ë˜ëŠ” {'split_single': filepath} (Hì˜ ê²½ìš°)
    """
    if load not in all_files[fault_type]:
        return None
        
    # H (Normal): ë² ì–´ë§ 1ê°œë§Œ â†’ ì‹œê°„ìˆœ 3ë¶„í• 
    if fault_type == 'H':
        candidates = []
        for exp_num, files in all_files[fault_type][load].items():
            candidates.extend(files)
        if candidates:
            return {'split_single': sorted(candidates)[0]}
        return None
    
    # B/IR/OR: ìˆœí™˜ í• ë‹¹ ì „ëµ
    # ì„ í˜¸ fault size ê²°ì •
    if fault_type in ['B', 'IR']:
        preferred_size = '021'  # ì¤‘ê°„ í¬ê¸°
    else:  # OR
        preferred_size = '007'  # ì‘ì€ í¬ê¸° (@6 ìœ„ì¹˜)
    
    # ëª¨ë“  loadì˜ í•´ë‹¹ size ë² ì–´ë§ ìˆ˜ì§‘
    all_bearings = {}  # {bearing_num: {load: filepath}}
    for ld in ['0', '1', '2', '3']:
        if ld not in all_files[fault_type]:
            continue
        for exp_num, files in all_files[fault_type][ld].items():
            for f in files:
                match = False
                if fault_type == 'OR':
                    match = f"/{preferred_size}/" in f.replace('\\', '/') and "@6" in os.path.basename(f)
                else:
                    match = f"/{preferred_size}/" in f.replace('\\', '/')
                
                if match:
                    if exp_num not in all_bearings:
                        all_bearings[exp_num] = {}
                    all_bearings[exp_num][ld] = f
    
    # ê° loadì— ëŒ€ì‘í•˜ëŠ” ë² ì–´ë§ ë¦¬ìŠ¤íŠ¸
    sorted_bearings = sorted(all_bearings.keys())
    if len(sorted_bearings) < 3:
        # ë² ì–´ë§ì´ 3ê°œ ë¯¸ë§Œì´ë©´ fallback
        if load in all_files[fault_type]:
            candidates = []
            for exp_num, files in all_files[fault_type][load].items():
                candidates.extend(files)
            if candidates:
                return {'split_single': sorted(candidates)[0]}
        return None
    
    # ìˆœí™˜ í• ë‹¹: load ì¸ë±ìŠ¤ì— ë”°ë¼ offset
    load_idx = int(load)
    train_idx = load_idx % len(sorted_bearings)
    val_idx = (load_idx + 1) % len(sorted_bearings)
    test_idx = (load_idx + 2) % len(sorted_bearings)
    
    train_bearing = sorted_bearings[train_idx]
    val_bearing = sorted_bearings[val_idx]
    test_bearing = sorted_bearings[test_idx]
    
    # ê° ë² ì–´ë§ì˜ í•´ë‹¹ load íŒŒì¼ ì„ íƒ
    result = {}
    for subset, bearing in [('train', train_bearing), ('val', val_bearing), ('test', test_bearing)]:
        # ìš°ì„ : ê°™ì€ load, ì—†ìœ¼ë©´ ë‹¤ë¥¸ load
        if load in all_bearings[bearing]:
            result[subset] = all_bearings[bearing][load]
        else:
            # ë‹¤ë¥¸ load ì¤‘ í•˜ë‚˜ ì„ íƒ
            available_loads = sorted(all_bearings[bearing].keys())
            if available_loads:
                result[subset] = all_bearings[bearing][available_loads[0]]
            else:
                return None
    
    if len(result) == 3:
        print(f"    [ìˆœí™˜] {fault_type}-{load}HP: Train={train_bearing}({list(all_bearings[train_bearing].keys())}), "
              f"Val={val_bearing}({list(all_bearings[val_bearing].keys())}), "
              f"Test={test_bearing}({list(all_bearings[test_bearing].keys())})")
        return result
    
    return None


def extract_experiment_number(filepath):
    """íŒŒì¼ëª…ì—ì„œ ì‹¤í—˜ ë²ˆí˜¸ ì¶”ì¶œ"""
    filename = os.path.basename(filepath)
    
    # OR íŠ¹ìˆ˜ íŒ¨í„´: ìˆ«ì@ìœ„ì¹˜_ë¶€í•˜.mat
    match = re.search(r'^(\d+)@\d+_\d+\.mat$', filename)
    if match:
        return match.group(1)
    
    # í‘œì¤€ íŒ¨í„´: ìˆ«ì_ë¶€í•˜.mat
    match = re.search(r'^(\d+)_\d+\.mat$', filename)
    if match:
        return match.group(1)
    
    return None


def extract_load_from_filename(filepath):
    """íŒŒì¼ëª…ì—ì„œ ë¶€í•˜ ì¶”ì¶œ"""
    filename = os.path.basename(filepath)
    
    match = re.search(r'_(\d+)\.mat$', filename)
    if match:
        return match.group(1)
    
    match = re.search(r'@\d+_(\d+)\.mat$', filename)
    if match:
        return match.group(1)
    
    return None


def get_fault_info(filepath):
    """íŒŒì¼ì—ì„œ ê²°í•¨ ì •ë³´ ì¶”ì¶œ"""
    path_parts = filepath.split(os.sep)
    
    # ê²°í•¨ íƒ€ì…
    if 'Normal' in path_parts:
        return 'H', None, None, extract_experiment_number(filepath)
    
    fault_type = None
    for part in path_parts:
        if part in ['B', 'IR', 'OR']:
            fault_type = part
            break
    
    # ê²°í•¨ í¬ê¸°
    fault_size = None
    for part in path_parts:
        if part in ['007', '014', '021', '028']:
            fault_size = part
            break
    
    # OR ìœ„ì¹˜
    fault_position = None
    if fault_type == 'OR':
        filename = os.path.basename(filepath)
        for pos in ['@3', '@6', '@12']:
            if pos in filename:
                fault_position = pos
                break
    
    exp_num = extract_experiment_number(filepath)
    
    return fault_type, fault_size, fault_position, exp_num


def analyze_cwru_structure():
    """CWRU êµ¬ì¡° ë¶„ì„"""
    source_dir = "cwru_data"
    
    print("ğŸ” CWRU ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì¤‘...")
    
    all_files = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))
    # all_files[fault_type][load][exp_num] = [files]
    
    # Normal íŒŒì¼ë“¤
    normal_files = glob.glob(os.path.join(source_dir, "Normal", "*.mat"))
    for file in normal_files:
        load = extract_load_from_filename(file)
        fault_type, _, _, exp_num = get_fault_info(file)
        if load and exp_num:
            all_files['H'][load][exp_num].append(file)
    
    # Fault íŒŒì¼ë“¤
    fault_base = os.path.join(source_dir, "12k_Drive_End_Bearing_Fault_Data")
    fault_files = glob.glob(os.path.join(fault_base, "**", "*.mat"), recursive=True)
    
    for file in fault_files:
        load = extract_load_from_filename(file)
        fault_type, fault_size, fault_position, exp_num = get_fault_info(file)
        if load and exp_num and fault_type:
            all_files[fault_type][load][exp_num].append(file)
    
    # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Š ê²°í•¨ íƒ€ì…ë³„ ì‹¤í—˜ ë²ˆí˜¸ ë¶„ì„:")
    for fault_type in ['H', 'B', 'IR', 'OR']:
        print(f"\n  {fault_type} ê²°í•¨:")
        for load in ['0', '1', '2', '3']:
            exp_numbers = list(all_files[fault_type][load].keys())
            print(f"    {load}HP: ì‹¤í—˜ë²ˆí˜¸ {sorted(exp_numbers)} ({len(exp_numbers)}ê°œ)")
    
    return all_files


def create_experiment_based_split(all_files):
    """ì •ë³´ ì¶œë ¥ìš©(ëŒ€í‘œ íŒŒì¼ í†µê³„). ë¶„í•  í…Œì´ë¸”ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
    print("\nğŸ¯ ë¶„í•  ê°œìš”(ì •ë³´ ì¶œë ¥):")
    
    # ê° ê²°í•¨ íƒ€ì…ë³„ë¡œ ì‹¤í—˜ ë²ˆí˜¸ ìˆ˜ì§‘
    fault_experiments = {}
    
    for fault_type in ['H', 'B', 'IR', 'OR']:
        all_exp_nums = set()
        for load in ['0', '1', '2', '3']:
            all_exp_nums.update(all_files[fault_type][load].keys())
        
        exp_list = sorted(list(all_exp_nums))
        fault_experiments[fault_type] = exp_list
        print(f"  {fault_type}: {len(exp_list)}ê°œ ì‹¤í—˜ë²ˆí˜¸ {exp_list}")
    
    for fault_type in ['H', 'B', 'IR', 'OR']:
        print(f"    {fault_type}: {len(fault_experiments[fault_type])}ê°œ ì‹¤í—˜ë²ˆí˜¸ ê°ì§€")
    return None


def create_window_sliced_files(all_files) -> bool:
    """
    ë„ë©”ì¸Ã—í´ë˜ìŠ¤ë³„ íŒŒì¼ ì¤€ë¹„
    
    ì „ëµ:
    - H: 1ê°œ ë² ì–´ë§ë§Œ ì¡´ì¬ â†’ ì‹œê°„ìˆœ 3ë¶„í•  (ì‘ì€ leakage í—ˆìš©)
    - B/IR/OR: ê°™ì€ fault size ë‚´ ë‹¤ë¥¸ ë² ì–´ë§ â†’ train/val/test ê°ê° í• ë‹¹
    """
    target_dir = "data_scenario2"

    # ê¸°ì¡´ í´ë” ë¬´ì¡°ê±´ ì¬ìƒì„±
    if os.path.exists(target_dir):
        shutil.rmtree(target_dir)

    load_domains = {
        '0': 'Load_0hp',
        '1': 'Load_1hp',
        '2': 'Load_2hp',
        '3': 'Load_3hp'
    }

    for load in load_domains.keys():
        os.makedirs(os.path.join(target_dir, load_domains[load]), exist_ok=True)

    created = 0
    ratios = (0.6, 0.2, 0.2)  # H ì‹œê°„ìˆœ ë¶„í• ìš©

    for load in sorted(load_domains.keys()):
        domain_dir = os.path.join(target_dir, load_domains[load])
        print(f"\nğŸ“‚ {load_domains[load]} ì²˜ë¦¬ ì¤‘...")

        for fault_type in ['H', 'B', 'IR', 'OR']:
            selected = _select_bearings_for_splits(all_files, load, fault_type)
            if selected is None:
                print(f"  âš ï¸ {fault_type}-{load}HP: ì†ŒìŠ¤ íŒŒì¼ ì—†ìŒ - ê±´ë„ˆëœ€")
                continue

            # H: ì‹œê°„ìˆœ 3ë¶„í• 
            if 'split_single' in selected:
                rep_file = selected['split_single']
                try:
                    signal = _read_signal_from_mat(rep_file)
                except Exception as e:
                    print(f"  âŒ {fault_type}-{load}HP: ë¡œë“œ ì‹¤íŒ¨ - {os.path.basename(rep_file)} | {e}")
                    continue

                n = signal.shape[0]
                i1, i2 = _split_indices(n, ratios)
                sig_train = signal[:i1]
                sig_val = signal[i1:i2]
                sig_test = signal[i2:]

                out_train = os.path.join(domain_dir, f"{fault_type}_{load}hp_train_01.mat")
                out_val = os.path.join(domain_dir, f"{fault_type}_{load}hp_val_01.mat")
                out_test = os.path.join(domain_dir, f"{fault_type}_{load}hp_test_01.mat")

                _write_signal_to_mat(out_train, sig_train)
                _write_signal_to_mat(out_val, sig_val)
                _write_signal_to_mat(out_test, sig_test)
                created += 3

                print(f"  âœ… {fault_type}-{load}HP: ë² ì–´ë§ {os.path.basename(rep_file).split('_')[0]} â†’ ì‹œê°„ìˆœ 3ë¶„í• ")
            
            # B/IR/OR: ë‹¤ë¥¸ ë² ì–´ë§ ì‚¬ìš©
            else:
                for subset in ['train', 'val', 'test']:
                    src_file = selected[subset]
                    try:
                        signal = _read_signal_from_mat(src_file)
                    except Exception as e:
                        print(f"  âŒ {fault_type}-{load}HP-{subset}: ë¡œë“œ ì‹¤íŒ¨ - {os.path.basename(src_file)} | {e}")
                        continue

                    out_file = os.path.join(domain_dir, f"{fault_type}_{load}hp_{subset}_01.mat")
                    _write_signal_to_mat(out_file, signal)
                    created += 1

                bearing_nums = [os.path.basename(selected[s]).split('_')[0].split('@')[0] for s in ['train', 'val', 'test']]
                print(f"  âœ… {fault_type}-{load}HP: ë‹¤ë¥¸ ë² ì–´ë§ ì‚¬ìš© (Train:{bearing_nums[0]}, Val:{bearing_nums[1]}, Test:{bearing_nums[2]})")

    print(f"\nâœ… ì´ {created}ê°œ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤")
    return True


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ CWRU ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ ì¤€ë¹„ ì‹œì‘! (ê°œì„  ë²„ì „)")
    print("=" * 60)
    print("ğŸ¯ ì „ëµ: ë² ì–´ë§ ê¸°ë°˜ ë¶„í•  (Fault Typeë³„ ì°¨ë³„í™”)")
    print("   - H (Normal): ì‹œê°„ìˆœ 3ë¶„í•  (ë² ì–´ë§ 1ê°œë¿)")
    print("   - B/IR/OR: ê°™ì€ fault size ë‚´ ë‹¤ë¥¸ ë² ì–´ë§ í• ë‹¹")
    print("     * B/IR: 021 size â†’ ë² ì–´ë§ 3ê°œ ì‚¬ìš©")
    print("     * OR: 007/@6 â†’ ë² ì–´ë§ 3ê°œ ì‚¬ìš©")
    print("   - Domain-Incremental + ì§„ì •í•œ ì¼ë°˜í™” í‰ê°€")
    print("=" * 60)
    
    try:
        # 1. êµ¬ì¡° ë¶„ì„
        all_files = analyze_cwru_structure()
        
        # 2. ëŒ€í‘œ íŒŒì¼ í˜„í™© ì¶œë ¥
        _ = create_experiment_based_split(all_files)
        # 3. íŒŒì¼ ì¤€ë¹„ (ë‹¤ë¥¸ ë² ì–´ë§ ë˜ëŠ” ì‹œê°„ìˆœ 3ë¶„í• )
        if create_window_sliced_files(all_files):
            print(f"\nğŸ‰ CWRU ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ ì¤€ë¹„ ì™„ë£Œ!")
            print("âœ… H: ì‹œê°„ìˆœ 3ë¶„í•  (ì‘ì€ leakage, ë² ì–´ë§ 1ê°œë¿)")
            print("âœ… B/IR/OR: ì™„ì „íˆ ë‹¤ë¥¸ ë² ì–´ë§ ì‚¬ìš© (ì§„ì •í•œ ì¼ë°˜í™”)")
            print("âœ… Domain-incremental learning ì‹œë‚˜ë¦¬ì˜¤ ìœ ì§€")
            return True
        return False
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    if success:
        print("\nâœ… ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâŒ ì‘ì—… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
